<html lang="en">

<head>
  <meta charset="UTF-8">
  <title>Scientia Potestas Est</title>
  <meta name="theme-color" content="#222222" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script src="http://www.ashwinnarayan.com/blog/js/jquery.min.js"></script>
  <script src="http://www.ashwinnarayan.com/blog/js/bootstrap.min.js"></script>
  <script src="http://www.ashwinnarayan.com/blog/js/header.js"></script>
  <script src="http://www.ashwinnarayan.com/blog/js/toc.js"></script>
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <link href="http://www.ashwinnarayan.com/blog/css/bootstrap.min.css" rel="stylesheet">
  <link href="http://www.ashwinnarayan.com/blog/css/theme.css" rel="stylesheet">
  <link href="http://www.ashwinnarayan.com/blog/css/syntax.css" rel="stylesheet">
  <link href="http://www.ashwinnarayan.com/blog/css/font-awesome/css/font-awesome.min.css" rel="stylesheet">
</head>

<body>

  

  


 <script type="text/javascript">
  WebFontConfig = {
    google: {
      families: ['Ubuntu::latin']
    }
  };
  (function() {
    var wf = document.createElement('script');
    wf.src = ('https:' == document.location.protocol ? 'https' : 'http') +
      '://ajax.googleapis.com/ajax/libs/webfont/1/webfont.js';
    wf.type = 'text/javascript';
    wf.async = 'true';
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(wf, s);
  })();
</script>

  <nav class="navbar navbar-inverse navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="http://www.ashwinnarayan.com/blog/">Scientia Potestas Est</a>
      </div>
      <div class="collapse navbar-collapse">
        <ul class="nav navbar-nav">
	  <li><a href="http://www.ashwinnarayan.com">Ashwin</a></li>
          <li><a href="http://www.ashwinnarayan.com/blog/">/home</a></li>
          <li><a href="http://www.ashwinnarayan.com/blog/archive.html">/archive</a></li>
          <li><a href="http://www.ashwinnarayan.com/blog/tags.html">/tags</a></li>
          <!--<li><a href="http://www.ashwinnarayan.com/blog/about.html">/about</a></li>-->
        </ul>
      </div>
    </div>
  </nav>


<div class="wrapper">
  <div class="content">
    <div class="container container-center">
      <div class="row">
        <div class="col-md-8">
          <div class="article">
            <div class="well">
              <h1><a href="http://www.ashwinnarayan.com/blog/2015/11/machine-learning-implementing-linear">Machine Learning: Implementing Linear Regression and Gradient Descent in Python</a></h1>
              <div class="post-meta">
                <div class="post-time">
                  <!--<i class="fa fa-calendar"></i>-->
		  Posted on:
                  <time>20 Nov 2015</time>
                </div>
                <ul>
		  <li>Tags: </li>
                  
                    <li><a href="http://www.ashwinnarayan.com/blog/tag/machine learning">machine learning</a></li>
                  
                    <li><a href="http://www.ashwinnarayan.com/blog/tag/technical">technical</a></li>
                  
                </ul>
              </div>
              <div class="post-content">
                <div id="toc" class="toc"></div>
                <div dir="ltr" style="text-align: left;" trbidi="on"><div style="text-align: justify;">It's been a while since I went through Andrew Ng's Machine Learning course on Coursera. The course is very good at introducing the basic concepts but it lacks the depth of knowledge that I need if I really want to understand how to implement and use some of the algorithms on my own. So I decided to work through a more difficult textbook on machine learning. One of the first things I decided to do was implement the machine learning algorithms from scratch using my language of choice: Python.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">The most simple idea out there that can be called machine 'learning' is linear regression. I first learned about linear regression in high school math class. So when I saw that linear regression was the first topic in the machine learning course, I was a bit skeptical. I felt that linear regression was too simple to be called machine learning. But it turns out that linear regression is quite a powerful tool to make predictions from data. The term 'linear' in linear regression is a bit misleading because it makes you think about straight line graphs and gives you the impression that trying to fit straight lines to data can't really be that useful. The trick to levelling up the power of linear regression lies in how you choose your variables (or features)! So you can have features that are crazy functions of your initial variables.&nbsp;</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">To understand this think about how we can use a straight line to fit a set of data points that you think might be exponential in nature. Say yoususpect that output $y$ is related to the variable $x$ by $y = ke^{cx}$. You can rearrange this equation to $log(y) = cx&nbsp;+ k_1$ by taking the natural logarithm of both sides of the equation. Now we can plot $log(y)$ vs $x$ on a graph and try to fit a straight line to it. Here the parameter that we 'learn' is $c$ and $k_1$. The variable $x$ is called a feature.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">In a similar way you can add features that are functions of the existing features if you think that the relationship is not linear. In a sense we are choosing a 'basis' of functions which we can mix together in different amounts to (hopefully) accurately model the output $y$. The way a Fourier Series builds up a periodic sequence using sine waves of different frequencies is exactly the same as how linear regression works with non linear basis functions.<br /><br />So I decided to make the system 'learn' the square wave in my first implementation of linear regression. First some math:<br /><br />The output prediction $\hat{y}$ can is represented by the linear model below. Here 'n' is the number of feature vectors.<br /><br />$$ \hat{y} = \sum_{i=1}^{n} \theta_i x_i$$<br /><br />To use gradient descent to train this model we need two things: a cost function and a gradient function.<br /><br />The cost function is a function that takes the values of theta, and the features and the data samples and calculates a cost based on the error between the prediction that the model makes and the actual value. The most commonly used cost function is the mean square error cost function.<br /><br />In this equation, m is the total number of training samples that we have and $x^{(i)}$ represents a feature vector that is ith training example. The cost function sums over all the training examples available to give one real number that represents the cost of the current values of the parameters.<br /><br />$$<br />J = \frac{1}{m} \sum_{i=1}^{m}(\hat{y}^{(i)} - y^{(i)})^2 \\<br />\frac{\partial J}{\partial \theta_j} = \frac{2}{m} \sum_{i=1}^{m}(\hat{y}^{(i)} - y^{(i)})x^{(i)}_j<br />$$<br /><br />The gradient of a function is a vector that points in the direction in which the function changes the most. So if I want to find the place where the cost is minimum all I have to do is to start out at a point, find the gradient at that point and go in the opposite direction. I have to keep doing this until the gradient is zero (or very close to it). Think of it like a ball rolling down slopes until it comes to rest at a place where there is no slope. So in Python I have to make a loop and each time the loop is run, I update the parameters theta using the rule. Here alpha is the learning parameter.<br />$$ \theta_j := \theta_j - \alpha \frac{2}{m} \sum_{i=1}^{m}(\hat{y}^{(i)} - y^{(i)})x^{(i)}_j$$<br /><br />So I got a large set of points that were in the shape of a square wave and I used sine wave basis functions as features. After running gradient descent for a thousand iterations I got coeffecients that were really close to the actual Fourier Series expansion of a square wave!<br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://2.bp.blogspot.com/-umRuJOehi0A/Vk3WfUPUajI/AAAAAAAAHIo/MbTIENiej5c/s1600/lin_reg_fit.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="328" src="http://2.bp.blogspot.com/-umRuJOehi0A/Vk3WfUPUajI/AAAAAAAAHIo/MbTIENiej5c/s640/lin_reg_fit.png" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">The learned function superimposed over the original square wave</td></tr></tbody></table><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://3.bp.blogspot.com/-vzdWD2aJFeY/Vk3WfLDLrPI/AAAAAAAAHIk/Hm8igcqXJCo/s1600/lin_reg_error.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="328" src="http://3.bp.blogspot.com/-vzdWD2aJFeY/Vk3WfLDLrPI/AAAAAAAAHIk/Hm8igcqXJCo/s640/lin_reg_error.png" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">How the error decreases over time.</td></tr></tbody></table><br /><br /><br />You can find my implementation on <a href="https://github.com/RationalAsh/ml_scripts" target="_blank">my github page</a>.<br /><br /><script src="https://gist.github.com/RationalAsh/34a88d91fad7c676c37b.js"></script></div></div>

                

              </div>
              
              <div id="disqus_thread">
                <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
                <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
              </div>
              
            </div>
          </div>
        </div>
        <div class="col-md-4 hidden-xs">
          <div class="sidebar ">
  <h2>Recent Posts</h2>
  <ul>
    
    <li><a href="/blog/2016/03/unsupervised-learning-self-organizing">Unsupervised Learning: Self Organizing Maps</a></li>
    
    <li><a href="/blog/2016/03/machine-learning-part-2-implementing">Machine Learning Part 2: Implementing Multi Class Logistic Regression</a></li>
    
    <li><a href="/blog/2016/02/my-first-build-of-bb-8">My First Build of BB-8</a></li>
    
    <li><a href="/blog/2015/11/prime-spirals-in-python">Prime Spirals in Python</a></li>
    
    <li><a href="/blog/2015/11/machine-learning-implementing-linear">Machine Learning: Implementing Linear Regression and Gradient Descent in Python</a></li>
    
  </ul>
</div>

<div class="sidebar">
  <h2>Tags</h2>
  <ul>
    
      <li><a href="/blog/tag/opencv">opencv</a></li>
    
      <li><a href="/blog/tag/programming">programming</a></li>
    
      <li><a href="/blog/tag/technical">technical</a></li>
    
      <li><a href="/blog/tag/free will">free will</a></li>
    
      <li><a href="/blog/tag/thoughts">thoughts</a></li>
    
      <li><a href="/blog/tag/philosophy">philosophy</a></li>
    
      <li><a href="/blog/tag/atheism">atheism</a></li>
    
      <li><a href="/blog/tag/linux">linux</a></li>
    
      <li><a href="/blog/tag/blogging">blogging</a></li>
    
      <li><a href="/blog/tag/web">web</a></li>
    
      <li><a href="/blog/tag/window managers">window managers</a></li>
    
      <li><a href="/blog/tag/productivity">productivity</a></li>
    
      <li><a href="/blog/tag/robotics">robotics</a></li>
    
      <li><a href="/blog/tag/inverse kinematics">inverse kinematics</a></li>
    
      <li><a href="/blog/tag/robotic arm">robotic arm</a></li>
    
      <li><a href="/blog/tag/boiling water">boiling water</a></li>
    
      <li><a href="/blog/tag/coffee">coffee</a></li>
    
      <li><a href="/blog/tag/fire">fire</a></li>
    
      <li><a href="/blog/tag/random stuff">random stuff</a></li>
    
      <li><a href="/blog/tag/electric kettle">electric kettle</a></li>
    
      <li><a href="/blog/tag/electronics">electronics</a></li>
    
      <li><a href="/blog/tag/fpga">fpga</a></li>
    
      <li><a href="/blog/tag/youtube">youtube</a></li>
    
      <li><a href="/blog/tag/fun">fun</a></li>
    
      <li><a href="/blog/tag/cool stuff">cool stuff</a></li>
    
      <li><a href="/blog/tag/arduino">arduino</a></li>
    
      <li><a href="/blog/tag/vga">vga</a></li>
    
      <li><a href="/blog/tag/python">python</a></li>
    
      <li><a href="/blog/tag/Singapore">Singapore</a></li>
    
      <li><a href="/blog/tag/movie review">movie review</a></li>
    
      <li><a href="/blog/tag/terminator genisys">terminator genisys</a></li>
    
      <li><a href="/blog/tag/terminator">terminator</a></li>
    
      <li><a href="/blog/tag/July 18">July 18</a></li>
    
      <li><a href="/blog/tag/maker faire">maker faire</a></li>
    
      <li><a href="/blog/tag/2015 at 10:24PM">2015 at 10:24PM</a></li>
    
      <li><a href="/blog/tag/rant">rant</a></li>
    
      <li><a href="/blog/tag/ashley madison">ashley madison</a></li>
    
      <li><a href="/blog/tag/hack">hack</a></li>
    
      <li><a href="/blog/tag/hacking">hacking</a></li>
    
      <li><a href="/blog/tag/the martian">the martian</a></li>
    
      <li><a href="/blog/tag/books">books</a></li>
    
      <li><a href="/blog/tag/book review">book review</a></li>
    
      <li><a href="/blog/tag/science fiction">science fiction</a></li>
    
      <li><a href="/blog/tag/math">math</a></li>
    
      <li><a href="/blog/tag/space">space</a></li>
    
      <li><a href="/blog/tag/Mathematica">Mathematica</a></li>
    
      <li><a href="/blog/tag/machine learning">machine learning</a></li>
    
      <li><a href="/blog/tag/star wars">star wars</a></li>
    
  </ul>
</div>

        </div>
      </div>
    </div>
    
<!-- Add Disqus comments. -->
<div id="disqus_thread"></div>
<script type="text/javascript">
  /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
  var disqus_shortname = 'rationalash'; // required: replace example with your forum shortname
  var disqus_identifier = "/2015/11/machine-learning-implementing-linear";

  /* * * DON'T EDIT BELOW THIS LINE * * */
  (function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


  </div>
      <footer class="footer-distributed">
      <div class="container">
        <div class="footer">
          <p>Ashwin Narayan &copy; 2016</p>
          <h6>Follow me</h6>

<ul class="social-media">

  
    <li>
      <a title="RationalAsh on Github" href="https://github.com/RationalAsh" target="_blank"><i class="fa fa-github fa-2x"></i></a>
    </li>
  

  
    <li>
      <a title=" on StackOverflow" href="http://stackoverflow.com/users/" target="_blank"><i class="fa fa-stack-overflow fa-2x"></i></a>
    </li>
  

  

  
    <li>
      <a title=" on Instagram" href="https://instagram.com/" target="_blank"><i class="fa fa-instagram fa-2x"></i></a>
    </li>
  

  
    <li>
      <a title=" on Last.fm" href="http://lastfm.com/user/" target="_blank"><i class="fa fa-lastfm fa-2x"></i></a>
    </li>
  

  
    <li>
      <a title="feed.xml RSS" href="/blog/feed.xml" target="_blank"><i class="fa fa-rss fa-2x"></i></a>
    </li>
  

</ul>

	  <p><a href="https://github.com/streetturtle/jekyll-clean-dark">Jekyll Clean Dark Theme</a> by Pavel Makhov</p>
        </div>
      </div>
    </footer>
  </body>
</html>

</div>
