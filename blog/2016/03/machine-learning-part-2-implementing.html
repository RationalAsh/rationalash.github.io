<html lang="en">

<head>
  <meta charset="UTF-8">
  <title>Scientia Potestas Est</title>
  <meta name="theme-color" content="#222222" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script src="http://www.ashwinnarayan.com/blog/js/jquery.min.js"></script>
  <script src="http://www.ashwinnarayan.com/blog/js/bootstrap.min.js"></script>
  <script src="http://www.ashwinnarayan.com/blog/js/header.js"></script>
  <script src="http://www.ashwinnarayan.com/blog/js/toc.js"></script>
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
    CommonHTML: { linebreaks: { automatic: true } },
    "HTML-CSS": { linebreaks: { automatic: true } },
    SVG: { linebreaks: { automatic: true } },
    jax: ["input/TeX","output/SVG"]
  });
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <link href="http://www.ashwinnarayan.com/blog/css/bootstrap.min.css" rel="stylesheet">
  <link href="http://www.ashwinnarayan.com/blog/css/theme.css" rel="stylesheet">
  <link href="http://www.ashwinnarayan.com/blog/css/syntax.css" rel="stylesheet">
  <link href="http://www.ashwinnarayan.com/blog/css/font-awesome/css/font-awesome.min.css" rel="stylesheet">
</head>

<body>

  

  


 <script type="text/javascript">
  WebFontConfig = {
    google: {
      families: ['Ubuntu::latin']
    }
  };
  (function() {
    var wf = document.createElement('script');
    wf.src = ('https:' == document.location.protocol ? 'https' : 'http') +
      '://ajax.googleapis.com/ajax/libs/webfont/1/webfont.js';
    wf.type = 'text/javascript';
    wf.async = 'true';
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(wf, s);
  })();
</script>

  <nav class="navbar navbar-inverse navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="http://www.ashwinnarayan.com/blog/">Scientia Potestas Est</a>
      </div>
      <div class="collapse navbar-collapse">
        <ul class="nav navbar-nav">
	  <li><a href="http://www.ashwinnarayan.com">Ashwin</a></li>
          <li><a href="http://www.ashwinnarayan.com/blog/">/blog</a></li>
          <li><a href="http://www.ashwinnarayan.com/blog/archive.html">/archive</a></li>
          <li><a href="http://www.ashwinnarayan.com/blog/tags.html">/tags</a></li>
          <!--<li><a href="http://www.ashwinnarayan.com/blog/about.html">/about</a></li>-->
        </ul>
      </div>
    </div>
  </nav>


<div class="wrapper">
  <div class="content">
    <div class="container container-center">
      <div class="row">
        <div class="col-md-8">
          <div class="article">
            <div class="well">
              <h1><a href="http://www.ashwinnarayan.com/blog/2016/03/machine-learning-part-2-implementing">Machine Learning Part 2: Implementing Multi Class Logistic Regression</a></h1>
              <div class="post-meta">
                <div class="post-time">
                  <!--<i class="fa fa-calendar"></i>-->
		  Posted on:
                  <time>22 Mar 2016</time>
                </div>
                <ul>
		  <li>Tags: </li>
                  
                    <li><a href="http://www.ashwinnarayan.com/blog/tag/machine learning">machine learning</a></li>
                  
                    <li><a href="http://www.ashwinnarayan.com/blog/tag/python">python</a></li>
                  
                    <li><a href="http://www.ashwinnarayan.com/blog/tag/technical">technical</a></li>
                  
                </ul>
              </div>
              <div class="post-content text-justify">
                <div id="toc" class="toc"></div>
                <div dir="ltr" style="text-align: left;" trbidi="on"><div style="text-align: justify;">In my last post on machine learning I talked about how to implement simple linear regression in Python. This time I am going to implement logistic regression. This technique is used to classify input data into one of several classes.</div><div style="text-align: justify;"><div style="text-align: justify;"><br /></div><div style="text-align: justify;">First let's take a look at two class regression.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Let's have a set of input vectors $\{x_1, x_2, ... , x_N\}$ and a set of targets $\{t_1, t_2, t_3, ..., t_N\}$ as our training data. A logistic regression classifier defines a model $y(x,w) = h(w^Tx)$. The function $h(a)$ is a logistic sigmoid function or a "squashing" function that takes the output of the linear function $w^Tx$ and sqeezes it into a range of values from 0 to 1. Using the logistic sigmoid function allows us to interpret the output of the classifier as the probability that the input belongs to class 1 under certain assumptions.</div><br />So just like in linear regression we need to define cost function in terms of the parameters so that we have a measure of the performance of the model and a way to train the model. In the case of logistic regression there is a cost function - that is very effective and commonly used - called the <i>cross entropy</i>&nbsp;cost function. This cost function is again selected based on a probabilistic interpretation of the classifier.<br /><br />$$J &nbsp;= -\sum_{n=1}^{N}t_n ln(y(x_n) + (1-t_n)ln(1-y(x_n))$$<br /><br />The gradient of this cost function is surprisingly the same as the gradient of the square error cost function.<br /><br />$$\frac{\partial J}{\partial W} = \sum_{n=1}^{N}(y(x_n) - t_n)x_n$$<br /><br />The weights of the model can be adjusted using the gradient descent algorithm just like in linear regression. The classifier will generate a straight that will separate the two classes.<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="https://2.bp.blogspot.com/-iu_23IuO6GU/VvD8hRNpGdI/AAAAAAAAJNE/4Evp4p6aRZ8aD595Ao_Kq6-bfFgiIssCQ/s1600/index.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="286" src="https://2.bp.blogspot.com/-iu_23IuO6GU/VvD8hRNpGdI/AAAAAAAAJNE/4Evp4p6aRZ8aD595Ao_Kq6-bfFgiIssCQ/s400/index.png" width="400" /></a></div><br /><br /><br />Multiclass logistic regression can be done using many logistic regression units if the goal is to perform multiple binary classifications. However, if you have a vector that needs to be assigned to one of K classes, the procedure is slightly different. Multiclass regression is performed using the model $y(x) = softmax(W^Tx + \vec{b})$ where x is the input vector, W is a matrix with K columns where each column is a parameter vector, $\vec{b}$ is a vector of biases and the softmax function is defined as follows.<br /><br />$$softmax(a_j) = \frac{e^{a_j}}{\sum_{k=1}^{K}e^{a_k}}$$<br /><br />Each of the targets to train the classifier will be an array of size K. If an input belongs to class k, the kth position of the array will be a one. The rest of the elements in the array will be zero. This is called 'one-hot encoding'. It is easy to see from the definition of the softmax function that the output of the classifier will be an array of values&nbsp; that are between zero and one and that the sum of all the elements in the output array will be 1. This means that we can interpret the output array as a probability distribution that tells you the probabilities that the input vector belongs to each of the K classes.<br /><br />Like in two class classification, the input data (with N vectors and dimension M) set can be arranged in a NxM array $X$ where each row is an input vector. The corresponding targets can be arranged in a matrix T that has N rows and K columns. If the input vector $x_n$ belongs to class K the element $T_{nk}$ will be one. The rest of the elements of the matrix will be zero.<br /><br />The cost function is the same cross entropy function extended to work with the matrix T.<br />$$J = -\sum_{n=1}^{N}\sum_{k=1}^{K}T_{nk}ln(y_k(x_n))$$ <br />&nbsp;However, since we are using a softmax function instead of the logistic sigmoid function, the gradient of the cost function will be different. The derivation to obtain expression for the gradient gets very hairy but the expression for the gradient is surprisingly simple.<br /><br />$$\frac{\partial J}{\partial W_{uv}} = \sum_{n=1}^{N}X^T_{vn}(t_{nu} - y_{nu})$$<br /><br />Once we have this gradient, gradient descent can be performed on the parameters in the same way. I gathered all the vectorized implementations of the equations I've mentioned into a classifier class in Python for ease of usage. <br /><br /><script src="https://gist.github.com/RationalAsh/4485e789eb338a535bce.js"></script><br /><br />To test the classifier I created a scatter of normally distributed points centred around different means on a 2D plane and applied the classifier. With a little bit of help from stackoverflow I was able to figure out how to color the regions of the plot according to the trained classifier.<br /><br /><div class="separator" style="clear: both; text-align: center;"></div><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-ywuktlIYCVg/VvIBH30fZnI/AAAAAAAAJN4/-Kj3n6-G_jwr3tgR8nau7HixQm4OJW6WA/s1600/unclassified.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="480" src="https://1.bp.blogspot.com/-ywuktlIYCVg/VvIBH30fZnI/AAAAAAAAJN4/-Kj3n6-G_jwr3tgR8nau7HixQm4OJW6WA/s640/unclassified.png" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">This is a scatter plot of the unclassified data. The points were generated using multivariate normal distributions using different means.</td></tr></tbody></table><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="https://3.bp.blogspot.com/-HyCdzW-ifQk/VvIBH2t7evI/AAAAAAAAJN0/u7BDFR5y84URbbbkX66POy35QsNW4ob2g/s1600/error.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="480" src="https://3.bp.blogspot.com/-HyCdzW-ifQk/VvIBH2t7evI/AAAAAAAAJN0/u7BDFR5y84URbbbkX66POy35QsNW4ob2g/s640/error.png" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">This is a plot of the error or the cost over time as the gradient descent algorithm runs.</td></tr></tbody></table><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="https://4.bp.blogspot.com/-sf715jvJN7A/VvIBH1xw3pI/AAAAAAAAJNw/YQgCQ8mkkIgKeHGUqOAXc5WtlqqLOM9FA/s1600/classified.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="480" src="https://4.bp.blogspot.com/-sf715jvJN7A/VvIBH1xw3pI/AAAAAAAAJNw/YQgCQ8mkkIgKeHGUqOAXc5WtlqqLOM9FA/s640/classified.png" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">A plot of the decision regions learned by the classifier. If a region is shaded a particular color, that means that the classifier identifies all the points in that region as belonging to the same class.</td></tr></tbody></table><br /><div class="separator" style="clear: both; text-align: center;"></div><br /><div class="separator" style="clear: both; text-align: center;"></div></div><div style="text-align: justify;"><br /></div></div>

                

              </div>
              
              <div id="disqus_thread">
                <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
                <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
              </div>
              
            </div>
          </div>
        </div>
        <div class="col-md-4 hidden-xs">
          <div class="sidebar ">
  <h2>Recent Posts</h2>
  <ul>
    
    <li><a href="/blog/2016/06/new-website-and-blog">New Website and Blog</a></li>
    
    <li><a href="/blog/2016/03/unsupervised-learning-self-organizing">Unsupervised Learning: Self Organizing Maps</a></li>
    
    <li><a href="/blog/2016/03/machine-learning-part-2-implementing">Machine Learning Part 2: Implementing Multi Class Logistic Regression</a></li>
    
    <li><a href="/blog/2016/02/my-first-build-of-bb-8">My First Build of BB-8</a></li>
    
    <li><a href="/blog/2015/11/prime-spirals-in-python">Prime Spirals in Python</a></li>
    
  </ul>
</div>

<div class="sidebar">
  <h2>Tags</h2>
  <ul>
    
      <li><a href="/blog/tag/opencv">opencv</a></li>
    
      <li><a href="/blog/tag/programming">programming</a></li>
    
      <li><a href="/blog/tag/technical">technical</a></li>
    
      <li><a href="/blog/tag/free will">free will</a></li>
    
      <li><a href="/blog/tag/thoughts">thoughts</a></li>
    
      <li><a href="/blog/tag/philosophy">philosophy</a></li>
    
      <li><a href="/blog/tag/atheism">atheism</a></li>
    
      <li><a href="/blog/tag/linux">linux</a></li>
    
      <li><a href="/blog/tag/blogging">blogging</a></li>
    
      <li><a href="/blog/tag/web">web</a></li>
    
      <li><a href="/blog/tag/window managers">window managers</a></li>
    
      <li><a href="/blog/tag/productivity">productivity</a></li>
    
      <li><a href="/blog/tag/robotics">robotics</a></li>
    
      <li><a href="/blog/tag/inverse kinematics">inverse kinematics</a></li>
    
      <li><a href="/blog/tag/robotic arm">robotic arm</a></li>
    
      <li><a href="/blog/tag/boiling water">boiling water</a></li>
    
      <li><a href="/blog/tag/coffee">coffee</a></li>
    
      <li><a href="/blog/tag/fire">fire</a></li>
    
      <li><a href="/blog/tag/random stuff">random stuff</a></li>
    
      <li><a href="/blog/tag/electric kettle">electric kettle</a></li>
    
      <li><a href="/blog/tag/electronics">electronics</a></li>
    
      <li><a href="/blog/tag/fpga">fpga</a></li>
    
      <li><a href="/blog/tag/youtube">youtube</a></li>
    
      <li><a href="/blog/tag/fun">fun</a></li>
    
      <li><a href="/blog/tag/cool stuff">cool stuff</a></li>
    
      <li><a href="/blog/tag/arduino">arduino</a></li>
    
      <li><a href="/blog/tag/vga">vga</a></li>
    
      <li><a href="/blog/tag/python">python</a></li>
    
      <li><a href="/blog/tag/Singapore">Singapore</a></li>
    
      <li><a href="/blog/tag/movie review">movie review</a></li>
    
      <li><a href="/blog/tag/terminator genisys">terminator genisys</a></li>
    
      <li><a href="/blog/tag/terminator">terminator</a></li>
    
      <li><a href="/blog/tag/July 18">July 18</a></li>
    
      <li><a href="/blog/tag/maker faire">maker faire</a></li>
    
      <li><a href="/blog/tag/2015 at 10:24PM">2015 at 10:24PM</a></li>
    
      <li><a href="/blog/tag/rant">rant</a></li>
    
      <li><a href="/blog/tag/ashley madison">ashley madison</a></li>
    
      <li><a href="/blog/tag/hack">hack</a></li>
    
      <li><a href="/blog/tag/hacking">hacking</a></li>
    
      <li><a href="/blog/tag/the martian">the martian</a></li>
    
      <li><a href="/blog/tag/books">books</a></li>
    
      <li><a href="/blog/tag/book review">book review</a></li>
    
      <li><a href="/blog/tag/science fiction">science fiction</a></li>
    
      <li><a href="/blog/tag/math">math</a></li>
    
      <li><a href="/blog/tag/space">space</a></li>
    
      <li><a href="/blog/tag/Mathematica">Mathematica</a></li>
    
      <li><a href="/blog/tag/machine learning">machine learning</a></li>
    
      <li><a href="/blog/tag/star wars">star wars</a></li>
    
  </ul>
</div>

        </div>
      </div>
    </div>
    
<!-- Add Disqus comments. -->
<div id="disqus_thread"></div>
<script type="text/javascript">
  /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
  var disqus_shortname = 'rationalash'; // required: replace example with your forum shortname
  var disqus_identifier = "/2016/03/machine-learning-part-2-implementing";

  /* * * DON'T EDIT BELOW THIS LINE * * */
  (function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


  </div>
      <footer class="footer-distributed">
      <div class="container">
        <div class="footer">
          <p>Ashwin Narayan &copy; 2016</p>
          <h6>Follow me</h6>

<ul class="social-media">

  
    <li>
      <a title="RationalAsh on Github" href="https://github.com/RationalAsh" target="_blank"><i class="fa fa-github fa-2x"></i></a>
    </li>
  

  
    <li>
      <a title=" on StackOverflow" href="http://stackoverflow.com/users/" target="_blank"><i class="fa fa-stack-overflow fa-2x"></i></a>
    </li>
  

  

  
    <li>
      <a title=" on Instagram" href="https://instagram.com/" target="_blank"><i class="fa fa-instagram fa-2x"></i></a>
    </li>
  

  
    <li>
      <a title=" on Last.fm" href="http://lastfm.com/user/" target="_blank"><i class="fa fa-lastfm fa-2x"></i></a>
    </li>
  

  
    <li>
      <a title="feed.xml RSS" href="/blog/feed.xml" target="_blank"><i class="fa fa-rss fa-2x"></i></a>
    </li>
  

</ul>

	  <p><a href="https://github.com/streetturtle/jekyll-clean-dark">Jekyll Clean Dark Theme</a> by Pavel Makhov</p>
        </div>
      </div>
    </footer>
  </body>
</html>

</div>
