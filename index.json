[{"authors":["admin"],"categories":null,"content":"I am a PhD student at the National University of Singapore working with the Biorobotics research group in the Biomedical Engineering department. I do research on sensing and control methods for stroke rehabilitation robotics.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://www.ashwinnarayan.com/author/ashwin-narayan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/ashwin-narayan/","section":"authors","summary":"I am a PhD student at the National University of Singapore working with the Biorobotics research group in the Biomedical Engineering department. I do research on sensing and control methods for stroke rehabilitation robotics.","tags":null,"title":"Ashwin Narayan","type":"authors"},{"authors":null,"categories":[],"content":" Introduction Growing up in an Indian family, I had very little exposure to discussion and information about the stock market. People in India are generally less likely to invest in the stock market. Many view investments with suspicion. Indeed, most estimates put the percentage of the population that invest in stocks at 2-5% of the country\u0026rsquo;s total population [5, 6]. Unsurprisingly, investments were never really a topic of conversation in my home or in school growing up. The only remark I remember from my parents about it dismissed it as little more than gambling. School education in India is also lacking in this regard. Economics was either not taught or lumped in with other subjects such as history. I remember very little of economic theory actually being taught in school, especially for those who were aiming for engineering schools.\nI was introduced to the idea of investing during my PhD through some of the friends I made here in Singapore. Investing is relatively common here. It was interesting to see articles like this highlighting that around 33% of Singaporeans do not invest. Culturally, investing enjoys relative popularity here as a way to keep ahead of inflation and to grow savings. Always the scientist, I set out to understand the underlying principles behind investing in the stock market before I started. There is no dearth of articles on the internet with advice on getting started with investing in the stock market. However, a lot of the articles that I read left me unsatisfied as a scientist. Observations - like the fact that money loses value over time - were often presented as assumptions and discussions about the benefits of investing tended to be biased towards the investor; with the central point of most articles being that investing can grow your money. While I learnt quite a bit about investing, I was left with many unanswered questions. For instance, why does the assumption that money loses value over time hold? Who benefits from a healthy stock market apart from the investors?\nThese questions led me down a rabbit hole of academic articles about economic theory and monetary planning. I wrote this article for people who, like me, did not grow up in a culture of investing and would like to know of the raison d\u0026rsquo;être of stock markets. The article contains some of the information that helped me make an informed decision about whether I should invest in the stock market.\nInflation and Economic Growth The story starts with the assumption that money will lose value over time. Economists use the term inflation to refer to this phenomenon. When an economy experiences inflation, the prices of things increase over time. So, the same amount of money buys less things in the future than it buys today. Most countries experience a positive rate of inflation [4].\nCountries consider this a good thing. In fact, some countries even engage in something called “Inflation Targeting” to make sure that the rate of inflation remains at a low but stable and positive level. But if countries are willing and able to influence the rate of inflation, why do they target a positive inflation rate? Why not target zero? Or better yet, why not target a negative inflation rate and let money increase in value over time, and reward people who save their money?\nDeflation is when the prices of things decrease over time. That means money becomes more valuable as time goes on. The average person might consider this a good thing. If I save up money right now and just hold on to it long enough, I’ll be able to afford that expensive home or car eventually. But this effect of delaying purchases for the future appears to have a negative effect on the overall economy. Growth slows, unemployment rises, and businesses start to shut down as demand for the things that they make decreases. Deflation also increases the risk of a deflationary spiral - in which falling demand and prices and rising unemployment becomes a runaway positive feedback loop. Many economists think that such a spiral was responsible for the Great Depression of the 1930s.\nIs inflation better? A high rate of inflation is also considered a bad thing. If inflation is too high, the value of people’s savings decreases too fast and wages do not increase fast enough. This results in people hoarding physical goods. Hyper-inflation can also lead to a runaway positive feedback loop in the opposite direction.\nAs a result, keeping the economy on track is a balancing act. Countries target an inflation rate that is in the low single digits so that there is enough of a buffer zone between the current state of the economy and deflation and use regular updates to monetary policy to prevent runaway inflation. The United States for example targets a yearly inflation rate of 2%.\nIn other words, governments give more importance to price stability than anything else. Both deflation and high rates of inflation slow down economic growth and have negative effects while low rates of inflation offer price stability and controllability.\nGiven that modern economies tend to prefer inflation and actively try to maintain it, holding on to money means that the value of your money will decrease (albeit slowly) over time in most countries in the world. So, if people want to keep their savings from losing value, they need to do something with their savings other than hiding it under their pillow.\nBank Savings Accounts One way for people to save in an inflationary economy is to use a savings account in a bank that offers to periodically pay you a certain percentage of the money as interest. This is the form of savings that most people are familiar with. Some banks offer special “fixed deposit” accounts that you can put money into and take out only after a certain amount of time. If the savings account offered by the bank has a rate of interest that exceeds or is very close to the rate of inflation then your savings will keep most of their value over time. For many people this form of saving is perfectly fine. If people choose banks that are large and reliable, the risk of losing money is very low. And as long as you live within your budget, you’ll be perfectly happy person. This style of investment is good for people who are very risk averse or for people who plan to retire soon.\nThe opportunity cost of saving money like this is of course the fact that money invested in the stock market could potentially increase in value much faster than a bank savings account will allow. For instance, the value of the stocks in Google has increased by 25% since November 2018. This beats interest rates by a large amount. But the keyword here is “potentially”. When you put money into the stock market, there is also the risk that the money can be lost - sometimes entirely. Where does this money come from and where does it go? And why do stocks offer such large potential returns? To answer these questions, I need to go into why the stock market exists in the first place.\nBusinesses Need Capital Starting and running a business is no small task. Businesses typically need large amounts of money to get started. They may need office space, they may need to build factories and make expensive prototypes to perfect their technology. Sometimes businesses decide to expand by improving their products or making entirely new ones. One way to finance these costs is to use bank loans. This is in fact what a lot of companies do. However, the amount of money that banks can loan out is limited. Companies also need to pay an interest on the loans. So, if the company is working on something that will not produce a profit for some time, the interest on their loans can accumulate quite fast.\nSomewhere along the way people had the idea to raise money from regular people instead. However, rather than having people loan the business the money, the business would offer a small chunk or a share of itself in exchange for money. Once the business becomes profitable, the person with the share would be entitled to a portion of the profits. Partial ownership also granted other benefits. The shareholder could have a say in how the company was run and help choose managers. The stock market is a place that facilitates the buying and selling of these chunks of companies (for a fee of course). The Amsterdam Stock Exchange, established in 1602 is considered the oldest such place. The price of the share of a company is determined by the forces of supply and demand. Simply put, the value of stock is what people are willing to pay for it. If people think that a stock is valuable because the the company has the potential to grow, the stock gets more expensive because the demand for the stock is higher than the supply. If people think the company has no future, the stock\u0026rsquo;s value falls as more people are trying to sell the stock, increasing its supply.\nBusinesses benefit from this because they can quickly raise money at 0% interest. As long as they don’t part with more than 50% of the company ownership, they can even retain full control over what happens in the company. Many economists think that by letting more people participate in the economy, there is more money available for people to start businesses and make things. This leads to more growth as it encourages people make more new things and the overall ‘value’ of the economy increases (because now there are more things (knowledge, services, technology) in the economy.\nMost articles I’ve read talk about how investing is important because it lets you make money compared to just holding cash. But I feel that these articles are missing the more important point that having a stock market setup as a cornerstone of the world’s economic system could be the principal reason that human civilization has seen such amazing growth in knowledge and technology. This, in my view is a far more important reason to invest and to participate in the economy than the personal goal of getting more money. The stock market appears to be set up so that participating in it offers benefits to both businesses and the investors even if they do not know and care about the meta-goal of sustained growth of human civilization.\nThe Stock Market Gains Value in the Long Run While the sustained growth of human civilization is a fine goal, the most pertinent question for the individual investor is the risk of losing their money. If I buy stocks in a certain company and it folds, I do not get most of the money back. So what\u0026rsquo;s in it for the individual investor?\nWhile single stocks can lose value over time and even drop to zero, the stock market as a whole tends to rise in value over time. Stock markets have indices that track the value of a set of stocks over time. In a pattern that has remained consistent for decades, the market as a whole tends to gain value in the long run. While economic recessions like the one that happened in 2008 can reduce the value of stocks in the short term, in the long run (over the course of tens of years), they gain in value. The graph below shows the value of the total US stock market as represented by the Wilshire 5000 Price Index over time [8].\nMany such indices in other countries show a similar trend. For individuals then, the incentive is that even by \u0026ldquo;passively\u0026rdquo; investing in the entire stock market (a facility available through something called index funds) their savings grow over time with a high probability. For companies that are listed on the stock market, the incentive is that they have access to large amounts of capital to fund their growth. Individual companies can fail and try again. While individual investors can never reduce the probability of losing all their money to 0, they can reduce it significantly by buying and holding a diverse set of stocks.\nThe Other Side of the Coin This is of course not the complete story. I’ve only mentioned the bare essentials of the system. There are other ingredients needed to ensure that the growth generated by this economic system is sustainable. One of the most obvious problems is that the shareholders of a company may only care about making money. This means that the company would try to maximise profit above all else in a way that can be harmful for humanity as a whole. Part of the reason is that economic activity generates costs apart from that of labor and raw materials. These external costs - such as the generation of planet warming greenhouse gases - means that there is a need for well desiged regulations that ‘bake in’ these external costs into the cost of running businesses. Implementing things like a carbon tax or a pollution cleanup tax will probably be necessary in the coming years to make sure that our economic activity does not mess up the planet that we live in.\nSo, with some well-planned regulations, carefully controlled inflation and thriving stock market humanity should be set for growth - at least until the next disruptor comes along. An AI singularity perhaps?\nReferences  \rWikipedia Article on Deflation \rFriedman, Benjamin M. Monetary policy. No. w8057. National Bureau of Economic Research, 2000. \rRemarks by Governor Ben S. Bernanke \rInflation Rates by Country, CIA World Factbook \rIndians have a love-hate relationship with stock markets, says CEO of Asia’s first stock exchange \rMajority of states have very few stock market investors \r1 in 3 Singaporeans does not invest, most financially unprepared for retirement: OCBC survey \rWilshire 5000 Price Index Historic Data  ","date":1574502600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574502600,"objectID":"1a4b8aedb0539ac90f304eadc459c9c1","permalink":"https://www.ashwinnarayan.com/post/investing-and-personal-finance/","publishdate":"2019-11-23T17:50:00+08:00","relpermalink":"/post/investing-and-personal-finance/","section":"post","summary":"Introduction Growing up in an Indian family, I had very little exposure to discussion and information about the stock market. People in India are generally less likely to invest in the stock market.","tags":["investing"],"title":"Investing in the Stock Market: A Scientist's View","type":"post"},{"authors":null,"categories":[],"content":"Many websites use bots to automate tasks and add useful (and sometimes harmful) functionality. For instance, there are reddit bots that can help you stabilize shaky videos, remind you of events or even vote on the usefulness of other bots. Telegram - an instant messaging service similar to WhatsApp - lets you create and manage bots on their platform using their Bot API. Bots on Telegram are officially identified and provide fun and useful services. Last month, while exploring Google Cloud Platform after getting some free student credits, I came across Google Cloud Functions. I realized that this hammer was perfect for the nail of setting up a simple Telegram bot.\nMany years ago, when Telegram\u0026rsquo;s bot API was still young, I tried to create a bot that would send you random pictures of aurorae if you asked. That bot and the server that it lived on crashed a long time ago. But the bot\u0026rsquo;s name and API key lived on, still registered with Telegram\u0026rsquo;s servers. I decided to necromance this bot from the dead and inject it with some fun new functionality. Being a lover space exploration and what it represents for humanity, I had the idea of giving the bot the ability to send you random images from NASA with informative descriptions as seen on the NASA Image and Video Library.\nUsing the NASA Images API The first problem to solve is getting a random image from the NASA Image and Video Library. At first, I thought that I\u0026rsquo;d have to use a web-scraping python library to extract the images. But things turned out to be much easier. NASA has quite a few APIs that they\u0026rsquo;ve listed on this page. Using their API, I can search through the images for any query I like and retrieve results in the form of JSON formatted data. The API uses HTTP GET requests (\rmore info here). So for example, if I need to search for images related to planets using the API, I would open the URL: https://images-api.nasa.gov/search?q=planet.\nThere\u0026rsquo;s one extra step here. If you click on the api link above and examine the results, you\u0026rsquo;ll notice that it does not return all the results of a search at once. Instead, it gives you the first 100 results and gives you the option of getting more using the \u0026lsquo;page\u0026rsquo; parameter in the web request. So if I want to access the results from the 5th page of a search, I\u0026rsquo;d use the URL: https://images-api.nasa.gov/search?q=planet\u0026amp;page=5.\nSo, to select a random result, I need to select a number between 1 and the total number of results and use modular arithmetic to figure out which page to get the result from. I encapsulated this logic in a single function that returns the URL and caption of a random result given a search query.\nimport urllib.parse\rimport urllib.request\rimport json\rimport random\rimport math\rimport traceback\rdef get_random_nasa_image(search_term='planet'):\r\u0026quot;\u0026quot;\u0026quot;\rFetch a random image from the NASA media library.\r\u0026quot;\u0026quot;\u0026quot;\rtry:\r# The API URL\rnasa_img_url = \u0026quot;https://images-api.nasa.gov/search\u0026quot;\r# Setup the search data\rsend_data = {}\rsend_data['q'] = search_term\rsend_data['media_type'] = 'image'\r# Encode the url\rurl_values = urllib.parse.urlencode(send_data)\rurl = nasa_img_url + '?' + url_values\rdata = urllib.request.urlopen(url)\rjson_data = json.loads(data.read().decode('utf-8'))\rnum_results = json_data['collection']['metadata']['total_hits']\rresult_to_use = random.choice([i for i in range(num_results)])\rpage_num = math.ceil(result_to_use/100.0)\rresult_num_in_page = result_to_use%100\rif page_num != 1:\r# Do another request\rsend_data['page'] = page_num\rurl_values = urllib.parse.urlencode(send_data)\rurl = nasa_img_url + '?' + url_values\rdata = urllib.request.urlopen(url)\rjson_data = json.loads(data.read().decode('utf-8'))\rimage_url = json_data['collection']['items'][result_num_in_page]['links'][0]['href']\rimage_caption = json_data['collection']['items'][result_num_in_page]['data'][0]['description']\rimage_title = json_data['collection']['items'][result_num_in_page]['data'][0]['title']\relse:\rimage_url = json_data['collection']['items'][result_num_in_page]['links'][0]['href']\rimage_caption = json_data['collection']['items'][result_num_in_page]['data'][0]['title']\rimage_title = json_data['collection']['items'][result_num_in_page]['data'][0]['description']\rreturn (image_url, image_title, image_caption)\rexcept Exception as e:\rtraceback.print_exc()\rerr_url = 'https://upload.wikimedia.org/wikipedia/commons/3/3b/Gato_enervado_pola_presencia_dun_can.jpg'\rerr_caption = 'Uh-Oh. Something went wrong. Here\\'s a picture of a cat instead.'\rreturn (err_url, err_caption, json_data)\r Sending the Image to Telegram To make a Telegram Bot send an image to a user we need three pieces of information.\n The Chat ID : The chat ID is like a serial number that uniquely identifies the chat between a bot and a user. The Photo : There are a few different formats that telegram accepts the photo in. I chose the simplest option, a string with the URL to the photo. The Bot API Key : This is a long random looking string that you get when you create a bot. See instructions here to learn how to get your own.  The actual sending of the message is achieved by using more HTTP GET or POST requests. In this case I used the sendPhoto function defined in the API. Again, I encapsulated the functionality to send the photo into a single function.\ndef sendPhoto(chat_id, url, caption):\rsendPhotoUrl = 'https://api.telegram.org/bot{your-api-key}/sendPhoto'\rdata = {}\rdata['chat_id'] = chat_id\rdata['photo'] = url\rdata['caption'] = caption\rdata = urllib.parse.urlencode(data)\rdata = data.encode('ascii') # data should be bytes\rreq = urllib.request.Request(sendPhotoUrl, data)\rwith urllib.request.urlopen(req, timeout=10) as response:\rthe_page = response.read()\rreturn the_page\r Setting Up a Google Cloud Function Google Cloud Functions allow you to execute a custom block of code when triggered by some kind of event - like it being a certain time of the day. Apart from Google, companies like Amazon and Microsoft also have their own versions of cloud functions.\nSince my application logic was fairly simple, I opted to setup my cloud function from their web interface by following the instructions on this page. I kept all the default settings and opted to use Python 3.7 since that\u0026rsquo;s the programming language that I\u0026rsquo;m the most familiar with. The \u0026lsquo;hello_world\u0026rsquo; function that they have setup is the function that will be called when the service is triggered.\nInside the function, I need to implement some very simple logic:\n Extract the Chat ID from the incoming message. Get a random NASA photo. Send the photo (along with its caption) to the incoming message\u0026rsquo;s Chat ID Return an HTTP OK response.  Here\u0026rsquo;s my code for the main function that\u0026rsquo;s called when an event is triggered. I\u0026rsquo;ve added some exception handling to the main logic as well.\ndef hello_world(request):\r\u0026quot;\u0026quot;\u0026quot;Responds to any HTTP request.\rArgs:\rrequest (flask.Request): HTTP request object.\rReturns:\rThe response text or any set of values that can be turned into a\rResponse object using\r`make_response \u0026lt;http://flask.pocoo.org/docs/1.0/api/#flask.Flask.make_response\u0026gt;`.\r\u0026quot;\u0026quot;\u0026quot;\rrequest_json = request.get_json()\rdoneFlag = False\rtry_counter = 0\rtry_max = 5\rwhile not doneFlag:\rtry:\r# Send back a random nasa photo\rphoto, title, caption = get_random_nasa_image()\rprint(photo)\rsendPhoto(request_json['message']['chat']['id'],\rphoto, caption)\rdoneFlag = True\rexcept:\rprint(\u0026quot;Something Went Wrong. Trying again!\u0026quot;)\rtry_counter = try_counter + 1\rif try_counter \u0026gt; 5:\rdoneFlag = True\rtraceback.print_exc()\rsendPhoto(request_json['message']['chat']['id'],\r'https://upload.wikimedia.org/wikipedia/commons/3/3b/Gato_enervado_pola_presencia_dun_can.jpg',\r'I\\'m Sorry, something went wrong. Here\\'s a cat picture instead. :P')\relse:\rpass\rprint(request_json)\rreturn f'HTTP/1.0 200 OK'\r Connecting the Telegram Bot to the Cloud Function. The final step is to connect the Telegram Bot to the Cloud Function so that the function is triggered every time the bot receives a message from someone. The Telegram API has a function for just that. setWebhook allows you to set a URL that gets called every time the bot gets a new message. All the message data is passed on in JSON format. To connect your bot to the cloud function that you just created, you need to set the webhook to the URL specified in the \u0026lsquo;Trigger\u0026rsquo; tab of the function details page.\nDemo And we\u0026rsquo;re done! If there are no errors in the code, your bot should be triggered every time it receives a message. Here\u0026rsquo;s a demo of my bot working:\nConclusion Successes like these are the reason that I sometimes revive old projects. In the years that passed between my two attempts, some technologies had become cheap enough that I could use it nearly for free. In my last attempt to build the bot, I used a custom VPS server (basically a linux server) to try and run the bot. This meant that in addition to the logic for the bot, I needed to figure out how to get the bot to run on the server reliably. I often had to go back and restart the server or the script because it had got itself into an unexpected state. For cloud functions, there is no state. Each event invokes a new call of the function and if there is an error, the next function call isn\u0026rsquo;t affected by it. I also don\u0026rsquo;t need to worry about reliability and uptime because Google manages the service. Building systems like these are a great way of learning more about the inner workings of the internet and I hope that others who want to build their own Telegram bots (or other web based things) can use this article as a starting point.\n","date":1559800755,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559800755,"objectID":"c5b9cc1ba95538092bb7224098d405bd","permalink":"https://www.ashwinnarayan.com/post/gcp-telegram-bot/","publishdate":"2019-06-06T13:59:15+08:00","relpermalink":"/post/gcp-telegram-bot/","section":"post","summary":"Many websites use bots to automate tasks and add useful (and sometimes harmful) functionality. For instance, there are reddit bots that can help you stabilize shaky videos, remind you of events or even vote on the usefulness of other bots.","tags":["programming"],"title":"Building a Simple Telegram Bot Using Google Cloud Functions","type":"post"},{"authors":null,"categories":[],"content":"Introduction As is the case for a lot of PhDs, my main work focuses on a small part of robotics. There are many areas of robotics that I would love to work on but do not. As part of my ongoing effort to learn more about these areas, I work on accessible problems that interest me. One area of robotics that fascinates me is that of rigid body dynamics and control. Regardless of how many times I see it, there is something magical about using mathematics to make correct predictions about the world. Newtonian mechanics - the science that powers most modern robots - is many hundreds of years old, but I can still feel the magic when the equations come to life.\nOne toy system that is commonly used to learn about dynamics and control theory is the cart-pole or inverted pendulum. Over the past few weeks, I\u0026rsquo;ve been working through simulating the dynamics of the system. I alse tried out some common control strategies to perform the task of balancing the pendulum with its center of mass above the joint. In this article I\u0026rsquo;ll go through the process from beginning to end. I think the cart pole system is very convenient as it is simple enough that its dynamics can be worked out by hand. Concomitantly, it is complex enough to warrant applying some advanced control strategies.\nModeling and Simulating the Cart-Pole System The diagram above (lifted from the Wikipedia article) shows what the system looks like. It is assumed that the cart is on a fixed linear rail (frictionless of course). This can be considered a prismatic joint in robotics terminology. The pendulum is mounted on the cart with a revolute joint that has a single rotational degree of freedom. There are a few ways to model the pendulum. Some model it as a uniform bar/cylinder and some as a concentrated mass at the end of a massless link. For the purposes of this article, I\u0026rsquo;ll be modeling it as a thin cylindrical rod.\nLagrangian Mechanics \rLagrangian mechanics is a fascinating and beautiful formulation of classical mechanics. Rather than the three laws of motion, Lagrangian mechanics is interested in a scalar quantity called the action which is a function of the state of the mechanical system. By applying a simple constraint known as the Principle of Least Action, you can get the equations of motion for any system in any coordinate system.\nTo apply Lagrangian Mechanics to the cart-pole system, I need to first write down the Lagrangian of the system which is defined as the difference between the potential and kinetic energies of the system as functions of the state.\nSince the cart moves perpedicular to gravity, the potential energy $V$ only depends on the vertical position of the pendulum.\n$$ V = -m_{p}gl\\cos{\\theta} $$\nThe Kinetic Energy of the system is a bit more involved. It\u0026rsquo;s the sum of the kinetic energies of the cart and the pole.\n$$ \\begin{align} T \u0026amp;= \\frac{1}{2} m_c \\dot{x}^2 + \\frac{1}{2}m_p \\left[ (\\dot{x} + l\\dot{\\theta}\\cos{\\theta})^2 + (l\\dot{\\theta} \\sin{\\theta})^2\\right] \\\\ \u0026amp;= \\frac{1}{2} (m_c + m_p) \\dot{x}^2 + \\frac{1}{2} m_p l^2 \\dot{\\theta}^2 (\\cos^2{\\theta} + \\sin^2{\\theta}) + m_p l \\dot{x}\\dot{\\theta}\\cos{\\theta} \\\\ \u0026amp;= \\frac{1}{2} (m_c + m_p) \\dot{x}^2 + \\frac{1}{2} m_p l^2 \\dot{\\theta}^2 + m_p l \\dot{x}\\dot{\\theta}\\cos{\\theta}\\end{align} $$\nThe Lagrangian is then:\n$$ \\mathcal{L} = T - V $$\nIn Lagrangian mechanics, as the system evolves over time, a quantity called action is defined as the integral of the Lagrangian.\n$$ S = \\int_{t_1}^{t_2} \\mathcal{L} dt$$\nAccording to the Principle of Least Action, the dynamics of the system evolves so that this quantity - the action - is minimized. Once I have the action I can use the Euler-Lagrange equations to find the equations of motion of the system.\n$$ \\frac{d}{dt} \\frac{\\partial \\mathcal{L}}{\\partial \\dot{q}_i} - \\frac{\\partial \\mathcal{L}}{\\partial q_i} = F_i$$\nThe $q_i$ represent the state variables of the system and $F_i$ generalized forces. By applying these equations once for each state variable I get the full equations of motion of the system. In the case of the cart pole system, the state variables are the position of the cart and the angle between the cart and the pendulum. The resulting two equations are:\n$$ \\begin{align} -m_p l \\dot{\\theta} \\sin{\\theta} + (m_c + m_p) \\ddot{x} + m_p l \\ddot{\\theta} \\cos{\\theta} = F_1 \\\\ m_p g l \\sin{\\theta} + m_p l \\ddot{x} \\cos{\\theta} + m_p l^2 \\ddot{\\theta} = F_2 \\end{align} $$\nThe central equation of study in robot dynamics are the manipulator equations. These equations are a general way to express the dynamics of a multi-link rigid body. By inspecting the equations of motion derived above, they can be expressed in the manipulator equation form:\n$$ H(q)\\ddot{q} + C(q, \\dot{q})\\dot{q} + G(q) = F $$\nWhere\n$$ H = \\begin{bmatrix} m_c + m_p \u0026amp; m_p l \\cos{\\theta} \\\\ m_p l \\cos{\\theta} \u0026amp; m_p l^2 \\end{bmatrix}$$ $$ C = \\begin{bmatrix} 0 \u0026amp; -m_p l \\dot{\\theta} \\sin{\\theta} \\\\ 0 \u0026amp; 0 \\end{bmatrix} $$ $$ G = \\begin{bmatrix} 0 \\\\ m_p g l \\sin{\\theta} \\end{bmatrix} $$ $$ q = \\begin{bmatrix} x \\\\ \\theta \\end{bmatrix} $$\nSimulating the Cart Pole System There are a few ways to simulate a mechanical system once you have the equations of motion. Python is an excellent option. The scipy package has a good set of numerical integrators. You just have to feed in the initial conditions of the system and it\u0026rsquo;ll simulate the system for as long as you want (at least, until your RAM runs out). However, for this project, I chose to use MATLAB. Mathworks decided to make the student (and personal) version of MATLAB available for ridiculously cheap prices (compared to their organizational licenses). So about a year ago I bought their student license so I could learn to use it. Everything I do in this article can be done just as well using Python and scipy. However, I do admit that using MATLAB makes the work a little smoother.\nFor simulating the cart-pole I will be using the Simscape Multibody toolbox for Simulink. Without any kind of control system active, we can see the dynamics of the free system quite nicely.\nBalancing Control The balancing control task is that of having the pendulum balance with its center of mass above the cart by only moving the cart (there is no actuator on the revolute joint). The control input in this task is a force that is applied to the cart (through electric motors or rocket engines or some other means of actuation).\nThe cart pole system is a highly non-linear system. However, just like how the motion of the simple pendulum can be approximated by a linear system for small angles, the cart pole system can be linearized too. Sometimes in engineering, the approach of \u0026ldquo;fiddling with it till it works\u0026rdquo; really works! So the first thing I tried to do is to implement a simple PD controller. If the system is linear around the balancing point (which it is in this case) and long as the states aren\u0026rsquo;t too far off, this approach will work.\nHand-Tuned Control Gains So the very first thing I tried are hand tuned control gains. I just assumed that I could achieve what I wanted by using the control signal $u = K\\cdot s$ where $s$ is the state vector with the positions and velocities: $s = \\begin{bmatrix} x \u0026amp; \\dot{x} \u0026amp; \\theta \u0026amp; \\dot{\\theta}\\end{bmatrix}^T$. After a bit (a lot) of fiddling, I did manage to find a set of control gains that worked. Here\u0026rsquo;s what the controller looks like when it tries to balance the pendulum.\nLQR To avoid wasting all that time fiddling, control engineers invented a type of controller called a Linear Quadratic Regulator. LQR controllers formalize the process of fiddling by defining a cost function on the states and control inputs. The optimal control gain vector $K$ is the vector that minimizes this cost function. LQR is fundamental enough in control theory that standard functions exist to calculate the control gains if you have the linearized system. Such functions exist in both MATLAB and scipy or specialized control libraries.\nTo do LQR, we first need to linearize the system around an \u0026ldquo;operating point\u0026rdquo;. This process can be little (but not too much) involved if you try to do it by hand so I applied liberal amounts Mathematica to help me out (you can do the same using SymPy in Python). I first expressed the equations of motion in the form $\\dot{s} = f(s, u)$. This can be done by rearranging the manipulator equations. Once you have the dynamics in this form, the linearized equations of motion can be expressed as:\n$$ \\dot{x} = A(s - s^*) + B(u - u^{ *}) $$\nWhere\n$$ A = \\frac{\\partial f}{\\partial s}\\Bigr\\rvert _{s=s^{*}} $$ $$ B = \\frac{\\partial f}{\\partial u}\\Bigr\\rvert _{u=u^{ *}} $$\nFor the cart pole system, the matrices come out as:\n$$ A = \\begin{bmatrix} 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\\\ 0 \u0026amp; \\frac{m_p g}{m_c} \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; \\frac{(m_c + m_p)g}{m_c l} \u0026amp; 0 \u0026amp; 0 \\end{bmatrix} $$\n$$ B = \\begin{bmatrix} 0 \\\\ 0 \\\\ \\frac{1}{m_c} \\\\ \\frac{1}{m_c l}\\end{bmatrix} $$\nTo compute the optimal LQR control gains, I need to define a few more matrices. As I said before, LQR finds the gain matrix $K$ that optimizes the cost function\n$$ J = \\int_0^{\\infty} (s^TQs + u^TRu + 2x^TNu) dt$$\nI need to define the matrix $Q$, $R$ and $N$. You can think of $Q$ as a matrix of weights that tell you how much to \u0026ldquo;penalize\u0026rdquo; certain combinations of the state. For instance the first term in the diagonal of the $Q$ matrix tells you how much to penalize the value of the state variable $x$. The same goes for other matrices. Having the $Q$ matrix as a scalar multiple of the identity matrix is a good default. $R$ is just a single scalar value. $N$ can be skipped in most cases. With these I got a control gain matrix that also successfully drove the states to my target. It looked quite similar to my hand tuned control gains actually. On close inspection you can see that the system does reach it\u0026rsquo;s target slightly faster.\nConclusion Dynamics is an important part of a roboticist\u0026rsquo;s toolkit. Learning dynamics from a textbook can be a bit daunting. For me, implementing the ideas in code and generating nice animations helps me to get a better intuition of the mathematics. Now that I have the environment set up, I\u0026rsquo;m considering trying my hand at some swing-up control using energy shaping methods or reinforcement learning.\nReferences  \rAcrobot and Cartpole, Russ Tedrake 2009 \rMATLAB\u0026rsquo;s LQR Design Function \rEuler-Lagrange Equation  ","date":1555808204,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555808204,"objectID":"d66c74508d05f6b6825017d16b512d30","permalink":"https://www.ashwinnarayan.com/post/cartpole-dynamics/","publishdate":"2019-04-21T08:56:44+08:00","relpermalink":"/post/cartpole-dynamics/","section":"post","summary":"Introduction As is the case for a lot of PhDs, my main work focuses on a small part of robotics. There are many areas of robotics that I would love to work on but do not.","tags":["robotics","mathematics"],"title":"Cartpole Dynamics and Control","type":"post"},{"authors":null,"categories":[],"content":"Introduction Over the last year or so, I\u0026rsquo;ve been playing around with functional programming. As the first few lines of the Wikipedia page suggest, functional programming is all about expressing a computation or algorithm as the composition of functions rather than using a state that changes over time. From what I\u0026rsquo;ve understood so far, functional programming is based on lambda calculus which is an alternative but equivalent formulation of the famous Turing Machine that most modern computers are based on.\nOnce you start reading up on functional programming, the language that is most often recommended is Haskell. I got interested in functional programming and Haskell in the first place because I was attracted by its more mathematical appearance. A lot of the code that I looked at seemed to express ideas much more clearly and (in my opinion) more beautifully. However, Learning Haskell was not easy at all. As someone who\u0026rsquo;s been programming using imperative languages all my life, I found it unusually difficult to think about solving problems using the style that Haskell (and functional programming) imposed. Near the beginning of my journey to learn the language, there were quite a lot of stops and restarts and many instances where I questioned whether it was even useful to learn the language. I found it so difficult to express ideas that were, in my head simple to express in a language like Python. I also found writing programs that required I/O quite difficult. However, the aforementioned clarity and beauty that I found in the way functional programming expressed ideas stuck with me and I kept coming back to it. after nearly a year, things fell into place and I started writing code that was actually useful (i.e. interacted with the world through I/O). I feel like I\u0026rsquo;m finally at a point where I can program well enough in the language that I can solve problems without struggling too much with I/O. So, when I got the email notifying me about this year\u0026rsquo;s Google Code Jam I thought I\u0026rsquo;d participate and try to use Haskell as much as possible!\nGoogle Code Jam I\u0026rsquo;ve known about Google Code Jam for quite a while. I\u0026rsquo;ve even tried participating once before near the beginning of my undergraduate degree. Being a novice at the time, I did not even make it past the qualifying round. Since then I\u0026rsquo;ve been programming on a regular basis for nearly six years and it\u0026rsquo;s paid off. This time, I made it past the qualifying round quite comfortably. The main challenge before me was my use of a programming language that I hadn\u0026rsquo;t fully mastered yet. The added challlenge did make solving the problems a lot more fun however. Along the way, I was able to take advantage of some functional programming patterns and I thought that it might be valuable to write an article about how these patterns can be useful.\nProblem 1 - Foregone Solution To read the full problem description go here.\nSummary of Problem Statement The input for each testcase is a number N which when expressed in base 10 may or may not contain the digit 4. The goal is to split up the number N into 2 numbers A and B so that A + B = N and neither A nor B contain the digit 4.\nAnalysis A brute force approach to the solution would search through all possible sums of two integers between 0 and N/2. Of course, this solution would scale as $O(N^2)$ and would not work with the larger test cases. Another thing to think about is that the hidden test cases can contain numbers between 1 and $10^{100}$. That number is beyond the range of usual integer data types. The problem can be solved quite easily by making the simple observation that you can split up all the digits that are 4 into 2 and 2 (or 3 and 1) and easily generate two numbers without even adding the two numbers to check if they sum up to N. For instance, if N is 9454 you can split it up into 9252 and 202. To do this you do not even need to convert the number into an integer data type. You can work with the string representation directly.\nSolution I will read each test case number as a string and create two new numbers A and B. A will have all the digits 4 replaced with 2 and the remaining digits the same. B Will have all the digits 4 replaced with 2 and all the remaining digits replaced with 0. This pattern of replacing each member of an array with another one using information from only a single array element can be implemented using the higher order function map. So, I defined two functions to calculate A and B.\ngetA :: [Char] -\u0026gt; [Char]\rgetA n = map (\\x -\u0026gt; if x == '4' then '2' else '0') n\rgetB :: [Char] -\u0026gt; [Char]\rgetB n = map (\\x -\u0026gt; if x == '4' then '2' else x) n\r The rest of the solution is just I/O. You can see my full solution here.\nProblem 2: You Can Go Your Own Way To read the full problem description go here.\nSummary of the Problem Statement The goal is to get from the top right corner of an NxN grid to the bottom right corner using only South (Down) and East (Right) moves with the additional constraint that any segment of the path taken must not coincide (but can intersect at a single point) with another path that someone called Lydia took. The input is this path which is represented as a string containing uppercase \u0026ldquo;S\u0026rdquo; and \u0026ldquo;E\u0026rdquo; characters only.\nAnalysis This problem looks more difficult to solve than it actually is. Once you know the trick, the code is quite simple. Here are some observations about the problem which helped me arrive at the solution.\n Observation 1: Number of S moves and E moves must be exactly equal to N-1 if you want to reach the bottom right corner. You can see this by thinking of each move as a vector. This implies that it might be possible to find the solution by just transforming the input string as it is read. Observation 2: If I have a function that only stays the same or decreases along the X-axis and intersects the point (0, 0), I can mirror the function along the line y=-x and the only places where the path intersects will be crossings. That means I can solve this by just doing the opposite of whatever Lydia does at each step.  This means that I can take Lydia\u0026rsquo;s path and reverse the action she took at each step like some dark mirror and I have my solution. Interestingly, this problem can also be solved using the \u0026ldquo;map\u0026rdquo; higher order function pattern in Haskell. The meat of my solution was implemented in two functions. One is the character (move) mapping function:\nflipMove :: Char -\u0026gt; Char\rflipMove c\r| c == 'S' = 'E'\r| c == 'E' = 'S'\r| otherwise = c\r And another is the function that transforms the input string into the output string.\nsolveCase :: String -\u0026gt; String\rsolveCase lydiasMoves = map flipMove lydiasMoves\r As before, the rest of the code is just IO. My full solution is here.\nProblem 3: Cryptopangrams This problem was a bit harder than the others. I spent a lot of time thinking about this one and solved it quite close to the end of the round. Some of my initial attempts failed because I didn\u0026rsquo;t consider all the edge cases. Read the full problem statement here.\nSummary of Problem Statement A string is \u0026ldquo;encoded\u0026rdquo; using the following procedure:\n 26 prime numbers less than a number N are chosen. The numbers are sorted in increasing order and a character map is made from the numbers to the corresponding letter between A and Z. Each character in the sentence is replaced with the corresponding prime number (spaces are removed and ignored). The prime number at each position is replaced with the product of the number and the number corresponding to the next character in the sentence.  As an additional condition, the string is guaranteed to have all 26 characters occur at least once.\nFor each case, as input, the maximum number N and the encoded sentence is given. The output should be the decoded sentence (without spaces).\nAnalysis Let each sentence that is encoded be made of L characters. The set of primes that represent each of these characters can be represented by the sequence of numbers: $\\{P_1, P_2, \u0026hellip; , P_L\\}$. After the \u0026ldquo;encoding\u0026rdquo; procedure is carried out, the sequence will look like: $\\{P_1\\times P_2, P_2\\times P_3, \u0026hellip; , P_{L-1}\\times P_{L}\\}$. The brute-force approach to solve this problem would involve trying to find the prime factors of each number in the sequence. However, if you look at the sequence above you can see that each number in the sequence except for the first one shares a common factor with the number before it! This means that if I find the common factors of the first two numbers in the sequence then I can factorize the entire sequence quite easily using the following procedure:\n Find the common factor between the first two numbers in the sequence. Divide the first number by this common factor to get the first factor. Second factor is the common factor. For all subsequent numbers, the first factor is the common factor with the previous number and the second factor is the number divided by the common factor.  Solution So first, I wrote a function to find the greatest common divisor between two numbers. This function implements Euclid\u0026rsquo;s Algorithm for find the greatest common divisor of two numbers:\ncommonFactor :: Integer -\u0026gt; Integer -\u0026gt; Integer\rcommonFactor a b\r| remainder == 1 = 1\r| remainder == 0 = if a \u0026gt; b then b else a\r| otherwise = if a \u0026gt; b then commonFactor b remainder else commonFactor a remainder where remainder = if a \u0026gt; b then snd (quotRem a b) else snd (quotRem b a)\r In an imperative programming language we would loop through each character in the sequence to find the factors after setting up the loop by finding the common factor between the first two numbers. In Haskell the loop pattern for solving this particular problem is captured quite beautifully using the higher order function scanl. The type signature for scanl is (b -\u0026gt; a -\u0026gt; b) -\u0026gt; b -\u0026gt; [a] -\u0026gt; [b]. This means that scanl takes a function that takes a type a and b and returns a b, a member of type b and a list of type a and returns a list of type b.\nA scanl is a higher order function that is a variant of a general pattern in computing called a fold. To put it very simply, a fold takes a starting value (sometimes called a seed), a function and a list and applies the function repeatedly in a specific way. If I write down the fold imperatively in a language like Python, it would look like this (f is the function that is applied recursively):\nseed = 0\rfor idx, elem in enumerate(lst):\rif idx == 0:\rresult = f(seed, elem)\relse:\rresult = f(result, elem)\r A fold will run this loop and return the final value of the result in the computation. A scan is just a fold that returns a list of the intermediate values at each iteration in the loop. Haskell has two scan functions that work on lists: scanl and scanr. scanl starts the iteration from the left side of the list and scanr starts the iteration from the right side of the list.\nWith this in mind, I wrote a scanl based function to factorize the list of input numbers.\nfactorizeCiphertext :: [Integer] -\u0026gt; [Integer]\rfactorizeCiphertext lst@(x1:x2:nums) = scanl (\\n1 n2 -\u0026gt; n2 `div` n1) firstFactor lst\rwhere firstFactor = x1 `div` (commonFactor x1 x2)\r In my first attempt at solving the problem, I thought that this was the full solution. But I kept getting runtime errors once I uploaded the answer to the website. After thinking about the problem for a little bit I realized that I\u0026rsquo;d missed out on some edge cases. There are two ways in which this solution can fail.\n If there are consecutive numbers that are identical at the start of the sequence. The common factor algorithm will return the number itself. Consecutive identical numbers can be caused by either repeated characters (\u0026ldquo;AAAAAA\u0026rdquo;) or by repeated alternating characters (\u0026ldquo;ABABABA\u0026rdquo;) in the plain text. If there are multiple but different consecutive numbers at the start of the sequence. For instance, if the cipher text starts like [9, 9, 9, 15, 15, 15, 35, 217].  Note that if repeated characters appear in the middle of the sequence, it does not matter since the procedure we use will divide this number by the previous factor anyway. To handle this edge case, we\u0026rsquo;ll need to extract any successive repeated numbers from the start of the sequence. So I wrote two functions to split the input list into two lists. One contains any repeated characters at the start of the list and the other is the rest of the list.\ngroupHead :: [Integer] -\u0026gt; [Integer]\rgroupHead (x:xs)\r| x == (head xs) = [x] ++ (takeWhile (==x) xs) ++ groupHead (dropWhile (==x) xs)\r| otherwise = []\rgroupTail :: [Integer] -\u0026gt; [Integer]\rgroupTail (x:xs)\r| x == (head xs) = groupTail (dropWhile (==x) xs)\r| otherwise = [x] ++ xs\r For the rest of the list that does not have any initial repeating characters, the original factorizeCiphertext function can be used to factorize the list. But how do we factorize the first part of the list? After a bit of thought I realized that if we factorize the first number in the second part of the list, it must have a common factor with the last number in the first part of the list. So now I can use this as the first factor to scan the list from the right!\nSo the final function that accounts for the edge cases is:\nfactorizeCiphertext4 :: [Integer] -\u0026gt; [Integer]\rfactorizeCiphertext4 (n:nums)\r| isEdge = (scanr (\\n1 n2 -\u0026gt; n1 `div` n2) (head factorTail) groupHeads) ++ (tail factorTail)\r| otherwise = factorTail\rwhere groupHeads = groupHead ([n] ++ nums)\risEdge = if (length groupHeads) \u0026gt; 0 then True else False\rlistToScan = groupTail ([n] ++ nums)\rfirstFactor = (head listToScan) `div` (commonFactor (head listToScan) (head $ tail listToScan))\rfactorTail = scanl (\\f n -\u0026gt; n `div` f) firstFactor listToScan\r You can view my full solution to the problem here.\nConclusion Haskell is a difficult language to learn, especially if you\u0026rsquo;ve only been exposed to imperative languages all your life. Rather than thinking in terms of discrete steps, you have to force yourself to think in terms of recursion and higher order patterns in the problem. However, if you stick with it for that initial amount of time that it takes to develop some basic proficiency, the results can be very rewarding. You can write some beautiful code in this language. After learning Haskell, I\u0026rsquo;ve also found myself using a functional approach to solve programming problems in other languages too! For instance, I\u0026rsquo;ve started using Python\u0026rsquo;s iterools package much more often.\nHowever, usefulness wasn\u0026rsquo;t the main factor that motivated me to learn Haskell. For me it was more about the fun of solving puzzles in clever and aesthetically pleasing ways. Haskell is one of the few languages that puts some fun back into solving programming problems. I think it brings in some of the beauty and rigor traditionally associated with pure mathematics into a programming language. If you\u0026rsquo;re someone who enjoys programming puzzles for their own sake and finds beauty in clever solutions to puzzles, I highly recommend giving Haskell a go.\n","date":1555115194,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555115194,"objectID":"911fcaeca997641cd867fd68f998f88a","permalink":"https://www.ashwinnarayan.com/post/learning-haskell-google-code-jam/","publishdate":"2019-04-13T08:26:34+08:00","relpermalink":"/post/learning-haskell-google-code-jam/","section":"post","summary":"Introduction Over the last year or so, I\u0026rsquo;ve been playing around with functional programming. As the first few lines of the Wikipedia page suggest, functional programming is all about expressing a computation or algorithm as the composition of functions rather than using a state that changes over time.","tags":["programming"],"title":"Learning Haskell Through Google Code Jam","type":"post"},{"authors":null,"categories":[],"content":"The Witcher 3 follows the story of Geralt of Rivia, a Witcher or monster slayer in search of his adoptive daugter Cirllia. (well it\u0026rsquo;s not his story but we see the story through his eyes!). Set in a medieval world - after an event called the conjunction of spheres - magic and monsters (werewolves, spectres, vampire and the like.) roam the world. Witchers are magically and genetically enhanced humans that were created intentionally by sorcerers to help fight off these monsters. Cirilla (or Ciri) is a woman with special magical abilities and is prophesied to play a part in the fate of Geralt\u0026rsquo;s (and others) world(s) which are facing doom from a world ending White Frost.\nI purchased the game almost a year ago in December 2017 after getting strong recommendations from my friends. I\u0026rsquo;ll admit that I was a little intimidated at first. It was the third game in the series and it appeared as though I had a lot of catching up to do. I needn\u0026rsquo;t have worried too much though. One of the main features of the game are the huge number of random books lying around the world. You pick them up and they often contain bits and pieces of the story of the Witcher universe. However, one thing that was definitely intimidating was the combat mechanics. There were swords (two of them!), spells (signs), potions, decoctions, oils, bombs and crossbows all bound to correspondingly wide array of keys. Although the combat mechanics tutorial at the start of the game explained most things, it\u0026rsquo;s a lot to remember. I took a short break from playing the game for a few months in between and when I came back, I\u0026rsquo;d forgotten all the keybindings and had to play through the initial combat mechanics tutorial again to get used to things. Funnily enough although I preferred playing video games with a keyboard and mouse for the increased maneuverability, I think using a controller might be slightly easier for the Witcher 3 since you don\u0026rsquo;t have to keep track of random alphabets on the keyboard.\nThe high level of immersion is what I enjoyed the most about the game. As a person that likes a bit of realism in games, I like it when the game mechanics do not break immersion. This is something I felt while playing To the Moon (brilliant game!). A lot of the progress in the game was made through solving what felt like very artificial puzzles (tile flipping jigsaws?). So it felt like alternating between experiencing the story and playing minigames. The Witcher has a ton of game mechanics but they\u0026rsquo;re all integrated into the story in a very natural way. Progress in the game is made through talking, interacting with objects and fighting. The fighting is quite realistic too. If I\u0026rsquo;m fighting a group of people they all come at me at once and I have dodge and roll between them to make sure that I don\u0026rsquo;t get hit from behind while fighting one person. Additionally, there\u0026rsquo;s no Pokemon like battle animation that signals the start of a battle. One second you\u0026rsquo;re walking along, minding your own stuff and the next second a drowner\u0026rsquo;s taking a swipe at you.\nThe incredibly open world nature of the game is the second factor that adds to the realism and immersiveness. You can go almost anywhere on the absolutely huge map. There are practically no invisible walls that you can run into and obstacles that cannot be jumped over are at a realistic height most of the time. If you step off a cliff, you fall and if the fall is too great, you lose health and possibly die. The only invisible walls I\u0026rsquo;ve ever encountered are when you wander off to the edge of the map.\nThe third factor that adds to the immersiveness of the game is the map itself. The world of Witcher 3 is incredibly detailed. The cities like Oxenfurt and Novigrad feel like real full scale big cities. Although they are scaled down versions of the cities mentioned in the books, they\u0026rsquo;re still the biggest I\u0026rsquo;ve encountered in a video game. It was not like Pokemon where a \u0026ldquo;city\u0026rdquo; can be 4 buildings of which one is a Pokemon Center and another a Pokemart. I loved roaming around Novigrad (despite the nutjobs that are trying to burn witches alive). My favorite part of the city is probably the market square. I like how I can hear the chaotic sounds of a marketplace start up as you walk towards it. Outside the cities there are forests, snowy mountains, small villages, beaches and swamps all beatifully built and rendered in a very non-repetitive and organic way. The scenery never felt boring. It felt like nearly everything was placed and adjusted by hand. I was amazed in particular by the fantastical environments I encountered while traveling through the many parallel universes. The use of parallel universes in the game itself was quite a novel idea! I never thought that a game set in the medieval era would involve parallel universes and time travel. I saw worlds that were just deserts, worlds covered in frost, worlds with toxic gases and colorful plants. Even the modern day world (ours!) and possibly the world of Cyberpunk 2077 (another upcoming game by them) was mentioned in passing.\nDespite logging over 100 hours in the game over the past year, I have yet to finish all the quests in the game. I\u0026rsquo;ve completed the main story of the game but I\u0026rsquo;ve still got dozens of Witcher contracts and a few secondary quests left to finish off. On top of all that I have yet to start on the Hearts of Stone and Blood and Wine expansions of the game - which I hear are basically like two new games; adding 10 and 20 hours of playtime respectively. Looking at the scale of the game, I was quite surprised to learn that the game only took 3.5 years and 81 million USD to make (I was expecting a lot more!). The Witcher 3 is an RPG. So as expected the choices you make during quests play a part in the outcome of the game. Some decisions are clearly good/bad but in some quests all the choices are bad but you still have to choose.\nMy only big criticism of the game is related to the combat difficulty near the start of the game. I\u0026rsquo;m not a gamer that plays games in hard mode. I play video games mainly to experience the story. So I tend to choose the lowest difficulty setting the game has. But even at the lowest difficulty, I had some trouble staying alive during some of the quests at the start of the game. I also had trouble with getting enough gold to buy things as I was spending most of my money keeping my equipment repaired (weapons and armor degrade as you use them). The problem was not too bad though and vanished as soon as I got out of White Orchard; character leveling happened much faster and I started getting gold quite a bit faster.\nI really enjoy playing story rich games like the Witcher 3. I feel like that is a very natural next step in the very human tradition of storytelling. We had spoken stories, then written, then acted out (movies). Interactive stories where the person experiences the story through his own actions is a very natural next step. In this regard, The Witcher stands out as the best game I\u0026rsquo;ve ever played. It manages to immerse me in the universe of Witcher 3 and feel like I\u0026rsquo;m really there. Every time I played the game, for a brief period of time I really was Geralt of Rivia. I felt what he felt, I did what he did. And in the end I felt like it had just as much (if not more) emotional impact as watching the story unfold in a movie or a book with the added advantage of being able to drive the story on my own rather than passively watch a film.\n","date":1537031446,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537031446,"objectID":"cc8261d19f5d7c54d4a8df7653cff455","permalink":"https://www.ashwinnarayan.com/post/witcher-3-review/","publishdate":"2018-09-16T01:10:46+08:00","relpermalink":"/post/witcher-3-review/","section":"post","summary":"The Witcher 3 follows the story of Geralt of Rivia, a Witcher or monster slayer in search of his adoptive daugter Cirllia. (well it\u0026rsquo;s not his story but we see the story through his eyes!","tags":["gaming","thoughts"],"title":"The Witcher 3: Wild Hunt - A Review","type":"post"},{"authors":null,"categories":[],"content":"As I mentioned in my first article on this blog, I\u0026rsquo;m now using Hugo, the static site generator to build my personal website. Due to the needs of my work environment (mostly because I need to use MS Word and certain MATLAB features on a regular basis), I\u0026rsquo;ve been primarily using Windows as my operating system for the past year or so. Having used Linux for a long time, I definitely missed the conveniences offered by shell scripting and other command line tools. However, while setting up a workflow in Windows for publishing content to my website I discovered that Windows\u0026rsquo; scripting tools are not all that bad. In fact, for anyone familiar with scripting from Linux, moving to Powershell isn\u0026rsquo;t that hard.\nWorkflow A typical Hugo website development folder looks like this: I add new posts by creating new markown (.md) files in the post folder. When the website is compiled using the hugo command, the static website\u0026rsquo;s code is generated into the public folder. The content inside this is what goes into the folder that is served by any webserver. Since I am hosting the website on Github Pages, I found it most convenient to set up a separate folder with a clone of the username.githug.io repository. After article writing/editing is done, I can generate the website and copy the contents inside the public folder to the repository folder to publish.\nWhen I am editing an article, I can preview content locally by using the hugo server --watch command in the top level directory. This sets up a local webserver on localhost:1313 so that you can preview the website.\nTo publish my website to Github pages after I\u0026rsquo;m done with development, I copy everything inside the public folder into my local copy of the github repository and then commit all and push.\nBatch Script Automation Most of the the steps in the workflow can be automated away using batch scripts to save large amounts of time. I mean, who wants to spend time manually copying files and commiting after every small edit to the website? The build_on_laptop.bat file in the top level directory handles everything. Diving into the source, I first delete everything inside the public folder (Hugo does not automatically do this) and build a fresh version of the website.\nrmdir /S /Q public\rhugo\r My Github pages repo has a few files that are not generated by Hugo. So I can\u0026rsquo;t just nuke the folder and delete everything. So I have a set of commands that delete all the Hugo generated files in the repository folder:\nrmdir /S /Q \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\categories\u0026quot;\rrmdir /S /Q \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\css\u0026quot;\rrmdir /S /Q \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\fonts\u0026quot;\rrmdir /S /Q \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\home\u0026quot;\rrmdir /S /Q \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\img\u0026quot;\rrmdir /S /Q \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\js\u0026quot;\rrmdir /S /Q \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\post\u0026quot;\rrmdir /S /Q \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\project\u0026quot;\rrmdir /S /Q \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\publication\u0026quot;\rrmdir /S /Q \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\publication_types\u0026quot;\rrmdir /S /Q \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\tags\u0026quot;\rrmdir /S /Q \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\talk\u0026quot;\rdel \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\404.html\u0026quot;\rdel \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\index.html\u0026quot;\rdel \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\index.xml\u0026quot;\rdel \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\sitemap.xml\u0026quot;\rdel \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\site.webmanifest\u0026quot;\rdel \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\styles.css\u0026quot;\r Then comes the task of copying your updated website source into the folder. While it\u0026rsquo;s possible to use the cp command, I found that the robocopy command is in general much better for copying files around in Windows.\nrobocopy public \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\u0026quot; /E\r Finally, I need to commit the new version of the website and push to github. This is also easily done:\ncd \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\u0026quot;\rset /p commitmsg=\u0026quot;Enter a commit message: \u0026quot;\rgit add --all .\rgit commit -m \u0026quot;%commitmsg%\u0026quot;\rgit push origin master\r So the end result is that when I run this script, it automatically deletes everything in the public folder and the repository folder, rebuilds and copies the new website over and then commits and pushes the new version to github to deploy the website.\nEven More Automation with Visual Studio Code I can shave even more time off the workflow by using Visual Studio Code. VS Code has a really well made task management system. It\u0026rsquo;s also a natural choice since I do most of my markdown editing inside VS Code anyway. VS Code has a tasks.json file where you can bind custom tasks/commands to key combinations. In this case, I just bound the default build task mapped to Ctrl+Alt+B to the batch script. I also created a compose task which creates the local preview webserver.\n{\r// See https://go.microsoft.com/fwlink/?LinkId=733558\r// for the documentation about the tasks.json format\r\u0026quot;version\u0026quot;: \u0026quot;0.1.0\u0026quot;,\r\u0026quot;tasks\u0026quot;: [\r{\r\u0026quot;taskName\u0026quot;: \u0026quot;build\u0026quot;,\r\u0026quot;command\u0026quot;: \u0026quot;build_on_laptop.bat\u0026quot;,\r\u0026quot;isShellCommand\u0026quot;: true,\r\u0026quot;showOutput\u0026quot;: \u0026quot;always\u0026quot;,\r\u0026quot;echoCommand\u0026quot;: true\r},\r{\r\u0026quot;taskName\u0026quot;: \u0026quot;compose\u0026quot;,\r\u0026quot;command\u0026quot;: \u0026quot;hugo\u0026quot;,\r\u0026quot;args\u0026quot;: [\u0026quot;server\u0026quot;, \u0026quot;--watch\u0026quot;],\r\u0026quot;isShellCommand\u0026quot;: true,\r\u0026quot;showOutput\u0026quot;: \u0026quot;always\u0026quot;,\r\u0026quot;echoCommand\u0026quot;: true\r}\r] }\r With most of the steps automated, writing and publishing new articles don\u0026rsquo;t take that long compared to off the shelf solutions like Wordpress or Medium. It also comes with the advantage that you have full control over the website\u0026rsquo;s source code.\n","date":1514700691,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514700691,"objectID":"19fa3fa22d83f5ffc4b26664f3a378bd","permalink":"https://www.ashwinnarayan.com/post/hugo-windows-workflow/","publishdate":"2017-12-31T11:41:31+05:30","relpermalink":"/post/hugo-windows-workflow/","section":"post","summary":"As I mentioned in my first article on this blog, I\u0026rsquo;m now using Hugo, the static site generator to build my personal website. Due to the needs of my work environment (mostly because I need to use MS Word and certain MATLAB features on a regular basis), I\u0026rsquo;ve been primarily using Windows as my operating system for the past year or so.","tags":["programming","windows","batch"],"title":"Hugo Web Development Workflow on Windows","type":"post"},{"authors":null,"categories":null,"content":"\rThis article contains spoilers for all the episodes of Star Trek: Discovery.\r\r\rAs a lover of good science fiction I was really happy to hear the announcement of Star Trek: Discovery. I have not watched all of old Star Trek. But from the few that I have watched (Mostly Star Trek: Then Next Generation), I have come to love the Trek universe and the way it handles science fiction. I feel that of late, science fiction is leaning too much towards dystopian themes. I like the occasional story about a world in nuclear winter but I like optimistic or neutral science fiction far more. It appeals to the part of me that gets excited about science and my penchant for the cool technologies and knowledge that it generates. So stories like Contact and Rendezvous with Rama is much more up my alley. I consider even movies like Interstellar as optimistic science fiction since even though the premise is that the earth is becoming uninhabitable, the story is that we work together to build the technology to colonize the stars. I consider Her science fiction although the focus of the movie was the relationship between Theodore and Samantha. The movie portrayed beautiful cityscapes and a future which looked distinctly post-scarcity as the characters seemed to not have to worry about basic needs and could live comfortably while doing basically whatever they wanted. In the case of Star Trek (at least for Star Trek: TnG) the episodes that I\u0026rsquo;ve watched so far fall under very optimistic science fiction.\nOne of my biggest fears about Star Trek: Discovery was that it would devolve into an action flick - especially because of the way the trailer was cut. It seemed to focus more on the action and less on the discovery/science/exploration part while also making the whole thing look like yet another dystopian sci-fi series. I felt that first two episodes seemed to run with this theme so much that they turned me away from the series initially and I took a break from it for nearly a month. But I came back to it one weekend when I was bored - and I\u0026rsquo;m glad I did. The episodes got better and so did the themes in them. While there was still an appreciable amount of action, they did not ignore the exploration and discovery part of things and. I also like that they specifically included characters whose biggest motivation was scientific curiosity. Here are some parts of the show that I particularly enjoyed:\n1. The Warp Capable Tardigrade Basing the strange creature on the real world tardigrade was a really cool idea. Apart from the fact that the creature looked really cool, I like that they treated it with kindness (at least in the case of Burnham) and let it go at the end.\n2. The Mycelial Network and The Spore Drive I was nerding out when the show started talking about a giant fungus spanning the entire universe because it\u0026rsquo;s actually based on an amazing real world fungus called the Armillaria ostoyae which is often reported as one of the largest living organisms in the world. There\u0026rsquo;s a single fungal colony of this type in the Malheur National Forest in the Blue Mountains of eastern Oregon, U.S, spanning 8.9 square kilometers. It\u0026rsquo;s estimated to be 2400 years old. The spore drive animations are amazing and it\u0026rsquo;s a creative plot device too.\n3. The Imperfect Captain In the older Star Treks, I felt that the captains tended to be very \u0026ldquo;perfect\u0026rdquo; characters (Kirk, Picard). They tended to be the kind of characters that are obviously good. However, the captain of the U.S.S Discovery is quite a bit less than perfect. In fact, he does quite a lot of things that are decidedly in the gray zone. In fact, the way he was introduced in the series is very similar to how villians are sometimes introduced in films. This gave me an initial sense of apprehension about the character - I got a fleeting sense that this dude is a bit evil and might not up to any good. In fact, I spent most of the episodes expecting something sinister to happen and for Lorca to pull an Admiral Marcus (Into Darkness) and reveal that he is in fact on the dark side of the force. But that never happened. Now I feel like he is a good captain who just has some unusual interest in war and does the odd unethical thing to get what he wants. Whatever the case, he added a lot of interest and depth to the new Star Trek and I like that he was not the same type of Captain as Kirk or Picard. In fact, I thought that Gabriel Lorca was a more interesting character than Michael Burnham (who I feel the showrunners are trying to make the main character.).\nSumming Up I feel that Star Trek: Discovery was well executed. While it is not exactly the same as the original Star Treks, I feel that the parts that were changed added more to the story than it took away. I like the mid season \u0026ldquo;finale\u0026rdquo; in which the crew of the Discovery were stranded in what seemed to be an alternate dimension. It is reminiscent of the TNG episode \u0026ldquo;Where No One Has Gone Before\u0026rdquo; in which the crew does some crazy new warp technique to go to the edge of the known universe. I look forward to seeing release of rest of the season next year. I\u0026rsquo;m curious to find out how they will handle the parallel universes thing.\n","date":1512919608,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512919608,"objectID":"774567422dd09e5e8bcc61e3f0e3ffb4","permalink":"https://www.ashwinnarayan.com/post/star-trek-discovery/","publishdate":"2017-12-10T23:26:48+08:00","relpermalink":"/post/star-trek-discovery/","section":"post","summary":"This article contains spoilers for all the episodes of Star Trek: Discovery.\r\r\rAs a lover of good science fiction I was really happy to hear the announcement of Star Trek: Discovery.","tags":["movie review","miscellaneous"],"title":"My Review of Star Trek: Discovery","type":"post"},{"authors":[],"categories":[],"content":"I\u0026rsquo;ve been spending a lot of time working with inertial measurement units recently and am discovering the surprising amount of mathematics that goes into using data from accelerometers and gyroscopes to get the orientation of an object in 3D space. The story begins with me trying to integrate an angular velocity vector (in 3D) to get the orientation of an object. Angular velocity is a vector but common representations of orientation (like Euler Angles) are not. So getting the orientation is not as simple as doing $\\int_0^t \\vec{\\omega} \\mathscr{d}t$.\nRotations in two dimensions are really easy because there is only one plane in which you can do the rotation. The only thing you can change is the center of rotation. The orientation of an object in 2 dimensions can be given by a single angle $\\phi$ measured relative to the origin of the coordinate system. The angular velocity of an object in 2 dimensions can also be represented by a single number $\\omega$ which is defined as the rate of change of the angle $\\phi$. This gives us the basic formula we learn in high school physics. $$\\omega = \\frac{d\\phi}{dt} = \\frac{v_{\\bot}}{r}$$ Rotations in 3D are much more complicated. In 3 dimensions, the plane of rotation can be any among an infinite number of possibilities. The origin or \u0026ldquo;center\u0026rdquo; of rotation now becomes an axis of rotation which is represented by a vector. The plane of rotation is perpendicular to the axis of rotation. This is a result of the Euler Rotation Theorem\nBefore I can start integrating angular velocity I need to choose a representation for the orientation. There are several different conventions when it comes to representing the orientation of an object in 3D. The most popular approach is to use a set of three angles called Euler Angles. This approach was developed by the mathematician Leonhard Euler (pronounced oy-ler not you-ler). These set of three angles specify three successive rotations around three different axes in a very specific order. The order is important because rotations in 3D have an important property: they do not commute. This means that if I do rotation 1 before 2 I end up with a different orientation than if I do 2 before 1. Euler angles usually specify rotations in the ZXZ order. This means that the first axis of rotation is the current Z-axis. The second axis of rotation is the new X-axis after the first rotation. The final axis of rotation is the new Z-axis after the first and second rotations. A closely related approach is to use what\u0026rsquo;s called Tait-Bryan angles. Tait-Bryan angles are called yaw, pitch and roll and are commonly used when talking about the orientation of aircraft. The angles represent successive rotations around the body fixed X, Y and Z axes. Both Euler angles and Tait-Bryan angles however, suffer from something called Gimbal Lock. This is when for a certain value of one of the rotation angles, a degree of freedom is lost and two rotations \u0026ldquo;collapse\u0026rdquo; into a single rotation. The Wikipedia page linked has some nice visualizations and a short mathematical explanation (using rotation matrices) for why this happens.\nUsing Quaternions to represent rotations is a way to avoid the Gimbal Lock problem. Quaternions are so useful for representing orientations that most Kalman Filters that need to track 3D orientations use them instead of Euler Angles. So I settled on using quaternions. When I first started working with quaternions I found them a little difficult to understand. So I thought of writing an article about the path I took to understand and use quaternions for \u0026ldquo;integrating\u0026rdquo; angular velocity.\nFrom all my time working with mathematics, I\u0026rsquo;ve come to realize that mathematical ideas exist on a spectrum. At one end is math that is focused on the practical application. Math that is very close to the real world (as experienced by humans) and can be understood easily by making analogies to things that humans encounter in everyday life. This is the type of math that is often applied to solve everyday problems like settling bills or building bridges. At the other end of the spectrum is the type of math that is pure abstraction. This type of abstract math is often used to generalize specific results in practical math to other problems or to come up with new insights that can pave the way for new solutions to a problem. Quaternions are a little more towards the abstract end of the spectrum and can be difficult to get an intuition for. Sometimes though there are ideas that you can\u0026rsquo;t get an intuition for. Working with such math is mostly a matter of getting used to it. With abstract math, the best way I\u0026rsquo;ve found to get used to it is to learn the basic definition and keep applying it to problems until you get the hang of it. The understanding forms in the brain automatically as you get the hang of it.\nQuaternion Math So without further ado, I\u0026rsquo;ll talk about what quaternions are and how they behave.\nRepresentation A quaternion $q$ can be represented as a tuple of 4 numbers: $$q = \\begin{bmatrix} w \u0026amp; \\ x \u0026amp;\\ y \u0026amp; \\ z \\end{bmatrix} = \\begin{bmatrix} w \u0026amp; \\ \\vec{v}\\end{bmatrix} = w + x\\mathrm{i} + y\\mathrm{j} + z\\mathrm{k} $$\nwhere the $w$ is the scalar part and the $\\vec{v}$ is the vector part.\nTwo binary operations are defined for quaternions: addition $+$ and quaternion multiplication $\\otimes$.\nAddition Addition is defined as the component-wise sum just like for a 4D vector. The sum is commutative (order is not important) and associative (grouping is not important).\n$$ q_1 + q_2 = \\begin{bmatrix} w_1 + w_2 \u0026amp; \\ x_1 + x_2 \u0026amp; \\ y_1 + y_2 \u0026amp; \\ z_1 + z_2 \\end{bmatrix} = q_2 + q_1$$\nMultiplication Quaternion multiplication is defined in multiple ways but the formula that I find the easiest to remember is: $$ q_1 \\otimes q_2 = \\begin{bmatrix} w_1 w_2 - \\vec{v}_1\\cdot\\vec{v}_2 \u0026amp; \\ w_1\\vec{v}_2 + w_2\\vec{v}_1 + \\vec{v}_1\\times\\vec{v}_2 \\end{bmatrix} $$\nThe multiplication is non-commutative ($q_1 \\otimes q_2 \\neq q_2 \\otimes q_1$ ) and distributive over the sum $(q_1 \\otimes (q_2 + q_3) = q_1 \\otimes q_2 + q_1 \\otimes q_3 )$.\nNorm, Conjugate and Inverse It\u0026rsquo;s also useful to define the norm of a quaternion as: $$ ||q|| = \\sqrt{w^2 + x^2 + y^2 + z^2} $$\na conjugate quaternion $ q^* $ that satisfies the property $ q \\otimes q^* = ||q||^2 $ as $$ q^* = \\begin{bmatrix} w \u0026amp; \\ -x \u0026amp; \\ -y \u0026amp; \\ -z \\end{bmatrix} $$\nand a quaternion inverse $q^{-1}$ with the property $q \\otimes q^{-1} = \\begin{bmatrix} 1 \\ 0 \\ 0 \\ 0 \\end{bmatrix}$ as $$ q^{-1} = \\frac{q^*}{||q||^2} $$\nUsing Quaternions for Rotation Now that the behaviour of quaternions are established, there is the question of how to use them to represent 3D rotation. From Euler\u0026rsquo;s Rotation Theorem it is clear that rotations have 3 degrees of freedom. But quaternions as 4 tuples have 4 degrees of freedom. So an additional constraint needs to be imposed to use them to represent rotations. This is done by requiring that the quaternions are unit quaternions: $||q|| = 1$. Unit quaternions are also called versors. There are many diagrams and visualizations that attempt to make understanding the unit quaternion more intuitive but I found that for me, most were misleading. I found it the most useful to think of quaternions as just an abstract object with the properties that I\u0026rsquo;ve mentioned and not trying to have any picture in mind. The moment I left behind the crutch of visualization and forced myself to accept and think about quaternions as they are, everything fell into place.\nTo rotate a 3D vector $\\vec{r}$ by a versor $q$ an operation called conjugation is used. $$ \\vec{r}\u0026rsquo; = q \\otimes \\begin{bmatrix} 0 \u0026amp; \\ \\vec{r} \\end{bmatrix} \\otimes q^{*} $$\nIf I find the formula quite mysterious (as I did when I first saw it), it\u0026rsquo;s helpful to use one of the other methods (euler angles, axis angle) to rotate a vector and verify that the result is the same.\nIt\u0026rsquo;s possible to compose two rotations represented by two quaternions $q_1$ and $q_2$ by multiplying the two quaternions together $q_2 \\otimes q_1$. This product represents the rotation $q_1$ applied before $q_2$.\nQuaternions, Rotation Matrices and the Rotation Group $SO(3)$ Earlier, I mentioned that rotations in 3D have certain properties (like non-commutativity) that implies that they don\u0026rsquo;t belong to a vector space (and therefore can\u0026rsquo;t be represented by one). If I want to be exact when talking about rotations, I have to consider them as a group. A group is yet another mathematical abstraction. Abstractly, think of them as a set of objects that follow certain rules. Remember that groups are another concept that leans towards the abstract end of the mathematical spectrum. They can be applied to rotations but they were invented by mathematicians to study more general ideas. So what rules does a group follow?\nA group is a set $G$ along with some binary operation $\\cdot$ (takes two elements of the set and gives a third). The elements of the set follow these rules:\n Closure: If $a,b \\in G$ then $a\\cdot b \\in G$. Associativity: If $a,b,c \\in G$ then $a\\cdot ( b \\cdot c) = (a \\cdot b) \\cdot c $. Identity: There\u0026rsquo;s some element of the set $e$ which has the property $a \\cdot e = e\\cdot a = a$. Inverse: If $a \\in G$ there\u0026rsquo;s some element $a^* $ such that $a \\cdot a^* = a^* \\cdot a = e$.  If you compare this to 3D rotations, you can see that the set of 3D rotations are an example of a group under the binary operation of composition (doing one rotation after another)!\n Closure: If I compose two rotations it forms another rotation. It doesn\u0026rsquo;t suddenly become a translation or scaling or shear. There\u0026rsquo;s no way to combine rotations to do any of these other operations. Associativity: If I do three rotations, it doesn\u0026rsquo;t matter which two I compose first. Identity: There\u0026rsquo;s an identity rotation ($0^\\circ$ of rotation around any axis). And there\u0026rsquo;s an inverse rotation (rotating by negative of the angle around the same axis.)  Quaternions under multiplications also satisfy all these properties.\nIf I convert Euler angle rotations to rotation matrices and compare them with quaternions, the parallels between them are very clear.\n   Group Property Rotation Matrix $R_i \\in G$ Quaternion $q_i \\in \\mathbb{H}_R$     Closure $R_1 \\cdot R_2 \\in G$ $q_1 \\otimes q_2 \\in \\mathbb{H}_R$   Associativity $R_1 \\cdot (R_2 \\cdot R_3) = (R_1 \\cdot R_2) \\cdot R_3$ $q_1 \\otimes (q_2 \\otimes q_3) = (q_1 \\otimes q_2) \\otimes q_3$   Identity $I$ $1$   Inverse $R_i^{-1} = R_i^{T} $ $q_i^{-1}$    The closure and associativity properties rotation matrices can be easily seen as a consequence of the fact that rotation matrices are orthogonal matrices.\nWith this knowledge of the rules that rotations follow, it\u0026rsquo;s clear why it\u0026rsquo;s silly to think of the Euler angles as a vector. They\u0026rsquo;re a set of related numbers but vectors they are not! It\u0026rsquo;s also clear why integrating the angular velocity vector over time does not directly give the orientation in an easily usable form.\nRepresenting quaternion rotation as a matrix Linearity of operations are an important property that both engineers and mathematicians like to take advantage of. It can result in useful simplifications of results. So it\u0026rsquo;s useful (later in this article) to ask the question: Is quaternion multiplication a linear operation? The simplest way to find out is to write out the result of a general quaternion multiplication operation and check if it\u0026rsquo;s possible to represent it as a matrix multiplication.\nThe symbolic result of multiplying two quaternions $q_1$ and $q_2$ is: $$ q_1 \\otimes q_2 = \\left[\\begin{matrix}w_1 w_2 - x_1 x_2 - y_1 y_2 - z_1 z_2\\\\ w_1 x_2 + w_2 x_1 + y_1 z_2 - y_2 z_1\\\\ w_1 y_2 + w_2 y_1 - x_1 z_2 + x_2 z_1\\\\ w_1 z_2 + w_2 z_1 + x_1 y_2 - x_2 y_1\\end{matrix}\\right] $$\nFrom inspection, this can be written as a matrix product: $$ q_1 \\otimes q_2 = \\left[\\begin{matrix}w_2 \u0026amp; -x_2 \u0026amp; -y_2 \u0026amp; -z_2\\\\ x_2 \u0026amp; w_2 \u0026amp; z_2 \u0026amp; - y_2\\\\ y_2 \u0026amp; - z_2 \u0026amp; w_2 \u0026amp; x_2\\\\ z_2 \u0026amp; y_2 \u0026amp; - x_2 \u0026amp; w_2\\end{matrix}\\right] \\begin{bmatrix} w_1 \\\\ x_1 \\\\ y_1 \\\\ z_1 \\end{bmatrix} $$\nAnd if I change the order of multiplication: $$ q_2 \\otimes q_1 = \\left[\\begin{matrix}w_2 \u0026amp; - x_2 \u0026amp; - y_2 \u0026amp; - z_2 \\\\ x_2 \u0026amp; w_2 \u0026amp; - z_2 \u0026amp; y_2 \\\\ y_2 \u0026amp; z_2 \u0026amp; w_2 \u0026amp; - x_2 \\\\ z_2 \u0026amp; - y_2 \u0026amp; x_2 \u0026amp; w_2\\end{matrix}\\right] \\begin{bmatrix} w_1 \\\\ x_1 \\\\ y_1 \\\\ z_1 \\end{bmatrix} $$\nIntegrating Angular Velocity To properly integrate angular velocity to get a quaternion, I need to find a relationship between quaternions and angular velocity - or more precisely - a differential equation that relates the time derivative of the quaternion $\\dot{q}$ and the angular velocity vector $\\vec{\\omega}$.\nA natural place to start is the original definition of the angular velocity from physical law. If I imagine a vector of constant $\\vec{s}(t)$ length stretching out from the origin undergoing rotation with the instantaneous angular velocity $\\vec{\\omega}(t)$ I can find the velocity at the tip of this vector by taking it\u0026rsquo;s derivative. $$ \\frac{\\mathrm{d}\\vec{s}}{\\mathrm{d}t} = \\vec{\\omega} \\times \\vec{s} $$\nSince the angular velocity is perpendicular to the vector $\\vec{s}$ (driving their dot product $\\vec{\\omega} \\cdot \\vec{s}$ to zero) the equation can also be written in quaternion form as: $$ \\frac{\\mathrm{d}\\vec{s}}{\\mathrm{d}t} = \\vec{\\omega} \\otimes \\vec{s} $$\nNow I imagine that this instantaneous vector is represented by a quaternion $q$ rotation from a constant vector $\\vec{s}_0$. $$\\begin{align} \\vec{s} \u0026amp;= q \\otimes \\vec{s}_0 \\otimes q^* \\\\ \\frac{\\mathrm{d}\\vec{s}}{\\mathrm{d}t} \u0026amp;= \\frac{\\mathrm{d}}{\\mathrm{d}t} \\left[ q \\otimes \\vec{s}_0 \\otimes q^* \\right] \\end{align}$$\nSo how do I take that nasty looking derivative on the side? Well it turns out that the product rule of derivatives that is valid in basic calculus is also perfectly valid for quaternion multiplication! I converted the quaternion product into a matrix multiplication and spent some time converting the derivatives of the product to the result from applying the product rule. The only thing to watch out for is the non commutativity of the multiplication. The order of the quaternion product shouldn\u0026rsquo;t be changed when applying the product rule.\n$$ \\frac{\\mathrm{d}}{\\mathrm{d}t} \\left[ q \\otimes \\vec{s}_0 \\otimes q^* \\right] = \\dot{q} \\otimes \\vec{s}_0 \\otimes q^* + q \\otimes \\vec{s}_0 \\otimes \\dot{q^*} $$\nThere\u0026rsquo;s a term in this equation - the derivative of the conjugate - that\u0026rsquo;ll cause some trouble. It is possible to eliminate this using other methods but the simplest way is to directly find a relationship between $\\dot{q}$ and $\\dot{q^*}$. The easy way to do this is to take the derivative of the product of a quaternion and it\u0026rsquo;s conjugate which we know to be 1:\n$$\\begin{align} \\frac{\\mathrm{d}}{\\mathrm{d}t} (q \\otimes q^* ) \u0026amp;= \\frac{\\mathrm{d}}{\\mathrm{d}t} 1 \\\\ \\dot{q} \\otimes q^* + q \\otimes \\dot{q^*} \u0026amp;= 0 \\end{align} $$\nThat gives the relationship\n$$ \\dot{q^* } = -q^* \\otimes \\dot{q} \\otimes q^* $$\nExpressing $s_0$ in terms of $s$, substituting $\\dot{q^* } $ and doing a little algebra: $$ \\frac{\\mathrm{d}}{\\mathrm{d}t} \\left[ q \\otimes \\vec{s}_0 \\otimes q^* \\right] = \\dot{q} \\otimes q^* \\otimes \\vec{s} - \\vec{s} \\otimes \\dot{q} \\otimes q^* = \\vec{\\omega} \\otimes \\vec{s} $$\nThe Quaternion Commutator The expression $ \\dot{q} \\otimes q^* \\otimes \\vec{s} - \\vec{s} \\otimes \\dot{q} \\otimes q^* $ is in the form $p \\otimes q - q \\otimes p$ which is defined as a _commutator_ operation written as $[p, q]$. Going through the algebra of this operation and simplifying:\n$$ [q_1, q_2] = \\begin{bmatrix} 0 \\ 2(\\vec{v}_1 \\times \\vec{v}_2) \\end{bmatrix} $$\nInterestingly, if both $q_1$ and $q_2$ are pure quaternions (They do not have a scalar part) then the quaternion commutator and the product are related:\n$$[\\vec{q}_1, \\vec{q}_2] = 2(q_1 \\times q_2) = 2(q_1 \\otimes q_2) $$\nThe Product $\\dot{q} q^* $ is a Pure Quaternion $$\\begin{align} \\dot{q} \\otimes q^* + q \\otimes \\dot{q^* } \u0026amp;= 0 \\\\ \\dot{q} \\otimes q^* \u0026amp;= -(\\dot{q} \\otimes q^* )^* \\end{align} $$\nSaying that a $q = -q^* $ is the same as saying that $w = -w$ which means that the scalar part of the quaternion is zero.\nThe Differential Equation So finally, I can extract the quaternion differential equation:\n$$ \\begin{align} \\dot{q} \\otimes q^* \\otimes \\vec{s} - \\vec{s} \\otimes \\dot{q} \\otimes q^* \u0026amp;= \\vec{\\omega} \\otimes \\vec{s} \\\\ \\left[\\dot{q} \\otimes q^* , \\vec{s}\\right] \u0026amp;= \\vec{\\omega} \\otimes \\vec{s} \\\\ 2\\dot{q} \\otimes q^* \\otimes \\vec{s} \u0026amp;= \\vec{\\omega} \\otimes \\vec{s} \\\\ \\dot{q} \u0026amp;= \\frac{1}{2} \\vec{\\omega} \\otimes q \\end{align} $$\nIn this equation the $\\vec{\\omega}$ is the angular velocity in the global fixed frame. In many situations it\u0026rsquo;s more useful to have an equation in terms of the angular velocity as measured by a reference frame fixed to the moving body - like when it is measured using a gyroscope. The angular velocity in this frame is the global angular velocity rotated into the body frame $\\vec{\\omega}\u0026rsquo; = q^* \\otimes\\vec{\\omega}\\otimes q $. Replacing $\\vec{\\omega}$ gives the more useful differential equation:\n$$ \\dot{q} = \\frac{1}{2} q \\otimes \\vec{\\omega} $$\nIntegration To solve this differential equation is to be able to integrate it. Normal differential equations are difficult enough. How does one solve a differential equation with a quaternion multiplication in it? This is where the linearity of the quaternion multiplication becomes very useful. I am also going to make a (reasonable) assumption - that the angular velocity is constant over a time $\\Delta t$. Then I can rewrite the differential equation in a well known form:\n$$ \\begin{bmatrix} \\dot{w} \\\\ \\dot{x} \\\\ \\dot{y} \\\\ \\dot{z} \\end{bmatrix} = \\left[\\begin{matrix}0 \u0026amp; - \\omega_x \u0026amp; - \\omega_y \u0026amp; - \\omega_z \\\\ \\omega_x \u0026amp; 0 \u0026amp; \\omega_z \u0026amp; - \\omega_y \\\\ \\omega_y \u0026amp; - \\omega_z \u0026amp; 0 \u0026amp; \\omega_x \\\\ \\omega_z \u0026amp; \\omega_y \u0026amp; - \\omega_x \u0026amp; 0 \\end{matrix}\\right] \\cdot \\begin{bmatrix} w \\\\ x \\\\ y \\\\ z \\end{bmatrix} $$\nThis is an ODE in the form $\\dot{q} = Aq$ where A is the big matrix. The solution to this differential equation then is:\n$$ q(t) = e^{A(t - t_0 )} q_0 $$\nQuaternion Exponential Interestingly, if I define the quaternion exponential in the same way as the matrix exponential (using its Taylor Series representation), I get a quaternion equivalent formula.\n$$ \\begin{align} \\exp{(q)} \u0026amp;= e^{w}e^{\\vec{v}} \\\\ \u0026amp;= e^{w}\\left(\\sum_0^\\infty \\frac{\\vec{v}^k}{k!}\\right) \\\\ \u0026amp;= e^{w}\\left(\\cos{|\\vec{v}|} + \\frac{\\vec{v}}{|\\vec{v}|} \\sin{|\\vec{v}|}\\right) \\end{align} $$\nUsing the quaternion exponential, the solution to the differential equation can be expressed in quaternion form as:\n$$ q(t) = \\exp{\\left(\\frac{1}{2}\\vec{\\omega}\\Delta t\\right)} \\otimes q_0 $$\nSumming Up I started out with the simple sounding task of integrating angular velocity and in trying to solve it, traversed through a several different areas of mathematics and learned a lot along the way before coming to the final solution. However, my description here is far from complete. The equation above only holds if the angular velocity is constant over a time period. This means its a \u0026ldquo;first order\u0026rdquo; model. Dropping this assumption gives $n^{th}$ order models for integration. There are also intricate details that I\u0026rsquo;m only beginning to understand. For instance, I\u0026rsquo;m reading about how rotations are a special type of group called Lie Groups  where the group is also a differentiable manifold (yet another interesting abstract mathematical object). The space of angular velocity forms what is called a Lie Algebra  on the group. And the quaternion exponential function which most texts I refer to seem to pull out of thin air is actually related to a more general idea called an exponential map which maps general Lie Algebras to Lie Groups.\nDespite it\u0026rsquo;s incompleteness however, it is the minimum that I needed to understand to be able to actually implement in code the integration of a quaternion - i.e use quaternions practically for integrating data coming in from an inertial measurement unit. I hope that others trying to understand quaternions and their role in representing 3D rotations will find this article useful. Some of the references below go deeper into the nature of quaternions and how to use them for useful things like tracking orientations.\nReferences  \rBoyle, Michael. \u0026ldquo;The integration of angular velocity.\u0026rdquo; Advances in Applied Clifford Algebras (2016): 1-30. \rhttps://en.wikipedia.org/wiki/Rotation_group_SO(3) \rhttps://en.wikipedia.org/wiki/Quaternion \rSola, Joan. \u0026ldquo;Quaternion kinematics for the error-state KF.\u0026rdquo; (2015). \rhttps://math.stackexchange.com/questions/1030737/exponential-function-of-quaternion-derivation  ","date":1505037488,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505037488,"objectID":"eea2238e7c7929b4f053ade593ae49cf","permalink":"https://www.ashwinnarayan.com/post/how-to-integrate-quaternions/","publishdate":"2017-09-10T17:58:08+08:00","relpermalink":"/post/how-to-integrate-quaternions/","section":"post","summary":"I\u0026rsquo;ve been spending a lot of time working with inertial measurement units recently and am discovering the surprising amount of mathematics that goes into using data from accelerometers and gyroscopes to get the orientation of an object in 3D space.","tags":["mathematics","quaternions","robotics"],"title":"How to Integrate Quaternions","type":"post"},{"authors":null,"categories":null,"content":"When prototyping programs that deal with lots of data on an Arduino and other embedded systems or even on full blown computers, it\u0026rsquo;s really useful to have a quick tool for plotting the output of the program. Initially, I used python for doing this. Python is a beautifully simple language and between Numpy, Scipy and Matplotlib, you can do pretty much anything you want with data; from doing simple plotting to running machine learning algorithms on the data. However, when all you want is to quickly plot a text file containing some data, breaking out a text editor to write a python script can get annoying especially if you do it many times a day.\nThat was when I came across this interesting video from the computerphile YouTube channel.\n  It\u0026rsquo;s a fantastic interview with Brian Kernighan where he talks about his work on Unix and in particular then awk command line tool. I\u0026rsquo;ve been using linux as my primary operating system for quite some time now and I do a lot of programming in it. So I am fairly comfortable with using the terminal for compiling and debugging code. But there was never a situation where I had to sit down and learn about all the terminal based utilities that were available. As I was watching Brian Kernighan describe awk and how it works, I started to realize that I could really use this tool to my advantage when playing around with data. That was when I decided take a closer look at all the tools that were available on the linux terminal to see what I was missing out on.\nOver time I\u0026rsquo;ve developed a few \u0026ldquo;recipes\u0026rdquo; that are really useful to me and I thought I\u0026rsquo;d share some that I\u0026rsquo;ve found particularly useful.\n1. Log and monitor a serial port Logging and monitoring serial ports is a really common thing to have to do - especially if you\u0026rsquo;re working with embedded systems like the Arduino. It\u0026rsquo;s a standard way of getting data off the microcontroller. Checking what\u0026rsquo;s being logged to the serial port is as simple as running:\ncat /dev/ttyUSB0  Sometimes the command exits immediately or shows garbled output (due to the wrong baud rate). You can use stty to change the serial port settings.\nstty -F /dev/ttyUSB0 115200 min 1  I can also log the data from the serial port conveniently to a text file,\ncat /dev/ttyUSB0 \u0026gt; logfilename.txt  2. Log and monitor network ports One of the ways to get data off an Arduino is using an XBee device to wirelessly transmit it. I\u0026rsquo;m a big fan of using the XBee WiFi module to log data to a UDP port on my laptop. To view incoming data from the UDP port, I use a really useful tool called netcat. Say the device is logging data to port 9750. I can listen in on the data by running,\nnetcat -ul 9751  and log the data if I like.\nnetcat -ul 9751 \u0026gt; log.txt  3. Plot data in a log file from the terminal feedgnuplot is a really useful Perl script that can read data from stdin and pass it to gnuplot for plotting. The only requirement is that the data arrive in a specific format: One sample per line, spaces between each data stream. This means your data in the file should look like this:\n1.0 1.5 2.3 1.1 1.3 2.7 2.6 5.9 3.3  To plot the data:\ncat log.txt | feedgnuplot --lines --autolegend  The --autolegend option automatically numbers each line in the graph. The --legend option can be used to add custom legends. I highly recommend going through the feedgnuplot manpage to find out about all the functionality that the script offers.\n4. Plot only specific data The awk command is useful for filtering data that comes into the program line by line. A simple way it can be applied is to plot only specific columns in the text data.\ncat log.txt | awk '{ print $1, $2 }' | feedgnuplot --lines --autolegend  The awk command as shown here will filter out only columns 1 and 2 from the log file and pass it on to feedgnuplot.\nawk can also be used to do more complicated things like select lines with only numbers or only text. This can be useful if the log file contains other debug output lines as well and you want to filter out and plot just the lines that contain numeric data. Wikipedia has a pretty good introduction to awk. I also found that a lot of the time, I could find what I needed for specific problems by searching stackoverflow.\n5. Process data before plotting What if I have some raw data in a log file that you want to run through some processing (more complicated than an awk one liner)? I write a simple python script that reads lines from stdin and writes the processed sample to stdout. If I do this, I can plot the result by doing\ncat log.txt | ./process_script.py | feedgnuplot --lines --autolegend  or log it to another file.\ncat log.txt | ./process_script.py \u0026gt; processed_data.txt  6. Interpret packed binary data If the data in the log file, or data that\u0026rsquo;s coming in from a serial port or network interface is in some packed binary format, there\u0026rsquo;s a handy tool called od that can interpret it on the fly. The command below will interpret data coming in as packets of 8 bytes as 2 byte integers.\nnetcat -ul 9751 | od -An -td2 -w8  od is a versatile tool and as is usual for linux programs, I recommend reading the manpage to know more about what it can do.\n7. Process/Plot live data streams If I have data coming in from from a serial port or from a network interface and I want to create a real-time plot, feedgnuplot has an option for that.\ncat /dev/ttyUSB0 | feedgnuplot --lines --autolegend --xlen 100 --stream 0.1  The --xlen option plots a window of the last 100 samples and the --stream option updates the plot as new data comes in. The parameter 0.1 is the refresh rate.\nI can even run the live data stream through my processing algorithm before plotting.\nnetcat -ul 9750 | ./process_data.py | feedgnuplot --lines --autolegend --xlen 100 --stream 0.1  8. Redirecting to multiple programs. Sometimes I\u0026rsquo;ve been in a situation where I want to monitor data coming in from a serial port and log it to a file at the same time. One way of doing this is to write a python script that reads data from stdin, logs it to a file and also writes the same data to stdout.\ncat /dev/ttyUSB0 | ./log_and_print.py | feedgnuplot --lines --xlen 100 --stream 0.1  This is good if you only want to do one extra thing with the output. There is a better solution however that uses the tee command.\ncat /dev/ttyUSB0 | tee \u0026gt;(command1) \u0026gt;(command2) \u0026gt;(logfile.txt) | feedgnuplot --lines --autolegend --xlen 100 --stream 0.1  This technique is quite versatile and can be used in many ways. For example, I can use tee to get the raw data from the serial port, plot it, pass it through a data processing script and plot the output of that result as well for a comparison.\nSumming up I\u0026rsquo;m sure that there are many more clever ways to combine and compose these commands to make prototyping easier as well as commands that I don\u0026rsquo;t know about yet. If there is one thing that I\u0026rsquo;ve learned after using linux for a few years it\u0026rsquo;s that it often has modest looking command line tools that can do much more than a lot of GUI based applications if you spend just a little time to go through the manpage. I hope that this post inspires others to take a second look at the free tools that come with most linux distros. Some of them could really simplify your workflow!\n","date":1502623814,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502623814,"objectID":"f68bd26732c0fb8ac63aae0aab63bf4f","permalink":"https://www.ashwinnarayan.com/post/bash-recipes-for-science/","publishdate":"2017-08-13T19:30:14+08:00","relpermalink":"/post/bash-recipes-for-science/","section":"post","summary":"When prototyping programs that deal with lots of data on an Arduino and other embedded systems or even on full blown computers, it\u0026rsquo;s really useful to have a quick tool for plotting the output of the program.","tags":["programming","linux","science"],"title":"Bash Recipes for Doing Science!","type":"post"},{"authors":null,"categories":null,"content":"Over the past few months I\u0026rsquo;ve been spending a lot of time on implementing various signal processing algorithms in C/C++. Things like Kalman Filters, various types of FIR filters and finite state machines. The number of steps needed to implement each these algorithms were fairly small and in the beginning I tried to put all the functionality of these implementations into simple to use C++ classes. This made things look neater and also fit in quite well with the Arduino programming framework (I was implementing a lot of these algorithms on Arduino compatible microcontrollers like the Teensy). However, once I started combining different algorithms together to make something bigger, the code started becoming very messy. Making changes and debugging was starting to take longer and longer. In many instances, I had to go back and change the deisgn and interface of my C++ classes when I realized that the way I initially implemented it made it impossible or very difficult to do some step in the algorithm. I decided to take some time to figure out how I can do better. I wanted to find out a systematic method - a \u0026ldquo;meta-programming\u0026rdquo; algorithm if you will - that would tell me the way I should implement the algorithm so that the code is easy to write and more importantly, easy to read and debug.\nRepresenting the Algorithm Before I could start solving the problem I needed to decide how to represent a general data processing algorithm. What is a representation that can capture most if not all of the types of algorithms that I wanted to implement? I remembered that in a lot of papers that I\u0026rsquo;ve read, the authors used Simulink to implement their algorithm. So I decided to start out by assuming that I can represent what I want to do in the form of a block diagram - much like the block diagrams that you can draw in Simulink. It turns out that as long as they don\u0026rsquo;t have any cycles or loops, block diagrams with arrows representing the flow of data between the blocks can be represented by a mathematical structure called a Directed Acyclic Graph.\nDirected Acyclic Graphs \rGraphs as a mathematical structure (different from the graphs that you use to plot data) are useful for representing relationships between things. Intuitively I think of them as circles connected by lines. The circles represent things and the lines represent some type of relationship between the things. If this seems very abstract, that\u0026rsquo;s because graphs can be applied to a lot of different things and when an concept is that general, it tends to be very abstract. As an example, a graph can be used to represent an electrical circuit. Each discrete component like a resistor or an LED can be considered a node or vertex in the graph (circles). The wires that connect these components together can be considered the edges of the graph.\n\r\rA graph representing the collatz sequence and some unrelated drawings.\r\r\rA directed graph is a graph in which the edges connecting the nodes have a direction. The graph in the image from xkcd is a directed graph since it has arrows connecting the nodes of the graph.\nA directed acyclic graph (DAG) is a directed graph that does not have cycles in it. This means that there is no way to start at a node in the graph and follow the arrows from node to node and reach the node you started at. A directed acyclic graph is useful for modeling dependencies. If you\u0026rsquo;re planning to understand some big concept in science - General Relativitiy for example - there are prerequisite ideas that you need to understand first. A subject and it\u0026rsquo;s prerequisites can be arranged in the form of a directed acyclic graph.\n\r\rA directed acyclic graph showing the dependencies for learning about Markov Chains.\r\r\rTopological Sorting Given a DAG showing the dependencies for learning about Markov chains like in the image above, one might ask the question: Is there a way to list the nodes of the graph in correct learning order i.e the order in which any dependencies for a node appear before the node itself is listed. It turns out that you can! Every DAG has at least one way in which we can make this sorted list and there are a few algorithms for doing so.\nSo if you want to learn something new, topologically sorting a dependency graph of the topic is a nice approach! In fact, this is exactly what the website Metacademy does! It gives you the order in which to learn things using topological sorting.\nDataflows So how does this relate to programming algorithms represented by block diagrams in C? I thought of the block diagram as a directed acyclic graph. The blocks which represent steps in the data processing algorithm are represented by nodes in the graph and the arrows that connect the blocks represent the flow of data. In programming, the nodes in the block diagram can be naturally represented by functions whose arguments are the incoming edges and the return values are the outgoing edges. This also means that the edges themselves can be naturally represented by variables in the C program. Once I\u0026rsquo;ve defined all the edge variables and block functions, I need to figure out what is the correct order in which to call each of these block functions. The \u0026ldquo;correct\u0026rdquo; order can be defined as the order in which each function is only called once all the variables that represent the input edges to the block have been updated (if necessary) in the current iteration of the main loop of the program. It turns out that this correct order is the same as the topologically sorted order of the function blocks.\nSo to summarize the systematic meta algorithm to implement a data processing algorithm in C:\nStart out with a fresh .h file which will contain your implementation\n Construct a block diagram of the algorithm showing the data flow. Make sure that the block diagram is a directed acyclic graph. Give names to each node and edge. For each edge in the graph, declare a C variable in the global scope. I use the static keyword if I want to make sure that the variable is only visible inside the header file. The data type of the C variable depends on the node that the edge originates from. For each node in the graph, declare a function that takes as arguments pointers to both the input and and output edge variables from the node. It is useful to declare the input pointers as const to ensure that the function does not modify the data in the edge variables. The function uses the input to carry out the processing step and modifies the output edge variables. I use static variables inside the function if I need to keep track of any state (like for finite state machines). Any parameters needed by the processing step inside the function can either be declared globally or as a const argument of the function. Personally, I like to have the simple parameters as #defines at the top of the header file so I can tweak/change them easily. If there are parameters that need to be modified/tuned during execution, they can be declared as variables global to the file. This is useful if you\u0026rsquo;re running a code that implements something like a PID controller and you want to tune the gains of the controller online. I use an Arduino library that listens to incoming commands on one of the Serial ports. Define an initialization function that initializes all the edge variables to an initial state (if necessary). Define a main function graph execution function that calls the block functions in the topologically sorted order.  Here\u0026rsquo;s a rough outline of what the .h file will look like.\n#ifndef DATA_PROC_H #define DATA_PROC_H //#defines and parameters #define PARAM1 0 //Define the edge variables with the appropriate type float e1, e2, e3, e4 int e5; //Define the node function prototypes void F1(const float in1, const float in2, float *out); void F2(const float in1, const float in2, float *out); void F3(const float in1, int *out); //Define the initialization function void data_proc_init() { e1 = 0; e2 = 0; e3 = 0; e4 = 0; } //Define the main execution pipeline function void data_proc_exec() { //Node functions called in the topologically sorted order F1(e1, e2, \u0026amp;e3); F2(e2, e3, \u0026amp;e4); F3(e4, \u0026amp;e5); } //Function implementations //Implement the node functions here #endif  And in the main C file:\n#include \u0026quot;data_proc.h\u0026quot; int main(int argc, char** argv) { //Run the initialization function data_proc_init(); while(loop_condition) { //Execute pipeline function in loop data_proc_exec(); } }  I\u0026rsquo;ve noticed that if I stick to these rules consistently, my code is generally much easier to read. As long as I give descriptive names to the block functions, I only need to look at the main execution function to figure out the flow of the program. Debugging becomes easier too! It becomes a matter of adding one function from the topologically sorted list at a time and checking the output for correctess.\nWhile the meta algorithm that I wrote down is specifically for C, this method can easily be extended to other programming languages. Python would make doing this even easier as it is much more flexible with functions returning data. Instead of taking in pointers to the output variables as arguments, the function can actually return tuples of data that can be assigned to the output edge variables.\nI\u0026rsquo;m sure that this method will have some limitations. One I can see right away is that it uses a lot of variables. One for each edge and even more for the static variables inside the function. On memory constrained systems like small microcontrollers, the RAM can run out pretty fast (Declaring non-tweakable parameters as being stored in the code ROM should help with this a bit). Another problem is the question of what to do with algorithms that can\u0026rsquo;t be represented as a DAG. I don\u0026rsquo;t know if it\u0026rsquo;s possible to represent all possible algorithms using DAGs (A quick google search did not turn up any conclusive answers). I am also unsure how this model can be used for programming things like GUIs which sit around and wait for events to happen most of the time. However, when implementing control and signal processing algorithms, I find this method is singularly better than the others I\u0026rsquo;ve tried.\n","date":1501517714,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1501517714,"objectID":"2174a5a7eae47c81eef886c06def86d9","permalink":"https://www.ashwinnarayan.com/post/dataflow-programming-in-c/","publishdate":"2017-08-01T00:15:14+08:00","relpermalink":"/post/dataflow-programming-in-c/","section":"post","summary":"Over the past few months I\u0026rsquo;ve been spending a lot of time on implementing various signal processing algorithms in C/C++. Things like Kalman Filters, various types of FIR filters and finite state machines.","tags":["programming","C"],"title":"Programming Complex Dataflows in C","type":"post"},{"authors":null,"categories":null,"content":"The IEEE International Conference on Robotics and Automation (ICRA) that happened in Singapore over the last week is often referred to as the robotics conference. If you\u0026rsquo;re an academic working in the field of robotics, Singapore was the place to be in the last week. So I spent most of my time hanging around the Marina Bay Sands Hotel Convention center as a student volunteer for the conference, helping out and - in my free time - attending some of the hundreds of presentations that that took place.\nOne thing that completely blew me away was the scale of the event. It made me realize how vast human knowledge is and how my life\u0026rsquo;s entire work would just be a miniscule part of the sum total. Robotics itself is just a small portion of all there is to know. And even in a conference dedicated to this field, I had to sift through dozens to subfields to attend the talks that were relevant to my narrow area of research.\nDay 1  The first day of the conference did not have any paper presentations. I guess they wanted to give the delegates from other countries time to get used to the place before they had to present their work. There were however, workshops on several different subjects that were going on. It was also one of the busiest days as a volunteer for me since I was helping out with the registrations of those coming in for the conference. I spent the day helping people get their conference ID tags (which were used for access control) and package. Instead of the usual thick booklet of the conference schedule, ICRA 2017 gave out to all the delegates an android tablet pre-loaded with an app that had the full conference schedule.\nRegistration work ended at 4.30 and I had some time to catch the end of a very interesting workshop on rehabiliation robotics.\nDays 2 - 4  Days 2 - 4 were when the bulk of the conference happened. The papers were classified into sub topics and the presentations for each sub topic happened in different rooms. I feel like the organizers did a good job of separating the papers out in a way that prevented situations where you had two relevant sessions that you had to be in at the same time. After listening to many people presenting their work, I feel a little less nervous about the time I\u0026rsquo;ll have to present my own work in a conference. For the most part, people were friendly, interested and loved to discuss with you about your work after the presentation. In fact, I\u0026rsquo;ll say that I\u0026rsquo;m almost looking forward to my next conference so that I can discuss with interested people about my work.\nConferences are also very intellectually stimulating! As I listened to the presentations I also found myself getting new ideas for how I could solve problems that I\u0026rsquo;m facing in my own work. And surprisingly, I had some of my more interesting ideas in sessions that were not directly related to my work. In my next conference I think I will also spend some time attending sessions that are not directly related to my area of research.\nWhile the technical sessions were fantastic, I enjoyed even more the brilliant talks that were arranged for the Keynote and Plenary sessions. These are talks arranged in the afternoons and in the mornings. I think that the organizers selected the works of some particularly brilliant people for these sessions. There were three talks that really stood out.\nMy favorite talk was one by Professor Lourdes Agapito from University College London. She gave a talk on her work on extracting 3D information from static 2D photos and videos. This is something that\u0026rsquo;s very difficult to do. The best camera sensor that does this is the Kinect and it has to use multiple cameras and an infra red pattern projected onto the scene to get depth information. This limits the range of the camera to a few feet. To get really good long range 3D reconstruction, you need to use a LIDAR - the sensors that self-driving cars use to sense the environment around them. That\u0026rsquo;s why I was so impressed by the quality of the 3D reconstruction that she was able to extract from images taken by just a single camera.\nI also really enjoyed the talk by Chris Gerdes from Stanford. Strapping a bunch of electronics on a DeLorean (among other cars) and making automatic control systems that can keep up with human racecar drivers (and even perform drifting maneuvers) is just pure awesomeness.\nThe last Keynote on June 1 by Professor Katja Mombaur was in a category of its own. She talked about her work on developing very accurate dynamic models of human walking. As someone who spent a lot of time trying to understand the very hairy mathematics behind the dynamics of human walking, I could really appreciate the amount of effort that went into her research. It\u0026rsquo;s probably work that I will be referring to and using quite frequently during my PhD.\nThere were also some robot competitions and an exhibition happening at the conference. I was expecting a lot from these but I didn\u0026rsquo;t find them as exciting as I thought I would. Maybe working in lab with lots of cool robots every day has rasied my standards of the kind of robotics demos that I find exciting. The robotics competitions were pretty interesting to watch though. Especially the block stacking challenge from DJI.\nDay 5  The last day of the conference was a little quiet. A lot of the people had already left or were busy exploring Singapore. The few who stuck around were those interested in attending the workshops on the last day of the conference. I attended one focusing on Assistive robotics.\nWorth it?  Doing volunteer work in a conference is no easy task. I was on my feet through most of the 5 days and my feet were killing me at the end of the day. I don\u0026rsquo;t think I\u0026rsquo;ve ever walked more in my life than during the first four days of the conference. Your voice can also take quite a hit, especially if you\u0026rsquo;re working at the registration desk.\nOn the whole though, I think it was definitely worth it. I\u0026rsquo;d have gladly done all that work for the amazing talks and technical presentations alone, but that was not all that made the conference worth attending. It felt amazing to be surrounded by so much technology and by people who love robotics as much as I do. Being a bit of an introvert, I\u0026rsquo;ve always found it difficult to do small talk with people. The conversation just doesn\u0026rsquo;t feel natural or interesting to me. In the conference however, I felt like I could walk up to almost anyone and start a conversation about something without feeling like I\u0026rsquo;m boring my conversation partner. A welcome change for someone used to people zoning out when I talk about things that interest me.\nApart from the technical presentations, I also got to experience a really nice 9 course dinner, and free entry into the Night Safari and the flower dome in the Gardens By the Bay. So if you ever get an opportunity to become a student volunteer in a big conference like this in your field, go for it!\n","date":1496674252,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1496674252,"objectID":"b709a734684894012f1da4756659e20d","permalink":"https://www.ashwinnarayan.com/post/icra-2017/","publishdate":"2017-06-05T22:50:52+08:00","relpermalink":"/post/icra-2017/","section":"post","summary":"The IEEE International Conference on Robotics and Automation (ICRA) that happened in Singapore over the last week is often referred to as the robotics conference. If you\u0026rsquo;re an academic working in the field of robotics, Singapore was the place to be in the last week.","tags":["academia","conference","ICRA"],"title":"ICRA 2017","type":"post"},{"authors":null,"categories":null,"content":"Xenomai gets tasks to run in real-time by having a co-kernel running alongside the regular linux kernel handling all the time critical tasks. The Xenomai co-kernel is able to do this because of the i-pipe patch that the custom kernel is compiled with. This patch adds an interrupt pipeline that sits between the hardware of the computer and any kernels running on the hardware. The interrupt pipeline has domains which can be assigned a priority. When any interrupt, system call or processor fault comes in, the domain with the higher priority is allowed to process them first. The Xenomai co-kernel has the higher priority in an ipipe patched kernel. The Xenomai website has a more detailed explanation of how it works.\nBefore I start with the explanation, here\u0026rsquo;s the full code and Makefile for those who just want to compile some code and get started. The documentation for all the functions used in the code and more can be found here.\nThe code:\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;sys/mman.h\u0026gt; #include \u0026lt;alchemy/task.h\u0026gt; #include \u0026lt;alchemy/timer.h\u0026gt; #include \u0026lt;math.h\u0026gt; #define CLOCK_RES 1e-9 //Clock resolution is 1 ns by default #define LOOP_PERIOD 1e7 //Expressed in ticks //RTIME period = 1000000000; RT_TASK loop_task; void loop_task_proc(void *arg) { RT_TASK *curtask; RT_TASK_INFO curtaskinfo; int iret = 0; RTIME tstart, now; curtask = rt_task_self(); rt_task_inquire(curtask, \u0026amp;curtaskinfo); int ctr = 0; //Print the info printf(\u0026quot;Starting task %s with period of 10 ms ....\\n\u0026quot;, curtaskinfo.name); //Make the task periodic with a specified loop period rt_task_set_periodic(NULL, TM_NOW, LOOP_PERIOD); tstart = rt_timer_read(); //Start the task loop while(1){ printf(\u0026quot;Loop count: %d, Loop time: %.5f ms\\n\u0026quot;, ctr, (rt_timer_read() - tstart)/1000000.0); ctr++; rt_task_wait_period(NULL); } } int main(int argc, char **argv) { char str[20]; //Lock the memory to avoid memory swapping for this program mlockall(MCL_CURRENT | MCL_FUTURE); printf(\u0026quot;Starting cyclic task...\\n\u0026quot;); //Create the real time task sprintf(str, \u0026quot;cyclic_task\u0026quot;); rt_task_create(\u0026amp;loop_task, str, 0, 50, 0); //Since task starts in suspended mode, start task rt_task_start(\u0026amp;loop_task, \u0026amp;loop_task_proc, 0); //Wait for Ctrl-C pause(); return 0; }  The Makefile\nSKIN=alchemy MAIN_SRC=cyclic_test TARGET=cyclic_test LM=-lm CFLAGS := $(shell xeno-config --skin=alchemy --cflags) LDFLAGS := $(LM) $(shell xeno-config --skin=alchemy --ldflags) CC := $(shell xeno-config --cc) $(TARGET): $(MAIN_SRC).c $(CC) -o $@ $\u0026lt; $(CFLAGS) $(LDFLAGS)  First, the headers, defines and global variables:\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;sys/mman.h\u0026gt; #include \u0026lt;alchemy/task.h\u0026gt; #include \u0026lt;alchemy/timer.h\u0026gt; #include \u0026lt;math.h\u0026gt; #define CLOCK_RES 1e-9 //Clock resolution is 1 ns by default #define LOOP_PERIOD 1e7 //Expressed in ticks //RTIME period = 1000000000; RT_TASK loop_task;  The includes are fairly standard. The Xenomai libraries are included by the alchemy/task.h and the alchemy/timer.h statements. I\u0026rsquo;ve deifined CLOCK_RES (The resolution of the clock) and LOOP_PERIOD (The period with which I want the periodic task to run) for convenience. The variable RT_TASK loop_task will hold an address to a task descriptor for a Real-Time task/thread that Xenomai will create.\nJumping ahead to main(), the first line that you come across that might be unfamiliar is:\n//Lock the memory to avoid memory swapping for this program mlockall(MCL_CURRENT | MCL_FUTURE);  The mlockall() function is actually a function provided by linux rather than Xenomai and is provided by the \u0026lt;sys/mman.h\u0026gt; include. In Part one, I talked about how a real-time task can miss its deadlines if the task is swapped out of memory by the operating system. This line of code makes sure that the memory that is currently mapped to the address space of the process as well as any memory that gets mapped into the address space of the process in the future is \u0026ldquo;locked\u0026rdquo; into RAM and cannot get swapped out.\nIn the next few lines of code, a new real-time task is created.\n//Create the real time task sprintf(str, \u0026quot;cyclic_task\u0026quot;); rt_task_create(\u0026amp;loop_task, str, 0, 50, 0);  The rt_task_create() function creates a new real-time task using Xenoma\u0026rsquo;s Alchemy API. The first argument is the RT_TASK variable that holds the address of the task descriptor. The second is a string that holds a name for the task. You can give it a descriptive name. The third argument is the size of the stack for the new task. Passing a zero makes the function use a system dependent default. The next argument is the priority of the task. This tells the real-time scheduler how important the task is. Higher priority tasks can interrupt lower priority tasks. The last argument is the task creation mode into which you can pass bitwise OR\u0026rsquo;ed flags. For example, passing the T_JOINABLE flag allows you to call the rt_task_join() function to wait on the task to finish. In this code sample, I\u0026rsquo;m just passing in zero, which is the default mode. The function returns a 0 if the task is successfully created. Ideally, you should check for this and print an error if the return value is not zero. However, for this simple example, I\u0026rsquo;m omitting this.\nA real-time task created using rt_task_create() starts off dormant. To begin the execution of the task, you need to call the rt_task_start() function.\n//Since task starts in suspended mode, start task rt_task_start(\u0026amp;loop_task, \u0026amp;loop_task_proc, 0);  The first two arguments are the task descriptor and a pointer to the function that implements the real-time task. The last argument is a pointer to a user defined struct that will be passed on as arguments to the real-time task function.\nFinally we call the pause() function and wait for a Ctrl-C signal from the terminal.\nOnce rt_task_start() is called, the real-time task starts executing. To make a Xenomai task periodic, you need to call the rt_task_set_periodic() function.\n//Make the task periodic with a specified loop period rt_task_set_periodic(NULL, TM_NOW, LOOP_PERIOD);  If you\u0026rsquo;re calling this function from outside a real-time task, you need to pass in an RT_TASK as the first argument. However, you can also call this function from inside a real-time task with a NULL first argument. TM_NOW tells Xenomai to start timing the task right away and LOOP period is the period of the task in ticks of the clock. Since the default resolution of the clock is 1 nanosecond, this argument is the same as the period you want for the task expressed in nanoseconds.\nNow we can start the infinite loop of the task.\n//Start the task loop while(1){ printf(\u0026quot;Loop count: %d, Loop time: %.5f ms\\n\u0026quot;, ctr, (rt_timer_read() - tstart)/1000000.0); ctr++; rt_task_wait_period(NULL); }  In the loop I increment a simple counter and also use the rt_timer_read() function to get the current system time so I can print to the terminal and check if the task is running in real-time. The rt_task_wait_period() blocks the loop till the start of the next period.\nWhen I started out trying to compile and run Xenomai with no prior experience, it seemed like quite a daunting task. The Xenomai documentation although excellent is written for programmers and as a result, it can be difficult to write your very first program. However, once you do write your very first program and you get a good idea for how it works, things go very smoothly. This post, like the one before is a bit long but hopefully, someone trying to get started with Xenomai for the first time will find it useful!\n","date":1495293016,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1495293016,"objectID":"997bd596a75a293516994ef15bcdfdc6","permalink":"https://www.ashwinnarayan.com/post/xenomai-realtime-programming-part-2/","publishdate":"2017-05-20T23:10:16+08:00","relpermalink":"/post/xenomai-realtime-programming-part-2/","section":"post","summary":"Xenomai gets tasks to run in real-time by having a co-kernel running alongside the regular linux kernel handling all the time critical tasks. The Xenomai co-kernel is able to do this because of the i-pipe patch that the custom kernel is compiled with.","tags":["xenomai","real-time","programming"],"title":"Real-Time Programming with Xenomai 3 - Part 2: Writing a simple periodic task.","type":"post"},{"authors":null,"categories":null,"content":"In my lab, we recently started moving away from Simulink\u0026rsquo;s Real-Time packages and towards Real-Time Linux for implementing the low level control of our robots. I thought I would document what I went through to get Xenomai (A Real-Time framework for linux) working stably as a resource for others trying to get started on the same thing.\nWhat is Real-Time? The word \u0026ldquo;real-time\u0026rdquo; is used in a lot of different fields to mean different things. Some people also mistake real-time systems for high performance systems. I use the word real-time to refer to systems that guarantee consistent responses to events within time constraints (also called deadlines) with low variability regardless of system load. This is something that\u0026rsquo;s not easy to do. A normal linux operating system is not real-time. Say you want to implement a program in C on a regular linux computer that toggles a pin on the parallel port every millisecond. A naive implementation would be as a simple loop that toggles the pin and waits for 1 millisecond. This may work OK most of the time but the moment the system is loaded by something else, the program may start running its loops slower because the process may be preempted by the kernel or be swapped out of memory in favor of another memory intensive program. A real-time operating system will be designed so that regardless of the system load, the program that toggles the pin can do the operation every millisecond give or take a few microseconds. This is the reason that a high performance computer with the latest Core i7 processor running a non-realtime OS can be less \u0026ldquo;real-time\u0026rdquo; than a low end microcontroller running a single optimized control task. Real-time systems are used in mission critical control systems such as those on fly-by-wire aircraft, satellites, exoplanetary rovers, cardiac pacemakers or car engine control units.\nA real-time operating system (RTOS) usually has an API for creating and running real-time tasks and uses a scheduling algorithm that\u0026rsquo;s different from what\u0026rsquo;s used by general purpose operating systems like Windows and Linux. There are many RTOSs in the wild. Wikipedia has a great list of them. Some RTOS\u0026rsquo;s like FreeRTOS are meant to be used in embedded microcontrollers. Some - like RTLinux are used when the real-time application needs to be run on a full blown operating system. Using real-time with full operating systems also allow you to take advantage of a lot of existing software and functionality that the operating system will have like networking and math libraries like GSL.\nReal-Time Operating Systems for Control When implementing a control system such as a PID controller digitally, real-time response times become very important. One of the assumptions made when developing digital control systems is that of constant sampling time. When you implement a control loop in code, if the constant sampling rate assumption is not met or if the controller responds too late to changes in the system state, it could lead to the system becoming unstable.\nThe choice of using Xenomai to implement our real time controllers was mostly due to the fact that it has very good documentation apart from being free and open source.\nInstalling Xenomai To get Xenomai running on a linux system, you need to compile a modified kernel. I used Lubuntu 12.04 (which ships with kernel 3.2). The version of the kernel that I compiled is 3.18.20. Choose a version of the kernel that is close in version number to the one that the distribution ships with to minimize issues.\nBefore starting, create a fresh folder to act as your workspace. Also make sure you have plenty of disk space available. The 3.18.20 kernel requires just over 11 GB of free disk space to compile successfully. Newer versions of the kernel need more. 20 GB should be safe.\nThese are the steps that I\u0026rsquo;ve been following to get a freshly installed Lubuntu system working with xenomai. Keep in mind that if this is the first time you\u0026rsquo;re compiling a kernel, things are bound to go wrong. Be willing to debug your compilation patiently. I had to go through the compilation process dozens of times, making tweaks at each step to get my first successful kernel image.\n Go to the downloads section of the xenomai website and look for an ipipe patch (it\u0026rsquo;s a file with a .patch extension) that is for a kernel version that\u0026rsquo;s close to the version your distribution ships with. This is the kernel version that you\u0026rsquo;ll be compiling. Go to kernel.org and download the version of the linux kernel that exactly matches the kernel version on the ipipe patch file name. Download the xenomai source from the xenomai website. Unzip the files into separate folders. Apply the xenomai patch to the kernel: xenomai-3.0.4/scripts/prepare-kernel.sh --linux=linux-\u0026lt;version\u0026gt; --ipipe=patch-\u0026lt;patch-version\u0026gt;.patch --arch=x86_64 cd into the kernel source directory and run make menuconfig and make the following changes:  Power Management and ACPI Options -\u0026gt; CPU Frequency Scaling - DISABLE Power Management and ACPI Options -\u0026gt; ACPI Support -\u0026gt; Processor - DISABLE Power Management and ACPI Options -\u0026gt; CPU Idle -\u0026gt; CPU Idle PM Support - DISABLE Device Drivers -\u0026gt; Input Device Support -\u0026gt; Generic Input Layer -\u0026gt; Miscellaneous Devices -\u0026gt; PC Speaker Support - DISABLE Processor type and features -\u0026gt; Processor family: Select the exact processor on the motherboard. This is important for things to work properly. Xenomai/cobalt -\u0026gt; Core Features -\u0026gt; Shared Interrupts - ENABLE (If you want shared interrupts to work) In the Xenomai/Cobalt drivers section enable all the drivers for the devices that you’ll be using. Consider compiling the drivers as modules (using the m key) so that it is easier to load and unload and debug using modprobe/insmod/rmmod   Before compiling the kernel ensure that you have all the packages needed to compile the kernel. Use apt-get or any package manager.  gcc make Autoconf libtool kernel-package build-essential fakeroot dh-autoconf   cd into the kernel source folder again and compile the kernel using the command: sudo CONCURRENCY_LEVEL=8 CLEAN_SOURCE=no fakeroot make-kpkg --initrd --append-to-version -xenomai-realtime --revision 1.0 kernel_image kernel_headers Once the compile is complete, in the directory above the kernel source, there should be two .deb files: One starting with linux-headers and one starting with linux-image. These are the kernel image and header debian packages that you can use to install the kernel. Use sudo dpkg -i \u0026lt;package-name\u0026gt; to install each of the packages Update the initramfs using the command sudo update-initramfs -c -k \u0026lt;kernel-version\u0026gt;-xenomai-realtime \u0026amp;\u0026amp; sudo update-grub cd into the unzipped xenomai source folder and run sudo ./configure followed by sudo make \u0026amp;\u0026amp; make install Reboot and select the new kernel in the grub menu (Hold down shift at boot time to bring up the menu).  If everything went well, xenomai should be installed on your system now. You might be tempted to start running some tests immediately but I think it\u0026rsquo;s worth taking some more time to set up your build environment properly to make development easier.\nSome important xenomai related executables (including xeno-config) are in the /usr/xenomai/bin folder. You need to append this to the PATH environment variable. The library files that the code is linked against are installed in the /usr/xenomai/lib folder. You need to append this to the LD_LIBRARY_PATH environment variable. My preferred way of doing this is to edit the ~/.bashrc file with export statements. Open up your .bashrc file (it\u0026rsquo;s in your home folder, hidden) by running leafpad ~/.bashrc and add the following two lines to it at the end.\nexport LD_LIBRARY_PATH=”/usr/xenomai/lib:$LD_LIBRARY_PATH”``` When you try to run a compiled xenomai application afterwards, you will need to run it as superuser (using the sudo command). It might complain that it cannot find the library files. This is because environment variables are cleared when running a program as root. To fix this permanently: 1. Open up a terminal and go to the `/etc/ld.so.conf.d` folder. 2. Create a new file called xenomai.conf (as superuser) 3. Add the line `/usr/xenomai/lib` to the file. 4. Run `sudo ldconfig` _Now_ you can finally try to run some tests. If everything went well, running `sudo /usr/xenomai/bin/latency` should run the latency test program that outputs some numbers on to the terminal that shows you the latency figures of your system. It should be in the tens of microseconds range (If not something's wrong). The process of getting real-time linux with Xenomai or any other framework running for the first time can be a little painful but once your installation is stable, it'll serve you well for a very long time. Once you have a working compiled kernel package, installation on future hardware will also go much faster. In Part 2 of this series of blog posts, I will go through the process of writing a simple periodic real-time task using Xenomai's real-time API.  ","date":1494950856,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1494950856,"objectID":"518b90624e1fed5568732a8c3d044e50","permalink":"https://www.ashwinnarayan.com/post/xenomai-realtime-programming/","publishdate":"2017-05-17T00:07:36+08:00","relpermalink":"/post/xenomai-realtime-programming/","section":"post","summary":"In my lab, we recently started moving away from Simulink\u0026rsquo;s Real-Time packages and towards Real-Time Linux for implementing the low level control of our robots. I thought I would document what I went through to get Xenomai (A Real-Time framework for linux) working stably as a resource for others trying to get started on the same thing.","tags":["xenomai","real-time","programming"],"title":"Real-Time Programming with Xenomai 3 - Part 1: Installation and Basic Setup","type":"post"},{"authors":null,"categories":null,"content":"My old website was formatted a lot like an online resume - something I feel doesn\u0026rsquo;t quite fit me any more after I decided to join a PhD program. So I decided to refresh my website deisgn into something that fit my current research interests. I also wanted a platform where I could blog about my work and personal projects. I\u0026rsquo;ve read blogs by many active researchers and I feel that the informal tone and nature of a blog allows more accessible explanations of research than formal journal/conference papers - where the language can often be very terse and full of jargon. A few excellent research blogs that I was inspired by:\n \rStudywolf - About robotics and control. \rMath ∩ Programming Math and programming \rcolah\u0026rsquo;s blog - A blog by a researcher at Google about machine learning  Like for my old website, I decided to go with a static website which allows me to host the site for free using Github pages. I used a static site generator called Jekyll. However, I found it a bit time consuming to use. I wanted to spend more time focusing on the content of the website and less on the setup. So I did a little research on other static site generators that I can use and came across Hugo. It seemed to have all the nice features that a static site generator should have. It works across all operatings systems, had a lot of free themes, was open source and most importantly was easy to set up. I was able to get a basic website generated in under two minutes by following their getting started tutorial. If you\u0026rsquo;re looking for a good static site generator, I highly recommend Hugo.\n","date":1494693531,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1494693531,"objectID":"c37907f82482fd5612d3e60689e56628","permalink":"https://www.ashwinnarayan.com/post/welcome/","publishdate":"2017-05-14T00:38:51+08:00","relpermalink":"/post/welcome/","section":"post","summary":"My old website was formatted a lot like an online resume - something I feel doesn\u0026rsquo;t quite fit me any more after I decided to join a PhD program. So I decided to refresh my website deisgn into something that fit my current research interests.","tags":["miscellaneous"],"title":"Brand New Website!","type":"post"}]