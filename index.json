[{"authors":["admin"],"categories":null,"content":"I am a Research Fellow at the National University of Singapore working with the Biorobotics research group in the Biomedical Engineering department. I do research on sensing and control methods for stroke rehabilitation robotics.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://www.ashwinnarayan.com/author/ashwin-narayan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/ashwin-narayan/","section":"authors","summary":"I am a Research Fellow at the National University of Singapore working with the Biorobotics research group in the Biomedical Engineering department. I do research on sensing and control methods for stroke rehabilitation robotics.","tags":null,"title":"Ashwin Narayan","type":"authors"},{"authors":[],"categories":[],"content":"1. Introduction I’ve recently been tinkering with Rust on embedded systems and have been pleasantly surprised by how thoughtfully designed it is compared to the C and C++ ecosystems. One of the things I immediately appreciated was how easy and straightforward builds are with Rust—just running cargo build makes life simpler. Debugging and printing are also more intuitive, thanks to tools like defmt, which feels like a breath of fresh air compared to traditional methods.\nIn contrast, setting up a project with C or C++ is often cumbersome. You typically find yourself locked into vendor-specific IDEs if you want quick setups. And if you prefer a more lightweight editor like Sublime or Neovim, you usually end up wrestling with creating and maintaining complex CMake files yourself.\nWith these advantages in mind, I’ve recently been working on building out an embedded controller for running some IMU sensors and motors for a personal project and decided it was the perfect opportunity to use Rust.\nFor the IMU, I\u0026rsquo;ll be using the MPU-6050 is a widely-used accelerometer and gyroscope IMU sensor that’s great for robotics, drones, and embedded projects. While there are some existing Rust drivers for this IMU sensor, I thought this was a good opportunity for me to go through the process of writing an I2C driver in Rust and compare it with the process of doing the same thing in C/C++. In this article, we’ll explore building a minimal MPU-6050 driver in Rust, specifically using the Embassy async framework on an STM32F103C8 (BluePill) microcontroller.\n2. High-Level Architecture and Approach As this is my first attempt at a driver, I decided to use the MPU6050 driver by SparkFun as a reference, and borrowed heavily from their approach. I also decided to write a blocking driver first.\nOur driver separates into three parts:\nRegister Definitions: Constants representing MPU-6050 registers. Bit-field Traits: Providing safe and ergonomic register manipulation. I²C Transport: Basic read/write methods using Embassy\u0026rsquo;s blocking I²C. 3. Communicating with MPU-6050 The MPU-6050 communicates over I²C, typically at address 0x68 or 0x69 depending on the AD0 pin:\nAD0 Low (GND): Address 0x68 (default) AD0 High (VCC): Address 0x69 However, I wanted the option to be able to use a completely custom I2C address if needed. So the final design of the driver struct was:\npub struct MPU6050I2c\u0026lt;'d\u0026gt; { peripheral: I2c\u0026lt;'d, embassy_stm32::mode::Blocking\u0026gt;, address: u8, } 4. Representing Registers in Rust 4.1 Register Constants All registers are defined as constants, avoiding heavy enum overhead:\npub const MPU6050_RA_ACCEL_XOUT_H: u8 = 0x3B; // More registers... 4.2 Bit-field Traits Using Rust traits, we create a safe way to handle register bits:\npub trait MPU6050BitField { fn addr() -\u0026gt; u8; fn location() -\u0026gt; u8; fn length() -\u0026gt; u8 { 1 } fn mask() -\u0026gt; u8 { (1 \u0026lt;\u0026lt; Self::length()) - 1 } fn from(value: u8) -\u0026gt; Self; fn to_value(\u0026amp;self) -\u0026gt; u8; } Implementing traits for specific fields:\npub enum SleepMode { Sleep = 0x01, WakeUp = 0x00, } impl MPU6050BitField for SleepMode { fn addr() -\u0026gt; u8 { MPU6050_RA_PWR_MGMT_1 } fn location() -\u0026gt; u8 { MPU6050_PWR1_SLEEP_BIT } // more methods... } 5. Core I²C Driver Our I²C driver class MPU6050I2c encapsulates Embassy\u0026rsquo;s blocking I²C:\nConstructor In our constructor we accept an embassy_stm32::i2c::Instance from which we can construct an I2C peripheral we can interact with. We also accept generic pin types for the SDA and SCL pins and a user defined I2C frequency. This lets the end user decide on which peripheral and pins to use in their application.\nimpl\u0026lt;'d\u0026gt; MPU6050I2c\u0026lt;'d\u0026gt; { pub fn new\u0026lt;P: Instance\u0026gt;( peri: P, scl_pin: impl SclPin\u0026lt;P\u0026gt;, sda_pin: impl SdaPin\u0026lt;P\u0026gt;, freq: Hertz, ) -\u0026gt; Self { MPU6050I2c { peripheral: I2c::new_blocking(peri, scl_pin, sda_pin, freq, Config::default()), address: MPU6050_DEFAULT_ADDRESS, } } pub fn new_with_address\u0026lt;P: Instance\u0026gt;( peri: P, scl_pin: impl SclPin\u0026lt;P\u0026gt;, sda_pin: impl SdaPin\u0026lt;P\u0026gt;, address: u8, freq: Hertz, ) -\u0026gt; Self { MPU6050I2c { peripheral: I2c::new_blocking(peri, scl_pin, sda_pin, freq, Config::default()), address, } } } Basic Read/Write Operations We have read_byte() and write_byte() functions to handle low-level communication.\n/// Read a byte from the specified register of the MPU6050. pub fn read_byte(\u0026amp;mut self, reg: u8) -\u0026gt; Result\u0026lt;u8, embassy_stm32::i2c::Error\u0026gt; { let mut buf = [0; 1]; self.peripheral .blocking_write_read(self.address, \u0026amp;[reg], \u0026amp;mut buf)?; Ok(buf[0]) } /// Write a byte to the specified register of the MPU6050. pub fn write_byte(\u0026amp;mut self, reg: u8, value: u8) -\u0026gt; Result\u0026lt;(), embassy_stm32::i2c::Error\u0026gt; { self.peripheral.blocking_write(self.address, \u0026amp;[reg, value]) } Generic Field Access Reading and writing specific configuration fields within bytes is simplified using generics. As long as you have your configuration field appropriately implemented.\npub fn read_field\u0026lt;T: MPU6050BitField\u0026gt;(\u0026amp;mut self) -\u0026gt; Result\u0026lt;T, embassy_stm32::i2c::Error\u0026gt; { // 1. Read the present 8-bit value in that register let value = self.read_byte(T::addr())?; // 2. Shift the bits to the right so that the field is in the least significant bits let shifted_value = value \u0026gt;\u0026gt; (T::location() - T::length() + 1); // 3. Mask the bits to get only the bits that belong to the field let masked_value = shifted_value \u0026amp; T::mask(); // 4. Return the masked value Ok(T::from(masked_value)) } pub fn write_field\u0026lt;T: MPU6050BitField\u0026gt;( \u0026amp;mut self, field: T, ) -\u0026gt; Result\u0026lt;(), embassy_stm32::i2c::Error\u0026gt; { // 1. Read the present 8-bit value in that register let mut current_value = self.read_byte(T::addr())?; // 2. Clear (zero) the bits that belong to the field current_value \u0026amp;= !(T::mask() \u0026lt;\u0026lt; T::location()); // 3. Insert the bits you want, lined up at the correct position current_value |= (field.to_value() \u0026amp; T::mask()) \u0026lt;\u0026lt; T::location(); // 4. Write the new byte back to the device self.write_byte(T::addr(), current_value) } We can then write and read fields like so:\nlet mut imu_sensor = MPU6050I2c::new(p.I2C2, p.PB10, p.PB11); imu_sensor.write_field(MPUClkSource::PLLWithXGyro)?; imu_sensor.read_field::\u0026lt;GyroFullScaleRange\u0026gt;()?; 6. High-Level Sensor Reads We simplify reading sensor data by writing functions to read single axis sensor data as well as bulk sensor reads.\nSingle-axis: read_accel_x(), read_gyro_y(), etc. Bulk reads: read_accel(), read_gyro(), read_all() An example of the read_gyro() function:\npub fn read_gyro(\u0026amp;mut self) -\u0026gt; Result\u0026lt;(i16, i16, i16), embassy_stm32::i2c::Error\u0026gt; { let mut data = [ MPU6050_RA_GYRO_XOUT_H, MPU6050_RA_GYRO_XOUT_L, MPU6050_RA_GYRO_YOUT_H, MPU6050_RA_GYRO_YOUT_L, MPU6050_RA_GYRO_ZOUT_H, MPU6050_RA_GYRO_ZOUT_L, ]; self.peripheral .blocking_write_read(self.address, \u0026amp;[MPU6050_RA_GYRO_XOUT_H], \u0026amp;mut data)?; let gyro_x = ((data[0] as i16) \u0026lt;\u0026lt; 8) | (data[1] as i16); let gyro_y = ((data[2] as i16) \u0026lt;\u0026lt; 8) | (data[3] as i16); let gyro_z = ((data[4] as i16) \u0026lt;\u0026lt; 8) | (data[5] as i16); Ok((gyro_x, gyro_y, gyro_z)) } 7. Example Application A complete example reading data at 50 Hz:\nInitialization let mut imu_sensor = MPU6050I2c::new(p.I2C2, p.PB10, p.PB11); imu_sensor.write_field(MPUClkSource::PLLWithXGyro)?; imu_sensor.write_field(TempDisable::Disable)?; imu_sensor.write_field(GyroFullScaleRange::FS500)?; imu_sensor.write_field(AccelFullScaleRange::FS2)?; imu_sensor.write_field(SleepMode::WakeUp)?; Main loop let mut ticker = Ticker::every(Duration::from_hz(50)); loop { match imu_sensor.read_accel_gyro() { Ok((ax, ay, az, gx, gy, gz)) =\u0026gt; { info!(\u0026quot;{} {} {} {} {} {}\u0026quot;, ax, ay, az, gx, gy, gz); } Err(e) =\u0026gt; { error!(\u0026quot;Error reading IMU data: {:?}\u0026quot;, e); } } led.toggle(); ticker.next().await; } 8. Building \u0026amp; Flashing Using probe-rs makes flashing and debugging ridiculously simple, once your .cargo/config.toml is set up right. You can configure a runner for your target chip like so:\n[target.thumbv7m-none-eabi] # \u0026lt;-change for your platform runner = 'probe-rs run --chip STM32F103C8' # \u0026lt;- change for your chip # rustflags = [\u0026quot;-C\u0026quot;, \u0026quot;link-arg=-Tlink.x\u0026quot;] [build] target = \u0026quot;thumbv7m-none-eabi\u0026quot; # \u0026lt;-change for your platform [env] DEFMT_LOG = \u0026quot;trace\u0026quot; # \u0026lt;- can change to info, warn, or error And then run\ncargo run --release To have probe-rs flash the firmware on to the micro-controller and view the info!() statements print output. 9. Conclusion and Next Steps While this is a good first pass at the driver and things are working, there\u0026rsquo;s plenty of room to improve and generalize the driver further. Immediate next steps include:\nEnhanced Documentation: Expanding the coverage of documented MPU-6050 register fields. Robust Error Handling: Removing existing panic!() statements and implementing more precise and informative error handling. Generalization with Embedded-HAL: Adapting the driver to use Rust\u0026rsquo;s standardized embedded-hal traits will enhance its portability across various microcontrollers and frameworks, making the driver more widely usable in the embedded Rust ecosystem. ","date":1750169485,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1750169485,"objectID":"428e7beed01edf99d06cbedf69f3a97b","permalink":"https://www.ashwinnarayan.com/post/rust-driver-mpu6050/","publishdate":"2025-06-17T22:11:25+08:00","relpermalink":"/post/rust-driver-mpu6050/","section":"post","summary":"I've recently explored Rust for embedded systems development and found it refreshingly intuitive compared to traditional C and C++ workflows. Rust simplifies setup and debugging, eliminating complex build processes typical in C/C++. To understand better how rust works on embedded systems, I built a minimal MPU-6050 IMU sensor driver using the Embassy framework on an STM32F103C8 (BluePill) microcontroller.","tags":["programming","rust"],"title":"Writing a Rust Driver for the MPU6050","type":"post"},{"authors":[],"categories":[],"content":"Introduction I\u0026rsquo;ve been working with Rust on microcontrollers for a while now, and I\u0026rsquo;ve been using the excellent embassy crate for async programming. However, I recently started using a processor for which embassy does not have Hardware Abstraction Layer (HAL) support, and I wanted to experiment with building my own async runtime. This was also a great opportunity to learn more about the processor and understand the implementation details of async/await in Rust.\nIn this article, we\u0026rsquo;ll create an async runtime for ARM Cortex-M microcontrollers. We\u0026rsquo;ll build on Philipp Oppermann\u0026rsquo;s work for x86 bare-metal systems here and adapt the approach for Cortex-M, which presents unique challenges like limited memory and often lacking a Memory Management Unit (MMU). These constraints require different design choices for async primitives, executors, and interrupt handling.\nNote that this is an experimental project focused on learning and exploration. It is not production-ready, but it serves as a good starting point for building your own async runtime for embedded systems. If you\u0026rsquo;re looking for mature libraries for running real-time code on embedded systems, consider using embassy or rtic.\nWe will cover:\nBuilding a lightweight executor for embedded systems Implementing tasks in an async context Utilizing power-saving features to sleep the microcontroller when no tasks are active By the end of this article, you\u0026rsquo;ll understand the basics of creating a custom async runtime and how it can be adapted to a resource-constrained environment like Cortex-M microcontrollers.\nWhy Build Your Own Async Runtime? Building an async runtime from scratch is not just a fun exercise but a useful way to understand how embedded systems handle concurrent tasks. This is particularly important for real-time systems that need to manage limited resources, such as processing power and memory. You\u0026rsquo;ll also be forced to become familiar with the inner workings the underlying hardware peripherals on the microcontroller and how they interact with the runtime. In a world where abstractions are stacked liberally and the typical developer is separated from the hardware by multiple layers of abstraction, this exercise can be a refreshing change of pace.\nWith existing libraries like Embassy, you can quickly get started with async programming on supported hardware. However, there might be scenarios where support for specific hardware is not available, or you need more control over how tasks are managed. This article aims to bridge that gap by helping you understand what it takes to write a custom runtime for such cases.\nWhat is Async Programming? In Rust, async/await allows you to write asynchronous code that looks very similar to synchronous code. It allows you to write code that can pause and resume execution without blocking the entire system, which is particularly useful for handling tasks like I/O operations, waiting for timers, or running multiple concurrent tasks.\nThe async model in Rust uses cooperative multitasking, where tasks yield control back to the executor when they are waiting for something to happen. This is different from preemptive multitasking, where an operating system controls task switching. Cooperative multitasking has the advantage of being predictable and having lower overhead, but it requires each task to explicitly yield control and be well-behaved.\nFor embedded systems, cooperative multitasking often works well because it keeps the system simple and avoids the overhead of complex task switching, which is critical when working with constrained environments like microcontrollers.\nHow Async Works in Rust In Rust, async functions implement the Future trait. Futures can be polled using the poll() method. If a future is ready to produce a value, it returns Poll::Ready(T); otherwise, it returns Poll::Pending. The executor is responsible for polling these futures and managing the lifecycle of tasks.\nThe executor works by polling each task until it completes. It acts as the \u0026ldquo;runtime\u0026rdquo; that runs the tasks concurrently and keeps them progressing. For more details on how this works, I recommend checking out Phil Oppermann\u0026rsquo;s blog.\nAsync Execution Workflow Below is a visual representation of how an async executor manages tasks and keeps polling them until completion.\ngraph TD subgraph Executor A[Task Queue] --\u0026gt; B[Task Polling] end subgraph Task D[Future] --\u0026gt; E[Poll Function] end A --\u0026gt; F[Task Scheduler] F --\u0026gt; E E --\u0026gt; G{Poll Result} G --\u0026gt;|Pending| F G --\u0026gt;|Ready| H[Complete Task] M[Sleep if Idle] --\u0026gt; F This diagram shows how the executor maintains a queue of tasks, polls them to determine their state, and schedules them accordingly. If there are no tasks to execute, the executor can put the processor to sleep to save power.\nDefining a Task Each task in our runtime is represented as a Future pinned in memory, ensuring it can be polled without being moved. This is crucial because futures created by async/await may be self-referential, and moving them in memory would invalidate references to their internal fields.\nEmbedded environments typically don\u0026rsquo;t have access to standard memory allocators, so we need to initialize a custom heap allocator. We\u0026rsquo;ll use the embedded_alloc crate, which is designed for embedded systems. Below is the implementation of our task and how it uses atomic counters for task IDs.\n// Import the 'alloc' crate, which provides memory allocation utilities. // Necessary for dynamic memory allocation in a no_std environment. extern crate alloc; // Importing 'Box' from the 'alloc' crate. Box is a smart pointer for heap-allocated memory. use alloc::boxed::Box; // Importing 'addr_of_mut' from core::ptr to get the mutable pointer to the heap memory. use core::ptr::addr_of_mut; // Importing 'AtomicU32' and 'Ordering' to manage atomic operations in a multi-threaded or interrupt context. use core::sync::atomic::{AtomicU32, Ordering}; // Importing essential types for async and future handling from core: Future, Pin, Context, and Poll. use core::{ future::Future, pin::Pin, task::{Context, Poll}, }; // Importing LlffHeap as Heap from 'embedded_alloc' crate, which provides a memory allocator suitable for embedded systems. use embedded_alloc::LlffHeap as Heap; // Define a global allocator for heap memory. We use a static instance of Heap here. #[global_allocator] static HEAP: Heap = Heap::empty(); // The heap is initially empty and needs to be initialized. /// Initialize the heap. pub fn init_heap() { use core::mem::MaybeUninit; // Use 'MaybeUninit' to represent uninitialized memory safely. const HEAP_SIZE: usize = 1024; // Define the size of the heap in bytes. // Allocate an uninitialized array of bytes (of type MaybeUninit\u0026lt;u8\u0026gt;), which will serve as the heap. static mut HEAP_MEM: [MaybeUninit\u0026lt;u8\u0026gt;; HEAP_SIZE] = [MaybeUninit::uninit(); HEAP_SIZE]; // Initialize the heap using the starting address and size of the memory array. 'unsafe' is required // because we are using raw pointers and modifying static mutable data. unsafe { HEAP.init(addr_of_mut!(HEAP_MEM) as usize, HEAP_SIZE) } } /// Task ID type. We use a 32-bit unsigned integer to represent a task ID. /// Cortex-M architecture is 32-bit, and it doesn't support atomic 64-bit integers. #[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)] struct TaskId(u32); // TaskId is a wrapper around a 32-bit unsigned integer. impl TaskId { /// Generate a new unique task ID. fn new() -\u0026gt; Self { static NEXT_ID: AtomicU32 = AtomicU32::new(0); // Static AtomicU32 that stores the next available task ID. TaskId(NEXT_ID.fetch_add(1, Ordering::Relaxed)) // Increment and return the current ID. } } /// Base struct to represent a task. pub struct Task { /// A unique identifier for the task. id: TaskId, // Each task has a unique TaskId. /// The future representing the task. The Pin\u0026lt;Box\u0026lt;\u0026gt;\u0026gt; wrapper ensures that the /// future is not moved in memory. The Output type of the future is (), indicating /// that the future does not return a value - it just runs to completion. future: Pin\u0026lt;Box\u0026lt;dyn Future\u0026lt;Output = ()\u0026gt;\u0026gt;\u0026gt;, // The 'Pin' ensures that the future is pinned in memory and cannot be moved. } impl Task { /// Create a new task from a future. pub fn new(future: impl Future\u0026lt;Output = ()\u0026gt; + 'static) -\u0026gt; Task { Task { id: TaskId::new(), // Assign a new unique TaskId to the task. future: Box::pin(future), // Pin the future to ensure it is not moved in memory and store it in a Box. } } /// Poll the task. This checks whether the future is ready to make progress or has completed. /// 'poll' uses a mutable reference to the task's future and a context to manage async execution. fn poll(\u0026amp;mut self, context: \u0026amp;mut Context) -\u0026gt; Poll\u0026lt;()\u0026gt; { self.future.as_mut().poll(context) // Poll the pinned future and pass the provided Context. } } // A module declaration for 'executor', the runtime that manages task execution. pub mod executor; In this implementation, TaskId is used to uniquely identify each task, and we use a 32-bit atomic counter to generate these IDs. This approach avoids the overhead of locking and works well in a 32-bit environment like Cortex-M.\nImplementing the Executor The executor is responsible for managing tasks and running them to completion. It uses a task queue to determine which tasks are ready to run, and a custom TaskWaker to wake up tasks when they are ready to make progress.\nBelow is an implementation of the executor that runs tasks in a loop, polling each until they are complete.\nextern crate alloc; use super::*; use alloc::collections::{BTreeMap, VecDeque}; use alloc::sync::Arc; use alloc::task::Wake; use core::task::{Context, Poll, RawWaker, RawWakerVTable, Waker}; use cortex_m::asm; use crossbeam_queue::ArrayQueue; // The custom waker struct for waking tasks. struct TaskWaker { task_id: TaskId, // Unique identifier for the task. task_queue: Arc\u0026lt;ArrayQueue\u0026lt;TaskId\u0026gt;\u0026gt;, // Shared queue used to store task IDs ready to be executed. } impl TaskWaker { // Create a new waker instance for a given task. fn new(task_id: TaskId, task_queue: Arc\u0026lt;ArrayQueue\u0026lt;TaskId\u0026gt;\u0026gt;) -\u0026gt; Waker { Waker::from(Arc::new(TaskWaker { task_id, task_queue, })) } // Add the task to the task queue, making it ready to be polled again. fn wake_task(\u0026amp;self) { self.task_queue .push(self.task_id) .expect(\u0026quot;Task queue is full!\u0026quot;); } } impl Wake for TaskWaker { // Wakes the task by adding it back to the task queue. fn wake(self: Arc\u0026lt;Self\u0026gt;) { self.wake_task(); } // Wake the task by reference, allowing it to be added to the task queue without consuming the waker. fn wake_by_ref(self: \u0026amp;Arc\u0026lt;Self\u0026gt;) { self.wake_task(); } } /// Task executor that runs tasks to completion. pub struct Executor { /// Map of tasks to be run, indexed by task ID. tasks: BTreeMap\u0026lt;TaskId, Task\u0026gt;, /// Queue holding task IDs that are ready to be executed. task_queue: Arc\u0026lt;ArrayQueue\u0026lt;TaskId\u0026gt;\u0026gt;, /// Cache for storing wakers for tasks that are currently running. waker_cache: BTreeMap\u0026lt;TaskId, Waker\u0026gt;, } impl Executor { /// Create a new executor with an empty task queue. pub fn new\u0026lt;const N: usize\u0026gt;() -\u0026gt; Executor { Executor { tasks: BTreeMap::new(), task_queue: Arc::new(ArrayQueue::new(N)), // Initialize task queue with a capacity of N. waker_cache: BTreeMap::new(), } } /// Add a new task to the executor. pub fn spawn(\u0026amp;mut self, task: Task) { let task_id = task.id; if self.tasks.insert(task_id, task).is_some() { panic!(\u0026quot;task with same ID already in tasks\u0026quot;); } self.task_queue.push(task_id).expect(\u0026quot;Task queue is full.\u0026quot;); // Add the task ID to the task queue. } /// Run all tasks that are ready to execute. fn run_ready_tasks(\u0026amp;mut self) { // Continuously pop task IDs from the task queue and run them. while let Some(task_id) = self.task_queue.pop() { // Retrieve the task using its task ID. let task = match self.tasks.get_mut(\u0026amp;task_id) { Some(task) =\u0026gt; task, None =\u0026gt; continue, // If the task doesn't exist, skip it. }; // Retrieve or create a waker for the task. let waker = self .waker_cache .entry(task_id) .or_insert_with(|| TaskWaker::new(task_id, self.task_queue.clone())); // Create a new context from the waker. let mut context = Context::from_waker(waker); // Poll the task to determine if it is ready to make progress. match task.poll(\u0026amp;mut context) { Poll::Ready(()) =\u0026gt; { // If the task is complete, remove it and its waker from the cache. self.tasks.remove(\u0026amp;task_id); self.waker_cache.remove(\u0026amp;task_id); } Poll::Pending =\u0026gt; {} // If the task is not complete, leave it in the task list. } } } /// Put the processor to sleep if there are no tasks to run. fn sleep_if_idle(\u0026amp;self) { cortex_m::interrupt::free(|_| { // If the task queue is empty, put the processor to sleep. if self.task_queue.is_empty() { asm::wfi(); // Wait for interrupt to wake up the processor. } }); } /// Run the executor to completion, continuously executing tasks until none are left. pub fn run(\u0026amp;mut self) { loop { self.run_ready_tasks(); self.sleep_if_idle(); } } } The Executor structure maintains a map of tasks, a task queue, and cached wakers for tasks that are currently running. The run method continuously runs tasks until none are left, and the sleep_if_idle method puts the processor to sleep when there are no tasks to execute. As mentioned here the wfi instruction can be used to wait for an event or interrupt.\nPutting it all together Below is an example of how to put everything together to run a simple async task on a Cortex-M microcontroller.\n#![no_std] #![no_main] use cortex_m_asyncrt::os::{self, executor, init_heap, Task}; use cortex_m_rt::entry; use cortex_m_semihosting::{dbg, hprintln}; // use panic_probe as _; use panic_semihosting as _; #[entry] fn main() -\u0026gt; ! { init_heap(); hprintln!(\u0026quot;Hello, worlds!\u0026quot;); // New executor that can run up to 32 tasks let mut executor = executor::Executor:: new::\u0026lt;64\u0026gt;(); // Spawn a task executor.spawn(Task::new(example_task())); // Run the executor executor.run(); // This code is unreachable because the executor.run() function runs tasks to completion. loop {} } async fn example_task() { // your code goes here let r = example_fn().await; hprintln!(\u0026quot;r = {}\u0026quot;, r); } async fn example_fn() -\u0026gt; u32 { 42 } If you run this code on QEMU you should see the following output:\nTimer with period zero, disabling Hello, worlds! r = 42 If you want to try this out yourself, you can use the cortex-m-asyncrt crate on crates.io. Version 0.1.0 of the crate is exactly as described in this article.\nReal-World Use Cases and Future Work This async runtime could be applied to scenarios where you need a lightweight scheduler for real-time tasks, such as sensor data collection, motor control, or communication handling in resource-constrained embedded systems.\nFuture improvements could include adding task priority, enhancing the scheduler with time measurements for scheduling tasks at regular intervals and for asynchronously awaiting delays.\nReferences Philipp Oppermann\u0026rsquo;s blog on async/await embassy rtic cortex-m-asyncrt crate ","date":1728216291,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728475491,"objectID":"4d7b0b7c334d23d9e6927a20b928b443","permalink":"https://www.ashwinnarayan.com/post/embedded-async-with-rust/","publishdate":"2024-10-06T20:04:51+08:00","relpermalink":"/post/embedded-async-with-rust/","section":"post","summary":"This article explores how to create a custom async runtime for ARM Cortex-M microcontrollers. We'll adapt Philipp Oppermann's work for x86 bare-metal systems to Cortex-M and design a simple Task struct and Executor to run async tasks.","tags":["programming","rust"],"title":"Writing a small async runtime for Cortex-M micro-controllers with Rust","type":"post"},{"authors":[],"categories":[],"content":"Rust is a modern programming language focused on safety, speed, and concurrency. It\u0026rsquo;s a go-to for system-level tasks, offering strong guarantees against common bugs like null pointer dereferences. Embedded systems, with their resource constraints and real-time demands, could really benefit from more Rust. Rust\u0026rsquo;s zero-cost abstractions maintain performance while keeping code size small. Real-time requirements are met through precise hardware interaction, aided by Rust\u0026rsquo;s features like immutable variables and robust type systems. With cross-compilation capabilities and a growing library ecosystem, Rust has recently become (in my opinion) a viable choice for embedded development.\nRust is also the first new programming language that I\u0026rsquo;ve learned since Haskell and I really like how it combines the best of functional programming with the best of systems programming. I\u0026rsquo;ve been playing around with Rust for a while now and I wanted to try my hand at embedded development with Rust. In this post, I\u0026rsquo;ll show you how to blink an LED on an STM32F407 Discovery board using Rust.\nThe STM32F407 Discovery Board The STM32F407 Discovery board is a development board based on the STM32F407VG microcontroller. The board uses an STM32F407 micro-controller and has plenty of LEDs, some push buttons, an accelerometer, a microphone and an audio DAC. Plenty of peripherals to play around with. The user manual has the pinouts and list of peripherals.\nSetting Up Rust for Embedded Development First follow the instructions from rustup.rs to install rust.\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh To compile rust for our micro-controller, we need to let it know what target to compile for. Microcontrollers like the STM32 use the thumb instruction set, which is a subset of the ARM instruction set. Rust has a target for the thumb instruction set, so we need to install it.\nrustup target add thumbv7em-none-eabihf Next, we need to create a new empty project using cargo.\ncargo new --bin blinky Cargo needs some more information to build for a microcontroller. So we need a .cargo/config.toml file in the project directory with the following contents:\n[target.'cfg(all(target_arch = \u0026quot;arm\u0026quot;, target_os = \u0026quot;none\u0026quot;))'] # replace STM32F407VG with your chip as listed in `probe-rs chip list` runner = \u0026quot;probe-rs run --chip STM32F407VG\u0026quot; [target.thumbv7em-none-eabihf] rustflags = [\u0026quot;-C\u0026quot;, \u0026quot;link-arg=-Tlink.x\u0026quot;] [build] target = \u0026quot;thumbv7em-none-eabihf\u0026quot; [env] DEFMT_LOG = \u0026quot;trace\u0026quot; Also useful are some tools that can be used to prepare the binary for flashing onto the microcontroller. We can install these tools using cargo.\ncargo install cargo-binutils rustup component add llvm-tools-preview Libraries Rust has a lot of libraries already that support the hardware of the STM32, which makes things very convenient for us. Rust also has an excellent library called embassy - a lightweight async/await runtime that is designed to work on embedded devices. It is built on top of the cortex-m crate, which provides low-level access to the ARM Cortex-M processors. In traditional C++ based embedded development, you would use an embedded RTOS like FreeRTOS or MBED OS to manage tasks and interrupts. However, with embasst, you can use the async/await syntax to write concurrent code that is (in my opinion) much easier to reason about and debug.\nTo use embassy, add the following dependencies to your Cargo.toml file:\n[package] name = \u0026quot;stm32f407_tests\u0026quot; authors = [\u0026quot;Ashwin Narayan \u0026lt; ashwinnarayan1994@gmail.com \u0026gt;\u0026quot;] version = \u0026quot;0.1.0\u0026quot; edition = \u0026quot;2021\u0026quot; [[bin]] name = \u0026quot;blinky\u0026quot; path = \u0026quot;src/bin/blinky.rs\u0026quot; test = false bench = false # Set up the release profile to optimize our binaries [profile.release] codegen-units = 1 # better optimizations debug = true # symbols are nice and they don't increase the size on Flash lto = true # better optimizations opt-level = \u0026quot;s\u0026quot; # Optimize for size # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html [dependencies] embassy-stm32 = { version = \u0026quot;0.1.0\u0026quot;, features = [ \u0026quot;stm32f407vg\u0026quot;, \u0026quot;unstable-pac\u0026quot;, \u0026quot;memory-x\u0026quot;, \u0026quot;time-driver-any\u0026quot;, \u0026quot;exti\u0026quot;, \u0026quot;chrono\u0026quot;, ] } embassy-executor = { version = \u0026quot;0.5.0\u0026quot;, features = [ \u0026quot;integrated-timers\u0026quot;, \u0026quot;arch-cortex-m\u0026quot;, \u0026quot;executor-thread\u0026quot;, ] } embassy-time = { version = \u0026quot;0.3.0\u0026quot; } embassy-sync = { version = \u0026quot;0.5.0\u0026quot; } cortex-m = { version = \u0026quot;0.7\u0026quot;, features = [\u0026quot;critical-section-single-core\u0026quot;] } cortex-m-rt = \u0026quot;0.7\u0026quot; panic-probe = { version = \u0026quot;0.3\u0026quot; } We will then delete the src/main.rs file and create a new file src/bin/blinky.rs that will contain our code to blink our LEDs.\nBlinking an LED First, the code:\n#![no_std] #![no_main] use embassy_executor::Spawner; use embassy_stm32::gpio::{Level, Output, Speed}; use embassy_time::{Duration, Ticker}; use panic_probe as _; fn clock_config() -\u0026gt; embassy_stm32::Config { let mut config = embassy_stm32::Config::default(); // Configure to use the high speed internal oscillator (HSI). config.rcc.hsi = true; config } #[embassy_executor::main] async fn main(_spawner: Spawner) { // Initialize embassy let peripherals = embassy_stm32::init(clock_config()); // Create a new output pin - PA9 is the green led on the Discovery board let mut green_led = Output::new(peripherals.PA9, Level::High, Speed::VeryHigh); let mut red_led = Output::new(peripherals.PD5, Level::High, Speed::VeryHigh); let mut green_led2 = Output::new(peripherals.PD12, Level::High, Speed::VeryHigh); let mut orange_led = Output::new(peripherals.PD13, Level::High, Speed::VeryHigh); let mut red_led2 = Output::new(peripherals.PD14, Level::High, Speed::VeryHigh); let mut blue_led = Output::new(peripherals.PD15, Level::High, Speed::VeryHigh); // Create a new Ticker for the delay let mut ticker = Ticker::every(Duration::from_millis(100)); loop { // Wait for the ticker to expire ticker.next().await; // Toggle the leds green_led.toggle(); red_led.toggle(); green_led2.toggle(); orange_led.toggle(); red_led2.toggle(); blue_led.toggle(); } } Now let\u0026rsquo;s go through the code step by step and understand what each part does.\nNo Standard Library and No Main #![no_std] #![no_main] #![no_std] tells the rust compiler that we are building a binary without the standard library and #![no_main] tells the Rust compiler that this program does not use the conventional main function as its entry point. This is typical in embedded applications where the entry point needs to conform to specific requirements or where the startup is handled by the hardware or a framework.\nImporting Libraries Next, the library imports.\nSpawner from embassy_executor is used to handle task spawning in an async environment. From embassy_stm32::gpio, we import Level, Output, and Speed to configure GPIO pins. Duration and Ticker from embassy_time are used to handle time-related functions like delays. panic_probe is a library used for better panic messages in embedded systems; the as _ means it\u0026rsquo;s used for its side effects (setting up panic handling) and not for its symbols. use embassy_executor::Spawner; use embassy_stm32::gpio::{Level, Output, Speed}; use embassy_time::{Duration, Ticker}; use panic_probe as _; Clock Configuration This function sets up the clock configuration for the STM32 microcontroller. It enables the High-Speed Internal oscillator (HSI) which is one of the clock sources that can drive the system clock.\nfn clock_config() -\u0026gt; embassy_stm32::Config { let mut config = embassy_stm32::Config::default(); config.rcc.hsi = true; // Configure to use the high speed internal oscillator (HSI). config } Main Function The #[embassy_executor::main] attribute macro marks this asynchronous function as the entry point of the program. The function takes a Spawner argument for potentially spawning new asynchronous tasks. It initializes the STM32 peripherals according to our configuration.\n#[embassy_executor::main] async fn main(_spawner: Spawner) { let peripherals = embassy_stm32::init(clock_config()); GPIO Pins Next, we set up our GPIO pins according to the discovery board\u0026rsquo;s pinout. We create Output instances for each LED pin, specifying the pin number, initial level, and speed. The pins are configured as outputs, and the initial level is set to High. The speed is set to VeryHigh, which is the fastest speed available. The speed specifies the maximum frequency at which the pin can be toggled.\nlet mut green_led = Output::new(peripherals.PA9, Level::High, Speed::VeryHigh); ... let mut blue_led = Output::new(peripherals.PD15, Level::High, Speed::VeryHigh); Ticker for Delays let mut ticker = Ticker::every(Duration::from_millis(100)); Ticker is an embassy_time construct. The embassy_time crate provides time-related functionality for embedded systems. The Ticker::every(Duration::from_millis(100)) creates a new Ticker that expires every 100 milliseconds.\nThe Main Loop loop { ticker.next().await; green_led.toggle(); ... blue_led.toggle(); } The main loop waits for the ticker to expire, toggles the LEDs, and repeats the process indefinitely. The ticker.next().await suspends the task until the ticker expires, allowing the LEDs to blink at regular intervals. The toggle() method changes the state of the LED from on to off and vice versa.\nThe Result If you want to take a look at the code, the full repository is available at my github.\nReferences Rust Programming Language Rust Embedded Embassy Rustup STM32F407 Discovery STM32F407VG User Manual ","date":1714635500,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714635500,"objectID":"1fe86c5a6c91517ff12c69e163c18c94","permalink":"https://www.ashwinnarayan.com/post/embedded-rust-blinking-led/","publishdate":"2024-05-02T15:38:20+08:00","relpermalink":"/post/embedded-rust-blinking-led/","section":"post","summary":"Rust is a modern programming language focused on safety, speed, and concurrency. It\u0026rsquo;s a go-to for system-level tasks, offering strong guarantees against common bugs like null pointer dereferences. Embedded systems, with their resource constraints and real-time demands, could really benefit from more Rust.","tags":["programming","rust"],"title":"Blinking LEDs with Rust","type":"post"},{"authors":[],"categories":[],"content":"I’ve been recently doing a lot of programming using Swift and I’m quite enjoying how intuitive it is to pick up. It also helps that SwiftUI generally produces good looking user interfaces with less effort than other things I’ve tried.\nForms play a crucial role in creating interactive user interfaces for collecting and managing user input. Developing reusable form components in SwiftUI not only streamlines the development process but also ensures a consistent user experience throughout the app. By creating modular, reusable form components, developers can reduce code duplication, enhance maintainability, and simplify the process of updating or extending the functionality of their applications. In this article, we\u0026rsquo;ll explore the process of building a reusable login form component using SwiftUI.\nAt the end of the article you should have a login form that looks like this:\nFirst, the code import SwiftUI struct LoginForm: View { @State private var username: String = \u0026quot;\u0026quot; @State private var password: String = \u0026quot;\u0026quot; let onLoginButtonPress: ((String, String) -\u0026gt; Void)? let onResetPasswordPress: (() -\u0026gt; Void)? var body: some View { VStack { Text(\u0026quot;Login to App\u0026quot;) .font(.title.bold()) .padding() Spacer() TextField(\u0026quot;Username\u0026quot;, text: $username) .padding() .autocapitalization(.none) .disableAutocorrection(true) .border(Color.gray, width: 1) SecureField(\u0026quot;Password\u0026quot;, text: $password) .padding() .border(Color.gray, width: 1) Button(action: { onLoginButtonPress?(username, password) }) { Text(\u0026quot;Login\u0026quot;) .padding() .background(Color.blue) .foregroundColor(.white) .cornerRadius(5) } .padding() Spacer() Button { onResetPasswordPress?() } label: { Text(\u0026quot;Forgot your password? Click here to reset it.\u0026quot;) .font(.caption) .padding() } } .padding() } } struct LoginForm_Previews: PreviewProvider { static var previews: some View { LoginForm(onLoginButtonPress: { userName, password in print(\u0026quot;Login button tapped\u0026quot;) print(\u0026quot;Username is \\(userName), password is \\(password)\u0026quot;) }, onResetPasswordPress: { print(\u0026quot;Reset password requested.\u0026quot;) }) } } The code block above shows a login form where you can enter your username and password and has a button to login and a button to reset your password. Let’s take a look at how it works.\nStoring Username and Password States We use private variables marked with @State to hold the username and password variables. In SwiftUI, @State is a property wrapper that manages the state of a value within a view. It provides local, mutable storage for simple values relevant to a specific view, allowing for mutability within an otherwise immutable view. @State also allows child views or controls to read and write the property\u0026rsquo;s value using bindings, which is particularly useful for user input controls like TextField and Toggle. When a @State property value changes, SwiftUI automatically re-renders the affected parts of the view hierarchy, ensuring that the view always reflects the current state of the data. It is important to use @State only with value types, like structs, for proper change tracking, while other property wrappers like @ObservedObject or @EnvironmentObject are more suitable for reference types or complex data models.\n@State private var username: String = \u0026quot;\u0026quot; @State private var password: String = \u0026quot;\u0026quot; To bind these properties to the TextField and SecureField, respectively, you\u0026rsquo;ll use the $ symbol in front of the property names to create a binding:\nTextField(\u0026quot;Username\u0026quot;, text: $username) SecureField(\u0026quot;Password\u0026quot;, text: $password) By binding @State variables to TextField and SecureField, you ensure that your view always reflects the current state of the data, and changes made by the user in the input controls are automatically captured and stored in the corresponding @State properties.\nClosures for Form Actions In the LoginForm code, onLoginButtonPress and onResetPasswordPress are closure parameters that are passed to the LoginForm view. These closures define custom behavior that will be executed when the login button and reset password button are pressed, respectively.\nonLoginButtonPress: This closure takes two input parameters, a String for the username and a String for the password. It gets called when the user taps the \u0026ldquo;Login\u0026rdquo; button. You can define custom login functionality within this closure, such as authentication and navigation to the next screen. onResetPasswordPress: This closure does not take any input parameters. It gets called when the user taps the \u0026ldquo;Forgot your password? Click here to reset it.\u0026rdquo; button. You can define custom reset password functionality within this closure, such as navigating to a password reset screen or showing a reset password prompt. By using these closure parameters, you can create a more flexible and reusable LoginForm component, as the specific functionality for handling login and password reset actions can be defined outside the LoginForm view, making it adaptable to various use cases within your app.\nYou may also have noticed that I’ve made the closure parameters optional by marking them with a ? symbol. By marking them as optional, you indicate that these closures can have a value (a function) or be nil.\nI prefer and recommend optional closures because it allows you to use the LoginForm component in cases where you might not need to provide both closures. For example, you might want to display a LoginForm that only requires a login action and not the reset password functionality, or vice versa. In such cases, you can simply pass nil for the closure you don\u0026rsquo;t need, without having to modify the LoginForm component itself.\nYou might have scenarios where the behavior of the LoginForm component changes based on certain conditions. By making the closures optional, you can decide at runtime whether or not to provide a specific closure based on the current context or app state.\nTo safely call these optional closures, use the optional chaining syntax with the ?() operator:\nonLoginButtonPress?(username, password) onResetPasswordPress?() This syntax ensures that the closure is only called if it has a non-nil value; otherwise, nothing happens, and the app continues to function without any issues.\nUsing the Form Component in Another View Here’s how you’d use this form component in the main ContentView of your app as an example.\nimport SwiftUI struct ContentView: View { var body: some View { NavigationView { LoginForm(onLoginButtonPress: { username, password in // Implement your custom login functionality here print(\u0026quot;Login button tapped\u0026quot;) print(\u0026quot;Username: \\(username), Password: \\(password)\u0026quot;) // For example, you might perform authentication and navigate to the next screen }, onResetPasswordPress: { // Implement your custom reset password functionality here print(\u0026quot;Reset password requested.\u0026quot;) // For example, you might navigate to a password reset screen or show a reset password prompt }) .navigationBarTitle(\u0026quot;Your App\u0026quot;, displayMode: .large) } } } For onLoginButtonPress, we print the username and password when the login button is tapped. In a real-world scenario, you\u0026rsquo;d likely perform authentication here and navigate to the next screen upon successful login.\nFor onResetPasswordPress, we print a message indicating that a password reset has been requested. In practice, you might navigate to a password reset screen, show a password reset prompt, or perform any other relevant action.\nSummary In this article, we explored the creation of a reusable LoginForm component using SwiftUI. We learned about using @State for local, mutable storage and two-way data binding with user interface controls, such as TextField and SecureField. We also discussed the flexibility and adaptability of the LoginForm component through optional closure parameters for handling login and password reset actions. SwiftUI\u0026rsquo;s declarative approach and powerful features, such as property wrappers and bindings, make it easy and efficient to build modular and reusable components for user interfaces. As you continue to delve into SwiftUI, you\u0026rsquo;ll find that it greatly simplifies app development and promotes consistent user experiences across your applications. Keep exploring and expanding your SwiftUI knowledge, and you\u0026rsquo;ll be well-equipped to create fantastic apps that delight your users.\n","date":1679205145,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679205145,"objectID":"1458fd8067825647d716ad18572a0721","permalink":"https://www.ashwinnarayan.com/post/reusable-forms-swiftui/","publishdate":"2023-03-19T13:52:25+08:00","relpermalink":"/post/reusable-forms-swiftui/","section":"post","summary":"I’ve been recently doing a lot of programming using Swift and I’m quite enjoying how intuitive it is to pick up. It also helps that SwiftUI generally produces good looking user interfaces with less effort than other things I’ve tried.","tags":["programming","ios"],"title":"Reusable Forms in Swiftui","type":"post"},{"authors":[],"categories":[],"content":"I recently got into blockchain development focused on the Solana blockchain. I\u0026rsquo;ve been learning to build both Rust smart contracts and React based frontends. To see what I\u0026rsquo;m working on, subscribe to me at Solana Dev Journal.\nSolana Airdropper NFT Minter Kudos Program ","date":1659584216,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659584216,"objectID":"82d77e4a47b2ea46a7010c52987bf7e2","permalink":"https://www.ashwinnarayan.com/project/blockchain/","publishdate":"2022-08-04T11:36:56+08:00","relpermalink":"/project/blockchain/","section":"project","summary":"My Blockchain projects.","tags":[],"title":"Blockchain","type":"project"},{"authors":[],"categories":[],"content":"Introduction The first half of 2022 has not been kind to the world of crypto. Everyone expects a recession, cryptocurrency valuations are crashing; crypto firms file for bankruptcy every other week and many are predecting a \u0026ldquo;crypto winter\u0026rdquo;. As bad as things may seem, many would argue that the hype driven valuations crypto-currencies and associated projects were unsustainable, and had to come down eventually. Regardless, now that a lot of the hype and noise have faded, I feel that it is a good time to dive into the technical aspects of crypto currency technology with an academic mindset and learn about how it works.\nBlockchains and Smart Contracts The mathematics behind cryptocurrencies and blockchains have fascinated me since since 2012 - when I first heard about Bitcoin. Bitcoin pioneered the idea of a decentralized ledger of transactions of virtual tokens. However, modern blockchains have come a long way since then. In addition transactions of virtual tokens, blockchain today allow execution of arbitray logic on the blockchain - i.e., smart contracts. The mathematics of cryptography is what makes these features of blockchains possible.\nCyrptographic Hash Functions Cryptographic hash functions (CHFs) are mathematical functions take data as input and produce a \u0026ldquo;fingerprint\u0026rdquo; that is pre-image resistant - i.e. it is difficult to know what you put into the function given the output of the function.\nCHFs also have a few other properties. It\u0026rsquo;s difficult to find two inputs that have the same hash value and small changes to the file results in large changes to the hash.\n~ % echo \u0026quot;Hello\u0026quot; | md5sum\r09f7e02f1290be211da707a266f153b3 -\r~ % echo \u0026quot;Hellp\u0026quot; | md5sum\ra907206b6e6bf63124d4fa1e499eac8c -\rPublic Key Cryptography Public key cryptography lies at the foundation of how many blockchains work. These cryptographic systems uses two sets of numbers or \u0026ldquo;keys\u0026rdquo; for each person who wants to communicate. One key is kept a secret while the other is visible to everyone. If I want to send an encrypted message to Albert Einstein, I use a mathematical function that takes Einstein\u0026rsquo;s public key and the message as input and produces an encrypted message. The encrypted message will look like random noise to anyone except Einstein (well his computer at least) who can use his secret key with a mathematical decryption function to decrypt the message.\nDigital Signatures Public / Private keypairs can also be used to produce what are called digital signatures that prove that the person who owns the private key has written (or at least has signed) a message. Digital signature schemes first generate a hash of a document using a cryptographic hash function and then encrypt the hash using your private key. Anyone else can then verify that it is indeed signed using your private key by decrypting the signature using your private key and comparing it to the hash of the document.\nHow Bitcoin Works, Briefly Each transaction on the Bitcoin network is written in a small scripting language. Bitcoin wallets - which are essentially a secret / public keypair - sign and send transactions to computers on the internet that are running code to verify blocks of tranasactions. These computers batch together transactions into blocks and try to find a number to add to a block of transactions (called a nonce) so that the cryptographic hash (SHA-256) of the block and the nonce has a specific number of leading zeroes. Finding the nonce is difficult to do because the brute-force method of searching through all possible combinations is the best way we know.\nHowever, because of how cryptographic hashes work, it is easy to verify that the hash of the block with the nonce has the required number of leading zeroes. Therefore, the hash is proof that someone has done the work to verify the transaction. In the Bitcoin network, each block also contains the hash of the previous block so that we know the order in which the blocks were verified. The official ledger of transactions is the longest chain of blocks that have been verified by computers (miners) this way. In return for verifying transactions, the wallet that first verifies a block is rewarded with the fees of all the block\u0026rsquo;s transactions and a small amount of newly minted Bitcoin.\nHow Smart Contracts Work, Briefly Smart contracts are an extension of the blockchain to transactions other than sending tokens between accounts. Bitcoin\u0026rsquo;s scripting language is intentionally limited (i.e. it is not Turing Complete). Blockchains like Ethereum implement a Turing complete scripting language that allows the contract to store state and perform arbitrary calculations. This lets you make more complicated things on the blockchain. So a smart contract is essentially code which instead of executing on your computer is executed on other computers along with some cryptographic calculations to verify what the code did. This computation costs money (miners or validators need to pay for electricity) and gas fees are the reward that validators on the blockchain get for executing the smart contract logic.\nSummary Blockchains essentially solve the problem of carrying out calculations and maintainings ledgers in a decentralized, trustless way. Rather than trusting a central authority (like a bank) to honestly keep track of your money, blockchains rely on mathematical rules which when correctly followed ensure that the probability of the ledger of transactions being honest is very high. However, the cost of a trustless system if a lack of recourse if you do not follow the rules. For instance, if your private keys are leaked you cannot retrieve your tokens from the thief because there is no \u0026ldquo;central authority\u0026rdquo; who can restore your wallet.\nReferences https://www.cbsnews.com/news/celsius-bankruptcy-filing-most-activity-still-paused/ https://fortune.com/2022/07/08/voyager-crypto-bankruptcy-protection-next-steps-life-savings/ https://www.forbes.com/sites/jonathanponciano/2022/07/14/crypto-winter-watch-all-the-big-layoffs-record-withdrawals-and-bankruptcies-sparked-by-the-2-trillion-crash/?sh=4eb8957020f5 https://www.youtube.com/watch?v=bBC-nXj3Ng4\u0026amp;t=906s Bitcoin Scripting Language https://www.youtube.com/watch?v=GU4igNeYr-Q https://en.wikipedia.org/wiki/Cryptographic_hash_function https://www.docusign.com/how-it-works/electronic-signature/digital-signature/digital-signature-faq ","date":1659431734,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659431734,"objectID":"c8eed6e899bbfd5366383f7f892254b5","permalink":"https://www.ashwinnarayan.com/post/blockchains-as-i-understand-it/","publishdate":"2022-08-02T17:15:34+08:00","relpermalink":"/post/blockchains-as-i-understand-it/","section":"post","summary":"Introduction The first half of 2022 has not been kind to the world of crypto. Everyone expects a recession, cryptocurrency valuations are crashing; crypto firms file for bankruptcy every other week and many are predecting a \u0026ldquo;crypto winter\u0026rdquo;.","tags":["blockchain","cryptography"],"title":"Blockchains as I Understand It","type":"post"},{"authors":[],"categories":[],"content":"I\u0026rsquo;ve been doing early morning photo walks lately to replace my \u0026ldquo;wake up and scroll the phone\u0026rdquo; habit. In addition to getting a bit of exercise in I also get to see nice scenery and take photos! I live near one of the entrances to Singapore\u0026rsquo;s Rail Corridor. Today morning, I decided to walk along a section of it and take as many photos as I can.\nI intended to wake up at 6.00 a.m., but it was 6.20 by the time I managed to shake off all my sleepiness. I was a little apprehensive about the weather as this week has been unusually rainy and cloudy. However, the sky was already light orange when I set out. Thin, wispy clouds stretched out across the eastern horizon. I took the shortest route to the main road from where I could see the sky. Majestic shafts of light were already shining through breaks in the cloud cover.\nShafts of light\rI like this time in the morning when the sky is beginning to get lighter, but the streetlamps haven\u0026rsquo;t turned off yet. It feels like the lamps are clinging on to that last bit of night, hoping that it will last just a little longer.\nThe lamps were still shining, and the wispy clouds were casting shadows in the sky.\rDawn time skies have always embodied a sense of evanescence to me. The light and shadows changed every time I looked up. The shafts of light soon faded, and the sky brightened. I could see more of the golden morning light in the sky.\nThe lamps were still shining, and the wispy clouds were casting shadows in the sky.\rThe clock tower.\rThe air was cool but humid, and my glasses were covered in a permanent fog from mask-breath. Ferns, tall grasses, and overgrown vines lined the entrance to the rail corridor. Tall trees occasionally rose above the greenery. Skyscrapers and residential buildings towered above the trees on either side of the walkway. Some of the taller buildings were already beginning to catch a bit of sunlight. The waning gibbous moon was visible high in the sky, unobstructed by clouds. Despite its notoriety as a difficult subject to capture, my camera proved capable enough to capture some surface detail.\nThe moon was still bright in the sky.\rSome of the surface detail on the moon is visible here.\rA short walk brought me to a futuristic looking bridge that connected either side of the rail corridor. I noticed that the lamps were finally off. The morning was officially here.\nLamps are finally off. The morning is here.\rThe sun rose behind a building on the horizon. The sky was starting to get really bright, and its light was glinting off the glass windows on many nearby buildings.\nThe sun finally shows itself.\rThis plant looked really cool against the sunrise.\rSingapore is generally hot, but mornings are occasionally cold enough for dew drops to form. Today was one of those mornings.\nMany of the plants lining the road had dew drops clinking to the leaves.\rBy the time I reached the first exit on this section of the rail corridor, the sun had fully risen. That was my cue to get breakfast.\nBright blue sky.\r","date":1650593693,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650593693,"objectID":"1cb80d0d7f712e71af02ebd643112380","permalink":"https://www.ashwinnarayan.com/post/a-morning-walk-rail-corridor/","publishdate":"2022-04-22T10:14:53+08:00","relpermalink":"/post/a-morning-walk-rail-corridor/","section":"post","summary":"I take a morning walk along the rail corridor and take some photos of the sunrise.","tags":["photography"],"title":"A Morning Walk Along The Rail Corridor","type":"post"},{"authors":[],"categories":[],"content":"Introduction Now that I\u0026rsquo;ve submitted my PhD thesis for examination (finally!) I can spend some time fiddling around with things that are unrelated to it. After a hiatus of several months I\u0026rsquo;m finally back to playing with Haskell.\nOne of the things that make Haskell notoriously hard and non-intuitive to learn is the idea of functions that act on other functions (higher order functions). Folds were the first thing that really made things fit together in my mind and helped me understand the strengths of functional programming and why people rave about elegance in haskell.\nHaskell has two types of folds: the left fold and the right fold with slightly different function signatures. Folds take a function that takes two arguments and returns a third (a -\u0026gt; b -\u0026gt; a), a value that can be considered a \u0026ldquo;seed\u0026rdquo; value, and a list. For the right fold, the seed has to be of the same type as the second argument of the function and the list elements have to have the same type as the first argument of the function. For the left fold, this is reversed. The seed has to be of the same type as the first argument to the function and the list elements have to be of the same type as the first argument of the function.\nfoldl :: (a -\u0026gt; b -\u0026gt; a) -\u0026gt; a -\u0026gt; [b] -\u0026gt; a foldr :: (a -\u0026gt; b -\u0026gt; b) -\u0026gt; b -\u0026gt; [a] -\u0026gt; b Folds work like knocking down an arrangement of dominoes. It takes the seed value and the first element in the list and applies the function you have it. Then it repeatedly applies the function to the result and the next item in the list until all items in the list are consumed.\nThe Left Fold - Illustrated graph TD BN[\u0026quot;B[N]\u0026quot;] --- FN FN[fun :: b -\u0026gt; a -\u0026gt; b] -.- |\u0026quot;B[N-1]\u0026quot;|F2 FN --- AN[\u0026quot;A[N]\u0026quot;] F2[fun :: b -\u0026gt; a -\u0026gt; b] --- |\u0026quot;B[1]\u0026quot;|F1 F2 --- A1[\u0026quot;A[1]\u0026quot;] F1 --- S[\u0026quot;B[0]\u0026quot;] F1[fun :: b -\u0026gt; a -\u0026gt; b] --- A0[\u0026quot;A[0]\u0026quot;] The Right Fold - Illustrated graph TD BN[\u0026quot;B[N]\u0026quot;] --- FN FN[fun :: b -\u0026gt; a -\u0026gt; b] -.- |\u0026quot;B[N-1]\u0026quot;|F2 FN --- AN[\u0026quot;A[0]\u0026quot;] F2[fun :: b -\u0026gt; a -\u0026gt; b] --- |\u0026quot;B[1]\u0026quot;|F1 F2 --- A1[\u0026quot;A[N-1]\u0026quot;] F1 --- S[\u0026quot;B[0]\u0026quot;] F1[fun :: b -\u0026gt; a -\u0026gt; b] --- A0[\u0026quot;A[N]\u0026quot;] Applications Summing lists A standard illustrative example is how a fold can be used to sum a list.\nFollowing the diagram, foldl (+) 0 [1, 2, 3, 4, 5] would evaluate as 15. The fold function applies the (+) operator to 0 and the 1 (the first element). Then apply (+) to the result and the second element in the list and so on until we get the final result.\nIntegration A neat extension to summing lists is numerical integration. The simplest integral of an signal $x[t]$ (represnted by a list of values) with a sampling time $\\Delta T$ can be expressed very simply as a fold (combined with a map).\nThe equation\n$$ S = \\sum_{i=0}^{N} x[i] \\cdot \\Delta T $$\nTurns into\nsimpleIntegral :: Double -\u0026gt; [Double] -\u0026gt; Double simpleIntegral dT fvals = foldl1 (+) (map (*dT) fvals) Here, foldl1 is a version of fold that takes the first element of the list as the seed.\nScans and Filtering From the illustrations of the left and right folds you can see that the folds produce a set of intermediate results that get fed back into the function. When having the intermediate results are useful, we have scan. scan is a fold that returns the intermediate results as a list rather than just the final result. This is useful in a lot of filtering operations; for instance to calculate the exponential moving average of stock prices.\n$$\\begin{equation*} S_t=\\begin{cases} Y_1 \\quad \u0026amp;\\text{if} , t = 0 \\\\ \\alpha Y_{t} + (1-\\alpha) S_{t-1} \u0026amp;\\text{if} , t \\gt 0 \\\\ \\end{cases} \\end{equation*}$$\nThe EMA equation can be implemented as:\nema :: Double -\u0026gt; [Double] -\u0026gt; [Double] ema alpha vals = scanl1 (\\prev curr -\u0026gt; alpha*curr + (1-alpha)*prev) vals Summing Up Interestingly, the Complementary Filter - often used to measure tilts using IMU sensors follow a very similar format and folds can be used to implement these type of filters. This is the biggest strength of using higher order functions. They capture commonly used patterns of calculations in a very general way. If you use a fold, the Haskell compiler will produce highly optimized code to run your calculation. If you were to use hand-written loops - especially in programming languages like C/C++ - you might write code that is inefficient or segfaults. Higher order functions are also very general. Haskell\u0026rsquo;s foldl and foldr works on any data type at all. This is the reason the type signatures for these functions don\u0026rsquo;t mention any concrete types. While I\u0026rsquo;ve only applied these functions to Double data types, you can use this pattern on Strings, integers and on random custom defined data types. Higher order functions are also elegant. Rather than writing an ugly loop, I could write a one liner to do integration or complementary filtering. This is actually quite similar to how MATLAB scripting lets me express complicated operations like a matrix multiplication with a single operator.\nReferences Learn You a Haskell Hutton, Graham. \u0026ldquo;A tutorial on the universality and expressiveness of fold.\u0026rdquo; Journal of Functional Programming 9.4 (1999): 355-372. Exponential Moving Average ","date":1641034465,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641034465,"objectID":"a264d2bd1c9a3844e344338d5d2fcc6d","permalink":"https://www.ashwinnarayan.com/post/a-study-on-haskell-folds/","publishdate":"2022-01-01T18:54:25+08:00","relpermalink":"/post/a-study-on-haskell-folds/","section":"post","summary":"I try to wrap my head around one of Haskell's main higher order functions.","tags":["programming"],"title":"Haskell Folds Illustrated","type":"post"},{"authors":[],"categories":[],"content":"All images were shot on analog film using an old Minolta X-700 camera. I\u0026rsquo;m putting up the photos here in a zoomable format because many of these photos are best viewed on a big screen. Hover over the image and click to open them in full screen. To see more of my photography, follow me on Instagram\nOutside the tunnel that leads from the MRT station the Rail Corridor.\rThe green space near Ghim Moh Market.\rView of the MRT Station from Crossing.\rSunset on the Park Connector.\rSunset on the Park Connector.\rA really colorful tree on the Park Connector.\r","date":1625189439,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625189439,"objectID":"f9185cfe4f91367b5a476e42b4453d25","permalink":"https://www.ashwinnarayan.com/project/buona-vista-park-connector/","publishdate":"2021-07-02T09:30:39+08:00","relpermalink":"/project/buona-vista-park-connector/","section":"project","summary":"Photos from around Buona Vista","tags":["photography"],"title":"Buona Vista","type":"project"},{"authors":[],"categories":[],"content":"For about five years, I lived in a city called Ipoh. My room at the time had access to some of the best sunsets I\u0026rsquo;ve ever seen in my life. I would capture what I could using a small digital camera that I had on hand. It\u0026rsquo;s probably the reason that skies and sunsets are my favorite subjects to photograph. For more photos, check out my Instagram.\nLens Flare\rWindow at Dusk\rOrange Sky\rViolet Dusk\r","date":1622015360,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622015360,"objectID":"ac65deb2747231c6b94ad329ace0272a","permalink":"https://www.ashwinnarayan.com/project/ipoh-skyscapes/","publishdate":"2021-05-26T15:49:20+08:00","relpermalink":"/project/ipoh-skyscapes/","section":"project","summary":"Photographs from My Years in Ipoh","tags":[],"title":"Ipoh Skyscapes","type":"project"},{"authors":[],"categories":[],"content":"As a beverage, coffee smells incredible, keeps you awake and alert, and might even improve your working memory. But its chemical effects on the body are only a small part of why coffee means so much to me. For me, coffee is also a social beverage. Many of the most amazing conversations that I\u0026rsquo;ve had at work were over coffee. Brew a cup, grab a seat, and the ideas start flowing. If alcohol is a crowbar that pries open the doors of conversation, then coffee is a lock picking kit. With a bit of skill, it makes the doors spring open without any brute force.\nBut the most important aspect of coffee is the routine that it brought into my life over the last year. Nearly every morning, I grab a light breakfast from a nearby bakery, brew myself a pour-over from fresh, hand-ground beans before sitting down at my table to reflect on, write about and plan out the rest of my day. This routine played an essential part in keeping me sane during the last year and a half of on and off lockdowns and other restrictions caused by the global pandemic. To me, coffee represents a small island of peace—a few moments of calm thought before I head out into the chaos that is the world outside.\nMy taste in coffee has evolved over the years. Instant coffee was my go-to (blasphemy!) during the first year of my Ph.D. This changed after a friend brought back a sample of Vietnamese coffee and a Phin filter after his holiday in the country. Since then, I\u0026rsquo;ve experimented with several types of brewing apparatus, including many of the usual suspects like the Chemex, Moka Pot, and the Aeropress. Eventually, I found that the Hario V60 fit my life the best, and I built my morning routine around it.\nMy Morning Coffee Recipe Materials Hario V60 and filter paper. Whole coffee beans. Weighing scale. Boiling water. Technique ","date":1621649334,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621649334,"objectID":"0290ce4fdf476f9759427b25ee1d43bc","permalink":"https://www.ashwinnarayan.com/project/coffee/","publishdate":"2021-05-22T10:08:54+08:00","relpermalink":"/project/coffee/","section":"project","summary":"What coffee means to me, recipes and more.","tags":[],"title":"On Coffee","type":"project"},{"authors":[],"categories":[],"content":"\rSpoiler Warning: Contains spoilers for all of season 1.\rTanjiro Kamado, The Inspiring Stoic Hero Demon Slayer: Kimetsu no Yaiba had many messages that resonated with me. At the top of the list is the story of the Stoic hero that takes responsibility for his life and meets challenges with grace. Tanjiro Kamado has tragedy and death forced on him by events that were beyond his control. Muzan killed his whole family except for his sister, who was turned into a demon. It was clear that he was horrified and angry when he saw what happened to his family. But instead of becoming bitter, he accepts and channels his emotions into positive action. He nurtures his drive to prevent the same tragedy from affecting anyone else by training to become a demon slayer himself. He takes responsibility for the things that happened to him, even though it was not his fault.\nHowever, despite being motivated by a strong desire to prevent demons from killing people, Tanjiro never loses sight of his own humanity. This shows in most of his interactions with the other characters in the story. Most people who meet him are left inspired and comforted. However, his brilliant personality shines through the most during his interactions with demons. He feels for the demons, who were often made against their own will by Muzan. At times, he feels respect for their skills - like during the fight with the drum-wielding, gravity-bending demon. And in their final moments, Tanjiro often chooses to comfort the demons he killed rather than look at them with anger or disgust. The most impactful moment for me was when he switched techniques mid-attack to lessen the pain for a demon who was just enslaved by Rui.\nI think Tanjiro\u0026rsquo;s character resonated with me so much because he has many similarities to the ideal version of me in my head that I aspire to be. I have run away from the problems in my life many times, feeling overwhelmed or terrified. Most of the time, running away did not help. When reflecting on how I could have handled these situations better, I\u0026rsquo;ve often wished I could face life\u0026rsquo;s challenges with as much equanimity and optimism as Tanjiro does.\nSeeing Tanjiro grow by repeatedly facing terrifying challenges that were sometimes a little beyond his ability was the best part of the show for me. He\u0026rsquo;s not afraid to ask for help when challenges are overwhelming, and he gives it his best shot every time. Towards the end of the first season, I found myself drawing strength from his character. Indeed, the challenges in Tanjiro\u0026rsquo;s story are carefully curated for plot reasons. However, I think that the real message in the story is that you can choose to take on the right challenges that will help you, sometimes with the help of a trusted mentor.\nListening to the Voice in My Heart Another part of Tanjiro\u0026rsquo;s character that struck a chord with me was his enthusiastic recommendation to \u0026ldquo;listen to the voice in your heart .\u0026rdquo;\nIn my early twenties, I was heavily influenced by rationalist/skeptic literature. Convinced that emotions and feelings were irrational and sometimes unnecessary, I grew used to ignoring them. Instead, I would try to do the right thing as defined by rational analysis. This led to me making a lot of \u0026ldquo;right\u0026rdquo; but unsatisfying decisions. I\u0026rsquo;ve recently grown to realize that living my life in this way is deeply unfulfilling. These days, I think of my feelings as a sense - similar to touch or hearing - that tells me how to live a life that I will find enjoyable and fulfilling. The sense warns me when something I do doesn\u0026rsquo;t quite sit right with my internal values and makes me feel good when it fits. By stifling this sense, I realized that I was basically suppressing a core part of my personality. \u0026ldquo;Listening to the voice in my heart\u0026rdquo; is such a poetic way to express this idea. Indeed, once I started listening to my heart more, I found life so much more colorful and satisfying. I started enjoying social events more and finding more joy in getting to know people. Sometimes, I still think that I don\u0026rsquo;t listen to my heart\u0026rsquo;s voice as much as I should.\nSpecial Mentions Apart from the messaging, I also enjoyed the creative powers of the demons. The spacetime bending drum demon and the \u0026ldquo;arrow\u0026rdquo; demon was particularly inventive and well-executed. Zenitsu is an interesting character. Despite being annoying at times (most of the time?), I cannot deny being wowed by his first on-screen kill. Of course, Episode 19 is the star of the first season. The build-up was long and slightly tested my patience, but it was so worth it. It was probably the most satisfying on-screen anime fight scene that I\u0026rsquo;ve watched with a slow build and a spectacular, climactic finish.\n","date":1621492380,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621492410,"objectID":"0c64103bb1df3f7c9eafc5732164d3a1","permalink":"https://www.ashwinnarayan.com/post/messages-from-demon-slayer/","publishdate":"2021-05-20T14:33:00+08:00","relpermalink":"/post/messages-from-demon-slayer/","section":"post","summary":"I talk about the messages from Demon Slayer: Kimetsu no Yaiba that inspire me.","tags":[],"title":"Messages from Demon Slayer: Kimetsu no Yaiba","type":"post"},{"authors":[],"categories":[],"content":"Growing up, I was frequently reminded of the importance of reading the news. My family was always subscribed to at least one (physical) newspaper, and magazine subscriptions were not uncommon. A year into the COVID-19 pandemic, however, I\u0026rsquo;ve decided not to read the news anymore. Most local news websites are blocked on all my devices, in addition to aggregators and social media websites where links to these news sites are shared.\nThe reason? Mental health. Over the last few months, I found myself repeatedly checking news sites for updates related to the COVID pandemic. The habit got worse as the situation started to go downhill in India. On most days, I spent between 30 and 45 minutes in bed in the mornings, doom-scrolling on various news sites.\nNegative news sells. And as the pandemic worked its way around the globe, the news articles often only highlighted the worst aspects. I found myself increasingly obsessed with the negative news. Toxic, misinformed, or vitriolic comments on news websites that allowed them didn\u0026rsquo;t help much either.\nI noticed that I\u0026rsquo;d started feeling a general sense of anxiety and unease. Sometimes, I\u0026rsquo;d feel a sense of danger and hostility during benign activities like walking to work.\nAfter failed experiments with partial blocks and gradual weaning, I realized that the only real solution was to just stop reading the news every day. A few days ago, I went through the headlines on a website I frequented and asked myself:\nAre there any actions I could have taken from knowing this news that could have made my life better? What if I only found out about this a month from now? What if I never read this article? I realized that for 99% of the headlines, there wasn\u0026rsquo;t anything useful I could do after I read it. And for most of the headlines, it would not matter at all if I never read it.\nThe small 1% of deadlines that actually mattered were announcements about the changes in COVID rules (group sizes, travel restrictions, etc.). For these announcements, I found that my needs were met by subscriptions to the official government WhatsApp and telegram groups and a quick check of the main website. These sources gave me the information I needed without any emotional messaging and interpretation that news websites offered.\nHave your stress levels increased during the pandemic? If you\u0026rsquo;ve been reading a lot of news online, that could be part of the problem. Consider avoiding, or failing that, blocking these websites from your devices.\nPersonally, I found my days calmer, happier, and more productive after I cut down my news consumption.\nIf you\u0026rsquo;re looking for an easy way to block websites across all your devices, I can recommend the tool called Freedom. I bought a lifetime membership a year ago at the start of the pandemic. It\u0026rsquo;s probably the best investment that I made in myself last year.\n","date":1620634620,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620634620,"objectID":"ae31b0b790ee79f0a31ccd621aca456c","permalink":"https://www.ashwinnarayan.com/post/stop-reading-the-news/","publishdate":"2021-05-10T16:17:00+08:00","relpermalink":"/post/stop-reading-the-news/","section":"post","summary":"Growing up, I was frequently reminded of the importance of reading the news. My family was always subscribed to at least one (physical) newspaper, and magazine subscriptions were not uncommon. A year into the COVID-19 pandemic, however, I\u0026rsquo;ve decided not to read the news anymore.","tags":[],"title":"Why I Stopped Reading the News During the Pandemic","type":"post"},{"authors":[],"categories":[],"content":"About the Book As a heavy user of computer technology for over a decade, I\u0026rsquo;ll be the first defend its benefits. My familiarity with the internet is responsible for a significant chunk of my knowledge and much of my critical thinking abilities. Through personalities like Carl Sagan and Michael Shermer, it also played a big part in me developing an intense interest in science and eventually pursuing a career in it.\nWhen something is so useful, you tend to be slow to notice its downsides. In 2016, I started to feel that my technology use was filling large chunks of my time with un-productive habits, preventing me from doing many of the cool things that the internet told me was possible. I often found myself doom scrolling on websites like Facebook, Instagram or reddit at the end of my workday and during weekends. My habit of mindless browsing was taking away time that I could be putting into developing new skills that I wanted to develop. In other words, I was starting to feel like I was losing control over my time.\nI found Digital Minimalism when I was searching for methods that would help me stay on task when I was using tech. The book contains very practical advice on how to change habits surrounding technology usage and halped me free up large chunks of my time for pursuits that I find more satisfying.\nIf you\u0026rsquo;re the kind of person that finds themselves deep in a reddit thread about annoying habits of co-workers ten minutes after opening up your laptop for responding to an email, this book might help. For me, the most useful feature of the book is how it builds a coherent theory of how humans interact with technology. Newport takes many different negative aspects of unstructured technology use, and brings it together under one theoretical framework and uses this framework to dispense specific advice about how to make things better.\nSummary Humans are Biologically Wired in Certain Ways The mentions three key things that human brains have evolved to find satisfaction in.\nReal-World Social Interactions: Interacting with people in the real world involves processing a dense, \u0026ldquo;high-bandwidth\u0026rdquo; stream of information that engages multiple senses. Newport suggests that as a social species, humans have evolved to find satisfaction in such high-bandwidth social interactions. Occasional Solitude: Newport cites scientific studies to build the case that the brain does important types of reflective thinking when you are alone and that this might be very important to develop as a person. He also gives some case studies of famous people who have found value in developing new ideas for their work in solitude. Building Physical Things: As a species that evolved to use tools, Newport argues that humans are wired to find satisfaction in seeing physical consequences of our efforts. Modern Tech Optimizes for Capturing and Holding Human Attention The book highlights the fact that many technologies such as mobile apps and social media websites are precisely engineered to capture and maintain as much of our attention as possible. Since the users\u0026rsquo; attention is the source of revenue for many apps and websites, it is natural for them to optimize themselves for how much attention they can capture.\nSocial Interactions: Social media captures your attention by providing social approval (which the brain craves) but through low bandwidth channels such as \u0026ldquo;likes\u0026rdquo; or \u0026ldquo;upvotes\u0026rdquo;. The book argues that these signals of social approval keep our brains engaged in the app, leaving us with less time for real social interactions but leave us dissatisified because of their low bandwidth nature.\nSolitude: Constantly being \u0026ldquo;plugged-in\u0026rdquo; into these apps and websites prevents our brains from getting solitude from time to time, depriving it of time to reflect. This could have negative effects such as increasing anxiety and less time for developing creative ideas.\nPhysical Hobbies: Time spent using tech also necessarily means less time for developing hobbies that involve building physical things. Newport argues that activities like programming or building websites don\u0026rsquo;t quite satisfy our brains in the same way as building a fence or a house.\nThe Book\u0026rsquo;s Recommendation To mitigate these negative affects of technology, the book recommends adopting a philosophy of technology use that guides which technologies to adopt and which to avoid. This requires first getting a good idea of your values and goals in life and only adopting the use of technologies that align with your values and goals.\nThe book warns that one-off hacks like switching to a smart-phone or blocking time-wasting websites won\u0026rsquo;t work on their own without an over-arching philosophy.\nDigital Minimalism Cal Newport\u0026rsquo;s calls his preferred philosophy of technology use Digital Minimalism. Digital minimalism starts with a one month technology detox during which you cut out all non-essential technology from your life. The month is used to evaluate whether any of the tech you used to use actually aligned with your goals and values.\nRecommended Values The book also goes one step further and uses what science knows about human nature to recommend some specific values that may be useful to adopt when dealing with technology.\nPrioritize Real-World Social Interaction: Use technology to increase the amount of time that you spend on face-to-face interactions with people. Schedule Solitude: Use the time that may be gained from cutting out distracting tech, spend more time on your own and let your brain get a healthy amount of time to reflect quietly on things. Physical Hobbies: Consider adopting hobbies that involve creating and shaping material with the hands. Verify Before Trusting Since the source of income for much of the tech that we use is our attention, it will naturally optimize for capturing and holding our attention for as long as possible even if it is not in our interest. So the book recommends treating all new tech first with suspcion and letting the tech into our lives only after we have determined that it aligns with our goals and values. Periodically evaluating tech that you\u0026rsquo;ve already let in to make sure that its behaviour has not changed may also be a good idea.\nClosing Thoughts I think that the book gets right the idea that we need a philosophy of technology use so that it does not prevent us from achieving our goals. However, I think that some of the recommended values may be specific to the author. In particular, I find that writing code or making PCBs often scratch my creative itch just fine. In fact, I have an aversion to sports or things that make me feel physically winded or sweaty. I think that the most valuable takeaway from the book is that it\u0026rsquo;s a good idea to make sure that the technology and tools that you use align with your values and goals. What those values and goals should be is up to you.\n","date":1606963529,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607760269,"objectID":"b37cbacbda9b16cd73c259144d65d025","permalink":"https://www.ashwinnarayan.com/post/digital-minimalism/","publishdate":"2020-12-03T10:45:29+08:00","relpermalink":"/post/digital-minimalism/","section":"post","summary":"About the Book As a heavy user of computer technology for over a decade, I\u0026rsquo;ll be the first defend its benefits. My familiarity with the internet is responsible for a significant chunk of my knowledge and much of my critical thinking abilities.","tags":["book summaries","self-improvement"],"title":"Digital Minimalism","type":"post"},{"authors":[],"categories":[],"content":"May 31, 2020 April 17, 2020 April 11, 2020 Earlier ","date":1590387018,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590910878,"objectID":"d875a740c7a8a9cbf06f05a7aa47a9e2","permalink":"https://www.ashwinnarayan.com/project/music/","publishdate":"2020-05-25T14:10:18+08:00","relpermalink":"/project/music/","section":"project","summary":"Amateur musical recordings.","tags":[],"title":"Music","type":"project"},{"authors":[],"categories":[],"content":"My Attempt at Following a Bob Ross Tutorial So after getting my new iPad, I tried to work through one of Bob Ross\u0026rsquo;s videos as soon as I could. Here\u0026rsquo;s my attempt at the one from season 14 episode 1.\nIn the spirit of Bob\u0026rsquo;s technique, I tried making up stories about the things in my painting.\nThe empty boat was used by a traveler to cross the water body. But he didn\u0026rsquo;t secure it well enough. Now he has to walk for several hours to get home. The sky diver opened his parachute too late (he did not account for the mountain\u0026rsquo;s elevation) and will probably crash into the mountain too fast. Hopefully, the snow will cushion his fall. There\u0026rsquo;s a lone hiker on the mountain. He misjudged the slope. Shortly after the moment captured by the painting, he slips and slides all the way down. Let\u0026rsquo;s hope he\u0026rsquo;s able to call for help using his radio.\nThe mountain goat is enjoying the fabulous day.\nAn SR-71 Blackbird is flying by at greater than Mach 3. It\u0026rsquo;s sonic boom might trigger a minor avalanche.\nAm I doing this right?\nAnime Style Character Drawing The Cell Phone Tower A drawing of the evening sky with a cell phone tower visible. This one was a gift to my fiancee.\nDiyas A painting of lit diyas (diwali lamps).\n","date":1590385265,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590385265,"objectID":"ed8d659481cfdfbf24f862f810330927","permalink":"https://www.ashwinnarayan.com/project/artwork/","publishdate":"2020-05-25T13:41:05+08:00","relpermalink":"/project/artwork/","section":"project","summary":"My dabblings in digital art.","tags":[],"title":"Artwork","type":"project"},{"authors":[],"categories":[],"content":"Introduction Like many countries around the world, Singapore entered a lockdown (a \u0026ldquo;circuit-breaker\u0026rdquo; to use the local terminology) on April 4 to stem the rapid spread of COVID-19. Knowing how easy it is to get distracted from work and lose productivity at home, I made a commitment to myself at the start of the lockdown to use the extra time to improve myself. Specifically I wanted to improve my workflows for many of my daily tasks.\nA key part of the effort is my renewed commitment to TODO lists. I\u0026rsquo;ve made several attempts to integrate TODO lists as a habit into my life before, but the habit has never stuck. As a result, I use TODO lists quite loosely - i.e. when things get super hectic and I have no choice but to use them to keep me sane. Otherwise, I simply remember the big picture of what I want to get done. While this has led to me forgetting to do the odd task, I felt that my overall productivity was not significantly impacted. If I really want to remember something, I might stick a Post-It note on my work desk. However, I decided recently that this was not good enough for me for two reasons:\nI want to improve myself as a person. I want to take on more responsibilities and work and this is only possible if I improve this part of myself. So about a week into the lockdown, I decided to use TODO lists to track all my tasks for the next 30 days. If I saw real improvements in these 30 days, I\u0026rsquo;d keep the system. If not, I\u0026rsquo;d try to find a better one. I put some weight into the commitment by purchasing for myself a premium account in the todoist app. While the system felt awkward and cumbersome at the start, I began to notice tangible improvements at the two week mark. With a little experimentation, I was able to optimize TODO lists to work for me. Here\u0026rsquo;s what I learned from the 30 day experiment.\n1. Believe in the System In all my previous attempts, I started with a lot of skepticism about the effectiveness of using TODO lists. This time, I decided that I was going to proceed as though it was going to work. This seemed to make a big difference in how the experiment worked out. I observed straight away that I was more motivated to find ways to make the system work for me. In the past, I\u0026rsquo;d give up on the method when some small obstacle popped up (the app not having some small feature that I wanted for instance).\n2. Use it for Everything I read that this is similar to David Allen\u0026rsquo;s advice in his book \u0026ldquo;Getting Things Done\u0026rdquo;. It does help to capture in the list absolutely everything that you want to get done. Doing this meant that I did not need to keep a running list of all my tasks in my brain. I didn’t realize that keeping my task list in my head was generating a low background radiation of anxiety in my brain until I stopped doing it. Capture everything in your task list - both personal and work-related.\n3. Use a Cross-Platform System I\u0026rsquo;ve experimented with systems like the bullet journal before. While I do like the feeling of having a physical notebook to write down tasks in, I found that I became too dependent on the notebook. If I forgot to bring the notebook anywhere (which can happen), I got lost. Using a cross platform task tracking app that works on both the desktop and on the phone is more convenient and ensures that you\u0026rsquo;ll have your task list with you pretty much wherever you go.\n4. Check the List Before Starting Work Previously, I\u0026rsquo;d just sit down and start working on whatever floated to the top of my head at that moment. While this works great when you don\u0026rsquo;t have that many things to do, it may result in small things being forgotten and pushed to the last minute. In addition to making me more intentional about what I was doing, checking my list before starting work also made me more likely to finish off more of the small tasks before they accumulated to annoying levels.\n5. There\u0026rsquo;s a Time and Place for Specificity There\u0026rsquo;s a time and place for everything, but not now. -Professor Oak\nThe most important thing I learned is to choose the right level of specificity when entering tasks into the list. My first instinct was to overdo it. I made full use of the fact that you could nest subtasks pretty deep in todoist (4 levels) and wrote big picture items into the list and started breaking it down into smaller steps. Then I started doing the task and found out that the steps that I wrote down were either too optimistic completely unnecessary. However, when I tried only writing down the big picture tasks, they became too big and scary and I didn’t want to touch them. In the end what worked for me was to write down only big picture things when I first enter the task into the system. When I start working on the task, I click into it and start adding sub-tasks.\nAnother thing I learned about \u0026ldquo;sub-tasking\u0026rdquo; was not to add sub-tasks too far into the future. The further ahead I planned the more my plan deviated from reality and the more I had to delete what I wrote and replan.\n6. Choose the Right Level of Specificity On a related note to point 5, I recommend experimenting a bit to find the right level of task specificity for the subtasks. I experimented with breaking up large tasks into subtasks that took from 1 minute all the way up to a few hours. I found subtasks that took between 5 and 15 minutes to be the most rewarding. Anything smaller added too much overhead to the tasks. Anything longer exponentially decreased the probability that I’d start working on that task.\nChoosing a consistent level of specificity also solved the problem of unequal weighting of tasks for me. Checking off tasks is actually quite rewarding on its own. When the reward for checking off one big task that took 5 hours to do was the same as the reward for a two minute task, it gave me less motivation to tackle the big tasks. Once I started choosing a consistent level of specificity for the tasks that I checked off, larger tasks became naturally more rewarding than the smaller tasks and my productivity on larger tasks improved as a result.\n7. Consider Gamification There’s some evidence that gamification of tasks can help improve the motivation for completing them. I don’t think that gamification can work as a base motivation but it may help a little with the day to day motivation. For me, the simple points system on todoist adds a small touch of motivation without adding too much overhead.\n8. Attach it to Your Bedtime Routine Checking the list one last time before turning in is really helpful. It feels good to clear the schedule for the day and have a sense of resolution. I recommend doing this even if you haven\u0026rsquo;t finished everything on the list. Simply reschedule the unfinished items to the next day but get to zero tasks remaining for the day. Integrating it into my bedtime routine has also helped with my effort to avoid browsing the phone mindlessly in bed before going to sleep. I set a simple rule for myself: Once I clear the day\u0026rsquo;s list, I can\u0026rsquo;t use the phone anymore and must go to sleep.\n9. Don\u0026rsquo;t Let Perfect be the Enemy of Good This is related to me giving up on systems too early. I realized that I tend to try and find the perfect process to do things before even trying. While this is useful in many situations, it has sometimes led to me not doing things in the first place. If you have a proclivity for perfection, don\u0026rsquo;t let it get in the way of you trying new but imperfect systems. Just remember that you can always optimize later. The more important thing is to get started.\n","date":1590125450,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590296990,"objectID":"2739d80c0adec958155106116f575784","permalink":"https://www.ashwinnarayan.com/post/what-i-learned-about-todo-lists/","publishdate":"2020-05-22T13:30:50+08:00","relpermalink":"/post/what-i-learned-about-todo-lists/","section":"post","summary":"I used TODO lists for everything in my life for the last two months of the COVID-19 lockdown. Here's what I learned from the experience.","tags":["self-improvement","COVID-19"],"title":"On the Effective Use of TODO Lists","type":"post"},{"authors":[],"categories":[],"content":" Introduction Growing up in an Indian family, I had very little exposure to discussion and information about the stock market. People in India are generally less likely to invest in the stock market. Many view investments with suspicion. Indeed, most estimates put the percentage of the population that invest in stocks at 2-5% of the country\u0026rsquo;s total population [5, 6]. Unsurprisingly, investments were never really a topic of conversation in my home or in school growing up. The only remark I remember from my parents about it dismissed it as little more than gambling. School education in India is also lacking in this regard. Economics was either not taught or lumped in with other subjects such as history. I remember very little of economic theory actually being taught in school, especially for those who were aiming for engineering schools.\nI was introduced to the idea of investing during my PhD through some of the friends I made here in Singapore. Investing is relatively common here. It was interesting to see articles like this highlighting that around 33% of Singaporeans do not invest. Culturally, investing enjoys relative popularity here as a way to keep ahead of inflation and to grow savings. Always the scientist, I set out to understand the underlying principles behind investing in the stock market before I started. There is no dearth of articles on the internet with advice on getting started with investing in the stock market. However, a lot of the articles that I read left me unsatisfied as a scientist. Observations - like the fact that money loses value over time - were often presented as assumptions and discussions about the benefits of investing tended to be biased towards the investor; with the central point of most articles being that investing can grow your money. While I learnt quite a bit about investing, I was left with many unanswered questions. For instance, why does the assumption that money loses value over time hold? Who benefits from a healthy stock market apart from the investors?\nThese questions led me down a rabbit hole of academic articles about economic theory and monetary planning. I wrote this article for people who, like me, did not grow up in a culture of investing and would like to know of the raison d\u0026rsquo;être of stock markets. The article contains some of the information that helped me make an informed decision about whether I should invest in the stock market.\nInflation and Economic Growth The story starts with the assumption that money will lose value over time. Economists use the term inflation to refer to this phenomenon. When an economy experiences inflation, the prices of things increase over time. So, the same amount of money buys less things in the future than it buys today. Most countries experience a positive rate of inflation [4].\nCountries consider this a good thing. In fact, some countries even engage in something called “Inflation Targeting” to make sure that the rate of inflation remains at a low but stable and positive level. But if countries are willing and able to influence the rate of inflation, why do they target a positive inflation rate? Why not target zero? Or better yet, why not target a negative inflation rate and let money increase in value over time, and reward people who save their money?\nDeflation is when the prices of things decrease over time. That means money becomes more valuable as time goes on. The average person might consider this a good thing. If I save up money right now and just hold on to it long enough, I’ll be able to afford that expensive home or car eventually. But this effect of delaying purchases for the future appears to have a negative effect on the overall economy. Growth slows, unemployment rises, and businesses start to shut down as demand for the things that they make decreases. Deflation also increases the risk of a deflationary spiral - in which falling demand and prices and rising unemployment becomes a runaway positive feedback loop. Many economists think that such a spiral was responsible for the Great Depression of the 1930s.\nIs inflation better? A high rate of inflation is also considered a bad thing. If inflation is too high, the value of people’s savings decreases too fast and wages do not increase fast enough. This results in people hoarding physical goods. Hyper-inflation can also lead to a runaway positive feedback loop in the opposite direction.\nAs a result, keeping the economy on track is a balancing act. Countries target an inflation rate that is in the low single digits so that there is enough of a buffer zone between the current state of the economy and deflation and use regular updates to monetary policy to prevent runaway inflation. The United States for example targets a yearly inflation rate of 2%.\nIn other words, governments give more importance to price stability than anything else. Both deflation and high rates of inflation slow down economic growth and have negative effects while low rates of inflation offer price stability and controllability.\nGiven that modern economies tend to prefer inflation and actively try to maintain it, holding on to money means that the value of your money will decrease (albeit slowly) over time in most countries in the world. So, if people want to keep their savings from losing value, they need to do something with their savings other than hiding it under their pillow.\nBank Savings Accounts One way for people to save in an inflationary economy is to use a savings account in a bank that offers to periodically pay you a certain percentage of the money as interest. This is the form of savings that most people are familiar with. Some banks offer special “fixed deposit” accounts that you can put money into and take out only after a certain amount of time. If the savings account offered by the bank has a rate of interest that exceeds or is very close to the rate of inflation then your savings will keep most of their value over time. For many people this form of saving is perfectly fine. If people choose banks that are large and reliable, the risk of losing money is very low. And as long as you live within your budget, you’ll be perfectly happy person. This style of investment is good for people who are very risk averse or for people who plan to retire soon.\nThe opportunity cost of saving money like this is of course the fact that money invested in the stock market could potentially increase in value much faster than a bank savings account will allow. For instance, the value of the stocks in Google has increased by 25% since November 2018. This beats interest rates by a large amount. But the keyword here is “potentially”. When you put money into the stock market, there is also the risk that the money can be lost - sometimes entirely. Where does this money come from and where does it go? And why do stocks offer such large potential returns? To answer these questions, I need to go into why the stock market exists in the first place.\nBusinesses Need Capital Starting and running a business is no small task. Businesses typically need large amounts of money to get started. They may need office space, they may need to build factories and make expensive prototypes to perfect their technology. Sometimes businesses decide to expand by improving their products or making entirely new ones. One way to finance these costs is to use bank loans. This is in fact what a lot of companies do. However, the amount of money that banks can loan out is limited. Companies also need to pay an interest on the loans. So, if the company is working on something that will not produce a profit for some time, the interest on their loans can accumulate quite fast.\nSomewhere along the way people had the idea to raise money from regular people instead. However, rather than having people loan the business the money, the business would offer a small chunk or a share of itself in exchange for money. Once the business becomes profitable, the person with the share would be entitled to a portion of the profits. Partial ownership also granted other benefits. The shareholder could have a say in how the company was run and help choose managers. The stock market is a place that facilitates the buying and selling of these chunks of companies (for a fee of course). The Amsterdam Stock Exchange, established in 1602 is considered the oldest such place. The price of the share of a company is determined by the forces of supply and demand. Simply put, the value of stock is what people are willing to pay for it. If people think that a stock is valuable because the the company has the potential to grow, the stock gets more expensive because the demand for the stock is higher than the supply. If people think the company has no future, the stock\u0026rsquo;s value falls as more people are trying to sell the stock, increasing its supply.\nBusinesses benefit from this because they can quickly raise money at 0% interest. As long as they don’t part with more than 50% of the company ownership, they can even retain full control over what happens in the company. Many economists think that by letting more people participate in the economy, there is more money available for people to start businesses and make things. This leads to more growth as it encourages people make more new things and the overall ‘value’ of the economy increases (because now there are more things (knowledge, services, technology) in the economy.\nMost articles I’ve read talk about how investing is important because it lets you make money compared to just holding cash. But I feel that these articles are missing the more important point that having a stock market setup as a cornerstone of the world’s economic system could be the principal reason that human civilization has seen such amazing growth in knowledge and technology. This, in my view is a far more important reason to invest and to participate in the economy than the personal goal of getting more money. The stock market appears to be set up so that participating in it offers benefits to both businesses and the investors even if they do not know and care about the meta-goal of sustained growth of human civilization.\nThe Stock Market Gains Value in the Long Run While the sustained growth of human civilization is a fine goal, the most pertinent question for the individual investor is the risk of losing their money. If I buy stocks in a certain company and it folds, I do not get most of the money back. So what\u0026rsquo;s in it for the individual investor?\nWhile single stocks can lose value over time and even drop to zero, the stock market as a whole tends to rise in value over time. Stock markets have indices that track the value of a set of stocks over time. In a pattern that has remained consistent for decades, the market as a whole tends to gain value in the long run. While economic recessions like the one that happened in 2008 can reduce the value of stocks in the short term, in the long run (over the course of tens of years), they gain in value. The graph below shows the value of the total US stock market as represented by the Wilshire 5000 Price Index over time [8].\nMany such indices in other countries show a similar trend. For individuals then, the incentive is that even by \u0026ldquo;passively\u0026rdquo; investing in the entire stock market (a facility available through something called index funds) their savings grow over time with a high probability. For companies that are listed on the stock market, the incentive is that they have access to large amounts of capital to fund their growth. Individual companies can fail and try again. While individual investors can never reduce the probability of losing all their money to 0, they can reduce it significantly by buying and holding a diverse set of stocks.\nThe Other Side of the Coin This is of course not the complete story. I’ve only mentioned the bare essentials of the system. There are other ingredients needed to ensure that the growth generated by this economic system is sustainable. One of the most obvious problems is that the shareholders of a company may only care about making money. This means that the company would try to maximise profit above all else in a way that can be harmful for humanity as a whole. Part of the reason is that economic activity generates costs apart from that of labor and raw materials. These external costs - such as the generation of planet warming greenhouse gases - means that there is a need for well desiged regulations that ‘bake in’ these external costs into the cost of running businesses. Implementing things like a carbon tax or a pollution cleanup tax will probably be necessary in the coming years to make sure that our economic activity does not mess up the planet that we live in.\nSo, with some well-planned regulations, carefully controlled inflation and thriving stock market humanity should be set for growth - at least until the next disruptor comes along. An AI singularity perhaps?\nReferences Wikipedia Article on Deflation Friedman, Benjamin M. Monetary policy. No. w8057. National Bureau of Economic Research, 2000. Remarks by Governor Ben S. Bernanke Inflation Rates by Country, CIA World Factbook Indians have a love-hate relationship with stock markets, says CEO of Asia’s first stock exchange Majority of states have very few stock market investors 1 in 3 Singaporeans does not invest, most financially unprepared for retirement: OCBC survey Wilshire 5000 Price Index Historic Data ","date":1574502600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574502600,"objectID":"d260d9f2a4b894c27e4978fa4d623288","permalink":"https://www.ashwinnarayan.com/post/investing-and-personal-finance/","publishdate":"2019-11-23T17:50:00+08:00","relpermalink":"/post/investing-and-personal-finance/","section":"post","summary":"Introduction Growing up in an Indian family, I had very little exposure to discussion and information about the stock market. People in India are generally less likely to invest in the stock market.","tags":["investing"],"title":"Investing in the Stock Market: A Scientist's View","type":"post"},{"authors":null,"categories":[],"content":"Many websites use bots to automate tasks and add useful (and sometimes harmful) functionality. For instance, there are reddit bots that can help you stabilize shaky videos, remind you of events or even vote on the usefulness of other bots. Telegram - an instant messaging service similar to WhatsApp - lets you create and manage bots on their platform using their Bot API. Bots on Telegram are officially identified and provide fun and useful services. Last month, while exploring Google Cloud Platform after getting some free student credits, I came across Google Cloud Functions. I realized that this hammer was perfect for the nail of setting up a simple Telegram bot.\nMany years ago, when Telegram\u0026rsquo;s bot API was still young, I tried to create a bot that would send you random pictures of aurorae if you asked. That bot and the server that it lived on crashed a long time ago. But the bot\u0026rsquo;s name and API key lived on, still registered with Telegram\u0026rsquo;s servers. I decided to necromance this bot from the dead and inject it with some fun new functionality. Being a lover space exploration and what it represents for humanity, I had the idea of giving the bot the ability to send you random images from NASA with informative descriptions as seen on the NASA Image and Video Library.\nUsing the NASA Images API The first problem to solve is getting a random image from the NASA Image and Video Library. At first, I thought that I\u0026rsquo;d have to use a web-scraping python library to extract the images. But things turned out to be much easier. NASA has quite a few APIs that they\u0026rsquo;ve listed on this page. Using their API, I can search through the images for any query I like and retrieve results in the form of JSON formatted data. The API uses HTTP GET requests (\rmore info here). So for example, if I need to search for images related to planets using the API, I would open the URL: https://images-api.nasa.gov/search?q=planet.\nThere\u0026rsquo;s one extra step here. If you click on the api link above and examine the results, you\u0026rsquo;ll notice that it does not return all the results of a search at once. Instead, it gives you the first 100 results and gives you the option of getting more using the \u0026lsquo;page\u0026rsquo; parameter in the web request. So if I want to access the results from the 5th page of a search, I\u0026rsquo;d use the URL: https://images-api.nasa.gov/search?q=planet\u0026amp;page=5.\nSo, to select a random result, I need to select a number between 1 and the total number of results and use modular arithmetic to figure out which page to get the result from. I encapsulated this logic in a single function that returns the URL and caption of a random result given a search query.\nimport urllib.parse\rimport urllib.request\rimport json\rimport random\rimport math\rimport traceback\rdef get_random_nasa_image(search_term='planet'):\r\u0026quot;\u0026quot;\u0026quot;\rFetch a random image from the NASA media library.\r\u0026quot;\u0026quot;\u0026quot;\rtry:\r# The API URL\rnasa_img_url = \u0026quot;https://images-api.nasa.gov/search\u0026quot;\r# Setup the search data\rsend_data = {}\rsend_data['q'] = search_term\rsend_data['media_type'] = 'image'\r# Encode the url\rurl_values = urllib.parse.urlencode(send_data)\rurl = nasa_img_url + '?' + url_values\rdata = urllib.request.urlopen(url)\rjson_data = json.loads(data.read().decode('utf-8'))\rnum_results = json_data['collection']['metadata']['total_hits']\rresult_to_use = random.choice([i for i in range(num_results)])\rpage_num = math.ceil(result_to_use/100.0)\rresult_num_in_page = result_to_use%100\rif page_num != 1:\r# Do another request\rsend_data['page'] = page_num\rurl_values = urllib.parse.urlencode(send_data)\rurl = nasa_img_url + '?' + url_values\rdata = urllib.request.urlopen(url)\rjson_data = json.loads(data.read().decode('utf-8'))\rimage_url = json_data['collection']['items'][result_num_in_page]['links'][0]['href']\rimage_caption = json_data['collection']['items'][result_num_in_page]['data'][0]['description']\rimage_title = json_data['collection']['items'][result_num_in_page]['data'][0]['title']\relse:\rimage_url = json_data['collection']['items'][result_num_in_page]['links'][0]['href']\rimage_caption = json_data['collection']['items'][result_num_in_page]['data'][0]['title']\rimage_title = json_data['collection']['items'][result_num_in_page]['data'][0]['description']\rreturn (image_url, image_title, image_caption)\rexcept Exception as e:\rtraceback.print_exc()\rerr_url = 'https://upload.wikimedia.org/wikipedia/commons/3/3b/Gato_enervado_pola_presencia_dun_can.jpg'\rerr_caption = 'Uh-Oh. Something went wrong. Here\\'s a picture of a cat instead.'\rreturn (err_url, err_caption, json_data)\rSending the Image to Telegram To make a Telegram Bot send an image to a user we need three pieces of information.\nThe Chat ID : The chat ID is like a serial number that uniquely identifies the chat between a bot and a user. The Photo : There are a few different formats that telegram accepts the photo in. I chose the simplest option, a string with the URL to the photo. The Bot API Key : This is a long random looking string that you get when you create a bot. See instructions here to learn how to get your own. The actual sending of the message is achieved by using more HTTP GET or POST requests. In this case I used the sendPhoto function defined in the API. Again, I encapsulated the functionality to send the photo into a single function.\ndef sendPhoto(chat_id, url, caption):\rsendPhotoUrl = 'https://api.telegram.org/bot{your-api-key}/sendPhoto'\rdata = {}\rdata['chat_id'] = chat_id\rdata['photo'] = url\rdata['caption'] = caption\rdata = urllib.parse.urlencode(data)\rdata = data.encode('ascii') # data should be bytes\rreq = urllib.request.Request(sendPhotoUrl, data)\rwith urllib.request.urlopen(req, timeout=10) as response:\rthe_page = response.read()\rreturn the_page\rSetting Up a Google Cloud Function Google Cloud Functions allow you to execute a custom block of code when triggered by some kind of event - like it being a certain time of the day. Apart from Google, companies like Amazon and Microsoft also have their own versions of cloud functions.\nSince my application logic was fairly simple, I opted to setup my cloud function from their web interface by following the instructions on this page. I kept all the default settings and opted to use Python 3.7 since that\u0026rsquo;s the programming language that I\u0026rsquo;m the most familiar with. The \u0026lsquo;hello_world\u0026rsquo; function that they have setup is the function that will be called when the service is triggered.\nInside the function, I need to implement some very simple logic:\nExtract the Chat ID from the incoming message. Get a random NASA photo. Send the photo (along with its caption) to the incoming message\u0026rsquo;s Chat ID Return an HTTP OK response. Here\u0026rsquo;s my code for the main function that\u0026rsquo;s called when an event is triggered. I\u0026rsquo;ve added some exception handling to the main logic as well.\ndef hello_world(request):\r\u0026quot;\u0026quot;\u0026quot;Responds to any HTTP request.\rArgs:\rrequest (flask.Request): HTTP request object.\rReturns:\rThe response text or any set of values that can be turned into a\rResponse object using\r`make_response \u0026lt;http://flask.pocoo.org/docs/1.0/api/#flask.Flask.make_response\u0026gt;`.\r\u0026quot;\u0026quot;\u0026quot;\rrequest_json = request.get_json()\rdoneFlag = False\rtry_counter = 0\rtry_max = 5\rwhile not doneFlag:\rtry:\r# Send back a random nasa photo\rphoto, title, caption = get_random_nasa_image()\rprint(photo)\rsendPhoto(request_json['message']['chat']['id'],\rphoto, caption)\rdoneFlag = True\rexcept:\rprint(\u0026quot;Something Went Wrong. Trying again!\u0026quot;)\rtry_counter = try_counter + 1\rif try_counter \u0026gt; 5:\rdoneFlag = True\rtraceback.print_exc()\rsendPhoto(request_json['message']['chat']['id'],\r'https://upload.wikimedia.org/wikipedia/commons/3/3b/Gato_enervado_pola_presencia_dun_can.jpg',\r'I\\'m Sorry, something went wrong. Here\\'s a cat picture instead. :P')\relse:\rpass\rprint(request_json)\rreturn f'HTTP/1.0 200 OK'\rConnecting the Telegram Bot to the Cloud Function. The final step is to connect the Telegram Bot to the Cloud Function so that the function is triggered every time the bot receives a message from someone. The Telegram API has a function for just that. setWebhook allows you to set a URL that gets called every time the bot gets a new message. All the message data is passed on in JSON format. To connect your bot to the cloud function that you just created, you need to set the webhook to the URL specified in the \u0026lsquo;Trigger\u0026rsquo; tab of the function details page.\nDemo And we\u0026rsquo;re done! If there are no errors in the code, your bot should be triggered every time it receives a message. Here\u0026rsquo;s a demo of my bot working:\nConclusion Successes like these are the reason that I sometimes revive old projects. In the years that passed between my two attempts, some technologies had become cheap enough that I could use it nearly for free. In my last attempt to build the bot, I used a custom VPS server (basically a linux server) to try and run the bot. This meant that in addition to the logic for the bot, I needed to figure out how to get the bot to run on the server reliably. I often had to go back and restart the server or the script because it had got itself into an unexpected state. For cloud functions, there is no state. Each event invokes a new call of the function and if there is an error, the next function call isn\u0026rsquo;t affected by it. I also don\u0026rsquo;t need to worry about reliability and uptime because Google manages the service. Building systems like these are a great way of learning more about the inner workings of the internet and I hope that others who want to build their own Telegram bots (or other web based things) can use this article as a starting point.\n","date":1559800755,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559800755,"objectID":"c5b9cc1ba95538092bb7224098d405bd","permalink":"https://www.ashwinnarayan.com/post/gcp-telegram-bot/","publishdate":"2019-06-06T13:59:15+08:00","relpermalink":"/post/gcp-telegram-bot/","section":"post","summary":"Many websites use bots to automate tasks and add useful (and sometimes harmful) functionality. For instance, there are reddit bots that can help you stabilize shaky videos, remind you of events or even vote on the usefulness of other bots.","tags":["programming"],"title":"Building a Simple Telegram Bot Using Google Cloud Functions","type":"post"},{"authors":null,"categories":[],"content":"Introduction As is the case for a lot of PhDs, my main work focuses on a small part of robotics. There are many areas of robotics that I would love to work on but do not. As part of my ongoing effort to learn more about these areas, I work on accessible problems that interest me. One area of robotics that fascinates me is that of rigid body dynamics and control. Regardless of how many times I see it, there is something magical about using mathematics to make correct predictions about the world. Newtonian mechanics - the science that powers most modern robots - is many hundreds of years old, but I can still feel the magic when the equations come to life.\nOne toy system that is commonly used to learn about dynamics and control theory is the cart-pole or inverted pendulum. Over the past few weeks, I\u0026rsquo;ve been working through simulating the dynamics of the system. I alse tried out some common control strategies to perform the task of balancing the pendulum with its center of mass above the joint. In this article I\u0026rsquo;ll go through the process from beginning to end. I think the cart pole system is very convenient as it is simple enough that its dynamics can be worked out by hand. Concomitantly, it is complex enough to warrant applying some advanced control strategies.\nModeling and Simulating the Cart-Pole System The diagram above (lifted from the Wikipedia article) shows what the system looks like. It is assumed that the cart is on a fixed linear rail (frictionless of course). This can be considered a prismatic joint in robotics terminology. The pendulum is mounted on the cart with a revolute joint that has a single rotational degree of freedom. There are a few ways to model the pendulum. Some model it as a uniform bar/cylinder and some as a concentrated mass at the end of a massless link. For the purposes of this article, I\u0026rsquo;ll be modeling it as a thin cylindrical rod.\nLagrangian Mechanics Lagrangian mechanics is a fascinating and beautiful formulation of classical mechanics. Rather than the three laws of motion, Lagrangian mechanics is interested in a scalar quantity called the action which is a function of the state of the mechanical system. By applying a simple constraint known as the Principle of Least Action, you can get the equations of motion for any system in any coordinate system.\nTo apply Lagrangian Mechanics to the cart-pole system, I need to first write down the Lagrangian of the system which is defined as the difference between the potential and kinetic energies of the system as functions of the state.\nSince the cart moves perpedicular to gravity, the potential energy $V$ only depends on the vertical position of the pendulum.\n$$ V = -m_{p}gl\\cos{\\theta} $$\nThe Kinetic Energy of the system is a bit more involved. It\u0026rsquo;s the sum of the kinetic energies of the cart and the pole.\n$$ \\begin{align} T \u0026amp;= \\frac{1}{2} m_c \\dot{x}^2 + \\frac{1}{2}m_p \\left[ (\\dot{x} + l\\dot{\\theta}\\cos{\\theta})^2 + (l\\dot{\\theta} \\sin{\\theta})^2\\right] \\\\ \u0026amp;= \\frac{1}{2} (m_c + m_p) \\dot{x}^2 + \\frac{1}{2} m_p l^2 \\dot{\\theta}^2 (\\cos^2{\\theta} + \\sin^2{\\theta}) + m_p l \\dot{x}\\dot{\\theta}\\cos{\\theta} \\\\ \u0026amp;= \\frac{1}{2} (m_c + m_p) \\dot{x}^2 + \\frac{1}{2} m_p l^2 \\dot{\\theta}^2 + m_p l \\dot{x}\\dot{\\theta}\\cos{\\theta}\\end{align} $$\nThe Lagrangian is then:\n$$ \\mathcal{L} = T - V $$\nIn Lagrangian mechanics, as the system evolves over time, a quantity called action is defined as the integral of the Lagrangian.\n$$ S = \\int_{t_1}^{t_2} \\mathcal{L} dt$$\nAccording to the Principle of Least Action, the dynamics of the system evolves so that this quantity - the action - is minimized. Once I have the action I can use the Euler-Lagrange equations to find the equations of motion of the system.\n$$ \\frac{d}{dt} \\frac{\\partial \\mathcal{L}}{\\partial \\dot{q}_i} - \\frac{\\partial \\mathcal{L}}{\\partial q_i} = F_i$$\nThe $q_i$ represent the state variables of the system and $F_i$ generalized forces. By applying these equations once for each state variable I get the full equations of motion of the system. In the case of the cart pole system, the state variables are the position of the cart and the angle between the cart and the pendulum. The resulting two equations are:\n$$ \\begin{align} -m_p l \\dot{\\theta} \\sin{\\theta} + (m_c + m_p) \\ddot{x} + m_p l \\ddot{\\theta} \\cos{\\theta} = F_1 \\\\ m_p g l \\sin{\\theta} + m_p l \\ddot{x} \\cos{\\theta} + m_p l^2 \\ddot{\\theta} = F_2 \\end{align} $$\nThe central equation of study in robot dynamics are the manipulator equations. These equations are a general way to express the dynamics of a multi-link rigid body. By inspecting the equations of motion derived above, they can be expressed in the manipulator equation form:\n$$ H(q)\\ddot{q} + C(q, \\dot{q})\\dot{q} + G(q) = F $$\nWhere\n$$ H = \\begin{bmatrix} m_c + m_p \u0026amp; m_p l \\cos{\\theta} \\\\ m_p l \\cos{\\theta} \u0026amp; m_p l^2 \\end{bmatrix}$$ $$ C = \\begin{bmatrix} 0 \u0026amp; -m_p l \\dot{\\theta} \\sin{\\theta} \\\\ 0 \u0026amp; 0 \\end{bmatrix} $$ $$ G = \\begin{bmatrix} 0 \\\\ m_p g l \\sin{\\theta} \\end{bmatrix} $$ $$ q = \\begin{bmatrix} x \\\\ \\theta \\end{bmatrix} $$\nSimulating the Cart Pole System There are a few ways to simulate a mechanical system once you have the equations of motion. Python is an excellent option. The scipy package has a good set of numerical integrators. You just have to feed in the initial conditions of the system and it\u0026rsquo;ll simulate the system for as long as you want (at least, until your RAM runs out). However, for this project, I chose to use MATLAB. Mathworks decided to make the student (and personal) version of MATLAB available for ridiculously cheap prices (compared to their organizational licenses). So about a year ago I bought their student license so I could learn to use it. Everything I do in this article can be done just as well using Python and scipy. However, I do admit that using MATLAB makes the work a little smoother.\nFor simulating the cart-pole I will be using the Simscape Multibody toolbox for Simulink. Without any kind of control system active, we can see the dynamics of the free system quite nicely.\nBalancing Control The balancing control task is that of having the pendulum balance with its center of mass above the cart by only moving the cart (there is no actuator on the revolute joint). The control input in this task is a force that is applied to the cart (through electric motors or rocket engines or some other means of actuation).\nThe cart pole system is a highly non-linear system. However, just like how the motion of the simple pendulum can be approximated by a linear system for small angles, the cart pole system can be linearized too. Sometimes in engineering, the approach of \u0026ldquo;fiddling with it till it works\u0026rdquo; really works! So the first thing I tried to do is to implement a simple PD controller. If the system is linear around the balancing point (which it is in this case) and long as the states aren\u0026rsquo;t too far off, this approach will work.\nHand-Tuned Control Gains So the very first thing I tried are hand tuned control gains. I just assumed that I could achieve what I wanted by using the control signal $u = K\\cdot s$ where $s$ is the state vector with the positions and velocities: $s = \\begin{bmatrix} x \u0026amp; \\dot{x} \u0026amp; \\theta \u0026amp; \\dot{\\theta}\\end{bmatrix}^T$. After a bit (a lot) of fiddling, I did manage to find a set of control gains that worked. Here\u0026rsquo;s what the controller looks like when it tries to balance the pendulum.\nLQR To avoid wasting all that time fiddling, control engineers invented a type of controller called a Linear Quadratic Regulator. LQR controllers formalize the process of fiddling by defining a cost function on the states and control inputs. The optimal control gain vector $K$ is the vector that minimizes this cost function. LQR is fundamental enough in control theory that standard functions exist to calculate the control gains if you have the linearized system. Such functions exist in both MATLAB and scipy or specialized control libraries.\nTo do LQR, we first need to linearize the system around an \u0026ldquo;operating point\u0026rdquo;. This process can be little (but not too much) involved if you try to do it by hand so I applied liberal amounts Mathematica to help me out (you can do the same using SymPy in Python). I first expressed the equations of motion in the form $\\dot{s} = f(s, u)$. This can be done by rearranging the manipulator equations. Once you have the dynamics in this form, the linearized equations of motion can be expressed as:\n$$ \\dot{x} = A(s - s^*) + B(u - u^{ *}) $$\nWhere\n$$ A = \\frac{\\partial f}{\\partial s}\\Bigr\\rvert _{s=s^{*}} $$ $$ B = \\frac{\\partial f}{\\partial u}\\Bigr\\rvert _{u=u^{ *}} $$\nFor the cart pole system, the matrices come out as:\n$$ A = \\begin{bmatrix} 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\\\ 0 \u0026amp; \\frac{m_p g}{m_c} \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; \\frac{(m_c + m_p)g}{m_c l} \u0026amp; 0 \u0026amp; 0 \\end{bmatrix} $$\n$$ B = \\begin{bmatrix} 0 \\\\ 0 \\\\ \\frac{1}{m_c} \\\\ \\frac{1}{m_c l}\\end{bmatrix} $$\nTo compute the optimal LQR control gains, I need to define a few more matrices. As I said before, LQR finds the gain matrix $K$ that optimizes the cost function\n$$ J = \\int_0^{\\infty} (s^TQs + u^TRu + 2x^TNu) dt$$\nI need to define the matrix $Q$, $R$ and $N$. You can think of $Q$ as a matrix of weights that tell you how much to \u0026ldquo;penalize\u0026rdquo; certain combinations of the state. For instance the first term in the diagonal of the $Q$ matrix tells you how much to penalize the value of the state variable $x$. The same goes for other matrices. Having the $Q$ matrix as a scalar multiple of the identity matrix is a good default. $R$ is just a single scalar value. $N$ can be skipped in most cases. With these I got a control gain matrix that also successfully drove the states to my target. It looked quite similar to my hand tuned control gains actually. On close inspection you can see that the system does reach it\u0026rsquo;s target slightly faster.\nConclusion Dynamics is an important part of a roboticist\u0026rsquo;s toolkit. Learning dynamics from a textbook can be a bit daunting. For me, implementing the ideas in code and generating nice animations helps me to get a better intuition of the mathematics. Now that I have the environment set up, I\u0026rsquo;m considering trying my hand at some swing-up control using energy shaping methods or reinforcement learning.\nReferences Acrobot and Cartpole, Russ Tedrake 2009 MATLAB\u0026rsquo;s LQR Design Function Euler-Lagrange Equation ","date":1555808204,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555808204,"objectID":"d66c74508d05f6b6825017d16b512d30","permalink":"https://www.ashwinnarayan.com/post/cartpole-dynamics/","publishdate":"2019-04-21T08:56:44+08:00","relpermalink":"/post/cartpole-dynamics/","section":"post","summary":"Introduction As is the case for a lot of PhDs, my main work focuses on a small part of robotics. There are many areas of robotics that I would love to work on but do not.","tags":["robotics","mathematics"],"title":"Cartpole Dynamics and Control","type":"post"},{"authors":[],"categories":[],"content":"Introduction Over the last year or so, I\u0026rsquo;ve been playing around with functional programming. As the first few lines of the Wikipedia page suggest, functional programming is all about expressing a computation or algorithm as the composition of functions rather than using a state that changes over time. From what I\u0026rsquo;ve understood so far, functional programming is based on lambda calculus which is an alternative but equivalent formulation of the famous Turing Machine that most modern computers are based on.\nOnce you start reading up on functional programming, the language that is most often recommended is Haskell. I got interested in functional programming and Haskell in the first place because I was attracted by its more mathematical appearance. A lot of the code that I looked at seemed to express ideas much more clearly and (in my opinion) more beautifully. However, Learning Haskell was not easy at all. As someone who\u0026rsquo;s been programming using imperative languages all my life, I found it unusually difficult to think about solving problems using the style that Haskell (and functional programming) imposed. Near the beginning of my journey to learn the language, there were quite a lot of stops and restarts and many instances where I questioned whether it was even useful to learn the language. I found it so difficult to express ideas that were, in my head simple to express in a language like Python. I also found writing programs that required I/O quite difficult. However, the aforementioned clarity and beauty that I found in the way functional programming expressed ideas stuck with me and I kept coming back to it. after nearly a year, things fell into place and I started writing code that was actually useful (i.e. interacted with the world through I/O). I feel like I\u0026rsquo;m finally at a point where I can program well enough in the language that I can solve problems without struggling too much with I/O. So, when I got the email notifying me about this year\u0026rsquo;s Google Code Jam I thought I\u0026rsquo;d participate and try to use Haskell as much as possible!\nGoogle Code Jam I\u0026rsquo;ve known about Google Code Jam for quite a while. I\u0026rsquo;ve even tried participating once before near the beginning of my undergraduate degree. Being a novice at the time, I did not even make it past the qualifying round. Since then I\u0026rsquo;ve been programming on a regular basis for nearly six years and it\u0026rsquo;s paid off. This time, I made it past the qualifying round quite comfortably. The main challenge before me was my use of a programming language that I hadn\u0026rsquo;t fully mastered yet. The added challlenge did make solving the problems a lot more fun however. Along the way, I was able to take advantage of some functional programming patterns and I thought that it might be valuable to write an article about how these patterns can be useful.\nProblem 1 - Foregone Solution To read the full problem description go here.\nSummary of Problem Statement The input for each testcase is a number N which when expressed in base 10 may or may not contain the digit 4. The goal is to split up the number N into 2 numbers A and B so that A + B = N and neither A nor B contain the digit 4.\nAnalysis A brute force approach to the solution would search through all possible sums of two integers between 0 and N/2. Of course, this solution would scale as $O(N^2)$ and would not work with the larger test cases. Another thing to think about is that the hidden test cases can contain numbers between 1 and $10^{100}$. That number is beyond the range of usual integer data types. The problem can be solved quite easily by making the simple observation that you can split up all the digits that are 4 into 2 and 2 (or 3 and 1) and easily generate two numbers without even adding the two numbers to check if they sum up to N. For instance, if N is 9454 you can split it up into 9252 and 202. To do this you do not even need to convert the number into an integer data type. You can work with the string representation directly.\nSolution I will read each test case number as a string and create two new numbers A and B. A will have all the digits 4 replaced with 2 and the remaining digits the same. B Will have all the digits 4 replaced with 2 and all the remaining digits replaced with 0. This pattern of replacing each member of an array with another one using information from only a single array element can be implemented using the higher order function map. So, I defined two functions to calculate A and B.\ngetA :: [Char] -\u0026gt; [Char]\rgetA n = map (\\x -\u0026gt; if x == '4' then '2' else '0') n\rgetB :: [Char] -\u0026gt; [Char]\rgetB n = map (\\x -\u0026gt; if x == '4' then '2' else x) n\rThe rest of the solution is just I/O. You can see my full solution here.\nProblem 2: You Can Go Your Own Way To read the full problem description go here.\nSummary of the Problem Statement The goal is to get from the top right corner of an NxN grid to the bottom right corner using only South (Down) and East (Right) moves with the additional constraint that any segment of the path taken must not coincide (but can intersect at a single point) with another path that someone called Lydia took. The input is this path which is represented as a string containing uppercase \u0026ldquo;S\u0026rdquo; and \u0026ldquo;E\u0026rdquo; characters only.\nAnalysis This problem looks more difficult to solve than it actually is. Once you know the trick, the code is quite simple. Here are some observations about the problem which helped me arrive at the solution.\nObservation 1: Number of S moves and E moves must be exactly equal to N-1 if you want to reach the bottom right corner. You can see this by thinking of each move as a vector. This implies that it might be possible to find the solution by just transforming the input string as it is read. Observation 2: If I have a function that only stays the same or decreases along the X-axis and intersects the point (0, 0), I can mirror the function along the line y=-x and the only places where the path intersects will be crossings. That means I can solve this by just doing the opposite of whatever Lydia does at each step. This means that I can take Lydia\u0026rsquo;s path and reverse the action she took at each step like some dark mirror and I have my solution. Interestingly, this problem can also be solved using the \u0026ldquo;map\u0026rdquo; higher order function pattern in Haskell. The meat of my solution was implemented in two functions. One is the character (move) mapping function:\nflipMove :: Char -\u0026gt; Char\rflipMove c\r| c == 'S' = 'E'\r| c == 'E' = 'S'\r| otherwise = c\rAnd another is the function that transforms the input string into the output string.\nsolveCase :: String -\u0026gt; String\rsolveCase lydiasMoves = map flipMove lydiasMoves\rAs before, the rest of the code is just IO. My full solution is here.\nProblem 3: Cryptopangrams This problem was a bit harder than the others. I spent a lot of time thinking about this one and solved it quite close to the end of the round. Some of my initial attempts failed because I didn\u0026rsquo;t consider all the edge cases. Read the full problem statement here.\nSummary of Problem Statement A string is \u0026ldquo;encoded\u0026rdquo; using the following procedure:\n26 prime numbers less than a number N are chosen. The numbers are sorted in increasing order and a character map is made from the numbers to the corresponding letter between A and Z. Each character in the sentence is replaced with the corresponding prime number (spaces are removed and ignored). The prime number at each position is replaced with the product of the number and the number corresponding to the next character in the sentence. As an additional condition, the string is guaranteed to have all 26 characters occur at least once.\nFor each case, as input, the maximum number N and the encoded sentence is given. The output should be the decoded sentence (without spaces).\nAnalysis Let each sentence that is encoded be made of L characters. The set of primes that represent each of these characters can be represented by the sequence of numbers: $\\{P_1, P_2, \u0026hellip; , P_L\\}$. After the \u0026ldquo;encoding\u0026rdquo; procedure is carried out, the sequence will look like: $\\{P_1\\times P_2, P_2\\times P_3, \u0026hellip; , P_{L-1}\\times P_{L}\\}$. The brute-force approach to solve this problem would involve trying to find the prime factors of each number in the sequence. However, if you look at the sequence above you can see that each number in the sequence except for the first one shares a common factor with the number before it! This means that if I find the common factors of the first two numbers in the sequence then I can factorize the entire sequence quite easily using the following procedure:\nFind the common factor between the first two numbers in the sequence. Divide the first number by this common factor to get the first factor. Second factor is the common factor. For all subsequent numbers, the first factor is the common factor with the previous number and the second factor is the number divided by the common factor. Solution So first, I wrote a function to find the greatest common divisor between two numbers. This function implements Euclid\u0026rsquo;s Algorithm for find the greatest common divisor of two numbers:\ncommonFactor :: Integer -\u0026gt; Integer -\u0026gt; Integer\rcommonFactor a b\r| remainder == 1 = 1\r| remainder == 0 = if a \u0026gt; b then b else a\r| otherwise = if a \u0026gt; b then commonFactor b remainder else commonFactor a remainder where remainder = if a \u0026gt; b then snd (quotRem a b) else snd (quotRem b a)\rIn an imperative programming language we would loop through each character in the sequence to find the factors after setting up the loop by finding the common factor between the first two numbers. In Haskell the loop pattern for solving this particular problem is captured quite beautifully using the higher order function scanl. The type signature for scanl is (b -\u0026gt; a -\u0026gt; b) -\u0026gt; b -\u0026gt; [a] -\u0026gt; [b]. This means that scanl takes a function that takes a type a and b and returns a b, a member of type b and a list of type a and returns a list of type b.\nA scanl is a higher order function that is a variant of a general pattern in computing called a fold. To put it very simply, a fold takes a starting value (sometimes called a seed), a function and a list and applies the function repeatedly in a specific way. If I write down the fold imperatively in a language like Python, it would look like this (f is the function that is applied recursively):\nseed = 0\rfor idx, elem in enumerate(lst):\rif idx == 0:\rresult = f(seed, elem)\relse:\rresult = f(result, elem)\rA fold will run this loop and return the final value of the result in the computation. A scan is just a fold that returns a list of the intermediate values at each iteration in the loop. Haskell has two scan functions that work on lists: scanl and scanr. scanl starts the iteration from the left side of the list and scanr starts the iteration from the right side of the list.\nWith this in mind, I wrote a scanl based function to factorize the list of input numbers.\nfactorizeCiphertext :: [Integer] -\u0026gt; [Integer]\rfactorizeCiphertext lst@(x1:x2:nums) = scanl (\\n1 n2 -\u0026gt; n2 `div` n1) firstFactor lst\rwhere firstFactor = x1 `div` (commonFactor x1 x2)\rIn my first attempt at solving the problem, I thought that this was the full solution. But I kept getting runtime errors once I uploaded the answer to the website. After thinking about the problem for a little bit I realized that I\u0026rsquo;d missed out on some edge cases. There are two ways in which this solution can fail.\nIf there are consecutive numbers that are identical at the start of the sequence. The common factor algorithm will return the number itself. Consecutive identical numbers can be caused by either repeated characters (\u0026ldquo;AAAAAA\u0026rdquo;) or by repeated alternating characters (\u0026ldquo;ABABABA\u0026rdquo;) in the plain text. If there are multiple but different consecutive numbers at the start of the sequence. For instance, if the cipher text starts like [9, 9, 9, 15, 15, 15, 35, 217]. Note that if repeated characters appear in the middle of the sequence, it does not matter since the procedure we use will divide this number by the previous factor anyway. To handle this edge case, we\u0026rsquo;ll need to extract any successive repeated numbers from the start of the sequence. So I wrote two functions to split the input list into two lists. One contains any repeated characters at the start of the list and the other is the rest of the list.\ngroupHead :: [Integer] -\u0026gt; [Integer]\rgroupHead (x:xs)\r| x == (head xs) = [x] ++ (takeWhile (==x) xs) ++ groupHead (dropWhile (==x) xs)\r| otherwise = []\rgroupTail :: [Integer] -\u0026gt; [Integer]\rgroupTail (x:xs)\r| x == (head xs) = groupTail (dropWhile (==x) xs)\r| otherwise = [x] ++ xs\rFor the rest of the list that does not have any initial repeating characters, the original factorizeCiphertext function can be used to factorize the list. But how do we factorize the first part of the list? After a bit of thought I realized that if we factorize the first number in the second part of the list, it must have a common factor with the last number in the first part of the list. So now I can use this as the first factor to scan the list from the right!\nSo the final function that accounts for the edge cases is:\nfactorizeCiphertext4 :: [Integer] -\u0026gt; [Integer]\rfactorizeCiphertext4 (n:nums)\r| isEdge = (scanr (\\n1 n2 -\u0026gt; n1 `div` n2) (head factorTail) groupHeads) ++ (tail factorTail)\r| otherwise = factorTail\rwhere groupHeads = groupHead ([n] ++ nums)\risEdge = if (length groupHeads) \u0026gt; 0 then True else False\rlistToScan = groupTail ([n] ++ nums)\rfirstFactor = (head listToScan) `div` (commonFactor (head listToScan) (head $ tail listToScan))\rfactorTail = scanl (\\f n -\u0026gt; n `div` f) firstFactor listToScan\rYou can view my full solution to the problem here.\nConclusion Haskell is a difficult language to learn, especially if you\u0026rsquo;ve only been exposed to imperative languages all your life. Rather than thinking in terms of discrete steps, you have to force yourself to think in terms of recursion and higher order patterns in the problem. However, if you stick with it for that initial amount of time that it takes to develop some basic proficiency, the results can be very rewarding. You can write some beautiful code in this language. After learning Haskell, I\u0026rsquo;ve also found myself using a functional approach to solve programming problems in other languages too! For instance, I\u0026rsquo;ve started using Python\u0026rsquo;s iterools package much more often.\nHowever, usefulness wasn\u0026rsquo;t the main factor that motivated me to learn Haskell. For me it was more about the fun of solving puzzles in clever and aesthetically pleasing ways. Haskell is one of the few languages that puts some fun back into solving programming problems. I think it brings in some of the beauty and rigor traditionally associated with pure mathematics into a programming language. If you\u0026rsquo;re someone who enjoys programming puzzles for their own sake and finds beauty in clever solutions to puzzles, I highly recommend giving Haskell a go.\n","date":1555115194,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555115194,"objectID":"6fbb60187a417c21fb420049bb062402","permalink":"https://www.ashwinnarayan.com/post/learning-haskell-google-code-jam/","publishdate":"2019-04-13T08:26:34+08:00","relpermalink":"/post/learning-haskell-google-code-jam/","section":"post","summary":"I try to solve Google Code Jam Problems using Haskell.","tags":["programming"],"title":"Learning Haskell Through Google Code Jam","type":"post"},{"authors":null,"categories":[],"content":"The Witcher 3 follows the story of Geralt of Rivia, a Witcher or monster slayer in search of his adoptive daugter Cirllia. (well it\u0026rsquo;s not his story but we see the story through his eyes!). Set in a medieval world - after an event called the conjunction of spheres - magic and monsters (werewolves, spectres, vampire and the like.) roam the world. Witchers are magically and genetically enhanced humans that were created intentionally by sorcerers to help fight off these monsters. Cirilla (or Ciri) is a woman with special magical abilities and is prophesied to play a part in the fate of Geralt\u0026rsquo;s (and others) world(s) which are facing doom from a world ending White Frost.\nI purchased the game almost a year ago in December 2017 after getting strong recommendations from my friends. I\u0026rsquo;ll admit that I was a little intimidated at first. It was the third game in the series and it appeared as though I had a lot of catching up to do. I needn\u0026rsquo;t have worried too much though. One of the main features of the game are the huge number of random books lying around the world. You pick them up and they often contain bits and pieces of the story of the Witcher universe. However, one thing that was definitely intimidating was the combat mechanics. There were swords (two of them!), spells (signs), potions, decoctions, oils, bombs and crossbows all bound to correspondingly wide array of keys. Although the combat mechanics tutorial at the start of the game explained most things, it\u0026rsquo;s a lot to remember. I took a short break from playing the game for a few months in between and when I came back, I\u0026rsquo;d forgotten all the keybindings and had to play through the initial combat mechanics tutorial again to get used to things. Funnily enough although I preferred playing video games with a keyboard and mouse for the increased maneuverability, I think using a controller might be slightly easier for the Witcher 3 since you don\u0026rsquo;t have to keep track of random alphabets on the keyboard.\nThe high level of immersion is what I enjoyed the most about the game. As a person that likes a bit of realism in games, I like it when the game mechanics do not break immersion. This is something I felt while playing To the Moon (brilliant game!). A lot of the progress in the game was made through solving what felt like very artificial puzzles (tile flipping jigsaws?). So it felt like alternating between experiencing the story and playing minigames. The Witcher has a ton of game mechanics but they\u0026rsquo;re all integrated into the story in a very natural way. Progress in the game is made through talking, interacting with objects and fighting. The fighting is quite realistic too. If I\u0026rsquo;m fighting a group of people they all come at me at once and I have dodge and roll between them to make sure that I don\u0026rsquo;t get hit from behind while fighting one person. Additionally, there\u0026rsquo;s no Pokemon like battle animation that signals the start of a battle. One second you\u0026rsquo;re walking along, minding your own stuff and the next second a drowner\u0026rsquo;s taking a swipe at you.\nThe incredibly open world nature of the game is the second factor that adds to the realism and immersiveness. You can go almost anywhere on the absolutely huge map. There are practically no invisible walls that you can run into and obstacles that cannot be jumped over are at a realistic height most of the time. If you step off a cliff, you fall and if the fall is too great, you lose health and possibly die. The only invisible walls I\u0026rsquo;ve ever encountered are when you wander off to the edge of the map.\nThe third factor that adds to the immersiveness of the game is the map itself. The world of Witcher 3 is incredibly detailed. The cities like Oxenfurt and Novigrad feel like real full scale big cities. Although they are scaled down versions of the cities mentioned in the books, they\u0026rsquo;re still the biggest I\u0026rsquo;ve encountered in a video game. It was not like Pokemon where a \u0026ldquo;city\u0026rdquo; can be 4 buildings of which one is a Pokemon Center and another a Pokemart. I loved roaming around Novigrad (despite the nutjobs that are trying to burn witches alive). My favorite part of the city is probably the market square. I like how I can hear the chaotic sounds of a marketplace start up as you walk towards it. Outside the cities there are forests, snowy mountains, small villages, beaches and swamps all beatifully built and rendered in a very non-repetitive and organic way. The scenery never felt boring. It felt like nearly everything was placed and adjusted by hand. I was amazed in particular by the fantastical environments I encountered while traveling through the many parallel universes. The use of parallel universes in the game itself was quite a novel idea! I never thought that a game set in the medieval era would involve parallel universes and time travel. I saw worlds that were just deserts, worlds covered in frost, worlds with toxic gases and colorful plants. Even the modern day world (ours!) and possibly the world of Cyberpunk 2077 (another upcoming game by them) was mentioned in passing.\nDespite logging over 100 hours in the game over the past year, I have yet to finish all the quests in the game. I\u0026rsquo;ve completed the main story of the game but I\u0026rsquo;ve still got dozens of Witcher contracts and a few secondary quests left to finish off. On top of all that I have yet to start on the Hearts of Stone and Blood and Wine expansions of the game - which I hear are basically like two new games; adding 10 and 20 hours of playtime respectively. Looking at the scale of the game, I was quite surprised to learn that the game only took 3.5 years and 81 million USD to make (I was expecting a lot more!). The Witcher 3 is an RPG. So as expected the choices you make during quests play a part in the outcome of the game. Some decisions are clearly good/bad but in some quests all the choices are bad but you still have to choose.\nMy only big criticism of the game is related to the combat difficulty near the start of the game. I\u0026rsquo;m not a gamer that plays games in hard mode. I play video games mainly to experience the story. So I tend to choose the lowest difficulty setting the game has. But even at the lowest difficulty, I had some trouble staying alive during some of the quests at the start of the game. I also had trouble with getting enough gold to buy things as I was spending most of my money keeping my equipment repaired (weapons and armor degrade as you use them). The problem was not too bad though and vanished as soon as I got out of White Orchard; character leveling happened much faster and I started getting gold quite a bit faster.\nI really enjoy playing story rich games like the Witcher 3. I feel like that is a very natural next step in the very human tradition of storytelling. We had spoken stories, then written, then acted out (movies). Interactive stories where the person experiences the story through his own actions is a very natural next step. In this regard, The Witcher stands out as the best game I\u0026rsquo;ve ever played. It manages to immerse me in the universe of Witcher 3 and feel like I\u0026rsquo;m really there. Every time I played the game, for a brief period of time I really was Geralt of Rivia. I felt what he felt, I did what he did. And in the end I felt like it had just as much (if not more) emotional impact as watching the story unfold in a movie or a book with the added advantage of being able to drive the story on my own rather than passively watch a film.\n","date":1537031446,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537031446,"objectID":"cc8261d19f5d7c54d4a8df7653cff455","permalink":"https://www.ashwinnarayan.com/post/witcher-3-review/","publishdate":"2018-09-16T01:10:46+08:00","relpermalink":"/post/witcher-3-review/","section":"post","summary":"The Witcher 3 follows the story of Geralt of Rivia, a Witcher or monster slayer in search of his adoptive daugter Cirllia. (well it\u0026rsquo;s not his story but we see the story through his eyes!","tags":["gaming","thoughts"],"title":"The Witcher 3: Wild Hunt - A Review","type":"post"},{"authors":null,"categories":[],"content":"As I mentioned in my first article on this blog, I\u0026rsquo;m now using Hugo, the static site generator to build my personal website. Due to the needs of my work environment (mostly because I need to use MS Word and certain MATLAB features on a regular basis), I\u0026rsquo;ve been primarily using Windows as my operating system for the past year or so. Having used Linux for a long time, I definitely missed the conveniences offered by shell scripting and other command line tools. However, while setting up a workflow in Windows for publishing content to my website I discovered that Windows\u0026rsquo; scripting tools are not all that bad. In fact, for anyone familiar with scripting from Linux, moving to Powershell isn\u0026rsquo;t that hard.\nWorkflow A typical Hugo website development folder looks like this: I add new posts by creating new markown (.md) files in the post folder. When the website is compiled using the hugo command, the static website\u0026rsquo;s code is generated into the public folder. The content inside this is what goes into the folder that is served by any webserver. Since I am hosting the website on Github Pages, I found it most convenient to set up a separate folder with a clone of the username.githug.io repository. After article writing/editing is done, I can generate the website and copy the contents inside the public folder to the repository folder to publish.\nWhen I am editing an article, I can preview content locally by using the hugo server --watch command in the top level directory. This sets up a local webserver on localhost:1313 so that you can preview the website.\nTo publish my website to Github pages after I\u0026rsquo;m done with development, I copy everything inside the public folder into my local copy of the github repository and then commit all and push.\nBatch Script Automation Most of the the steps in the workflow can be automated away using batch scripts to save large amounts of time. I mean, who wants to spend time manually copying files and commiting after every small edit to the website? The build_on_laptop.bat file in the top level directory handles everything. Diving into the source, I first delete everything inside the public folder (Hugo does not automatically do this) and build a fresh version of the website.\nrmdir /S /Q public\rhugo\rMy Github pages repo has a few files that are not generated by Hugo. So I can\u0026rsquo;t just nuke the folder and delete everything. So I have a set of commands that delete all the Hugo generated files in the repository folder:\nrmdir /S /Q \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\categories\u0026quot;\rrmdir /S /Q \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\css\u0026quot;\rrmdir /S /Q \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\fonts\u0026quot;\rrmdir /S /Q \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\home\u0026quot;\rrmdir /S /Q \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\img\u0026quot;\rrmdir /S /Q \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\js\u0026quot;\rrmdir /S /Q \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\post\u0026quot;\rrmdir /S /Q \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\project\u0026quot;\rrmdir /S /Q \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\publication\u0026quot;\rrmdir /S /Q \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\publication_types\u0026quot;\rrmdir /S /Q \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\tags\u0026quot;\rrmdir /S /Q \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\talk\u0026quot;\rdel \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\404.html\u0026quot;\rdel \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\index.html\u0026quot;\rdel \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\index.xml\u0026quot;\rdel \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\sitemap.xml\u0026quot;\rdel \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\site.webmanifest\u0026quot;\rdel \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\\styles.css\u0026quot;\rThen comes the task of copying your updated website source into the folder. While it\u0026rsquo;s possible to use the cp command, I found that the robocopy command is in general much better for copying files around in Windows.\nrobocopy public \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\u0026quot; /E\rFinally, I need to commit the new version of the website and push to github. This is also easily done:\ncd \u0026quot;C:\\Users\\Ashwin Narayan\\rationalash.github.io\u0026quot;\rset /p commitmsg=\u0026quot;Enter a commit message: \u0026quot;\rgit add --all .\rgit commit -m \u0026quot;%commitmsg%\u0026quot;\rgit push origin master\rSo the end result is that when I run this script, it automatically deletes everything in the public folder and the repository folder, rebuilds and copies the new website over and then commits and pushes the new version to github to deploy the website.\nEven More Automation with Visual Studio Code I can shave even more time off the workflow by using Visual Studio Code. VS Code has a really well made task management system. It\u0026rsquo;s also a natural choice since I do most of my markdown editing inside VS Code anyway. VS Code has a tasks.json file where you can bind custom tasks/commands to key combinations. In this case, I just bound the default build task mapped to Ctrl+Alt+B to the batch script. I also created a compose task which creates the local preview webserver.\n{\r// See https://go.microsoft.com/fwlink/?LinkId=733558\r// for the documentation about the tasks.json format\r\u0026quot;version\u0026quot;: \u0026quot;0.1.0\u0026quot;,\r\u0026quot;tasks\u0026quot;: [\r{\r\u0026quot;taskName\u0026quot;: \u0026quot;build\u0026quot;,\r\u0026quot;command\u0026quot;: \u0026quot;build_on_laptop.bat\u0026quot;,\r\u0026quot;isShellCommand\u0026quot;: true,\r\u0026quot;showOutput\u0026quot;: \u0026quot;always\u0026quot;,\r\u0026quot;echoCommand\u0026quot;: true\r},\r{\r\u0026quot;taskName\u0026quot;: \u0026quot;compose\u0026quot;,\r\u0026quot;command\u0026quot;: \u0026quot;hugo\u0026quot;,\r\u0026quot;args\u0026quot;: [\u0026quot;server\u0026quot;, \u0026quot;--watch\u0026quot;],\r\u0026quot;isShellCommand\u0026quot;: true,\r\u0026quot;showOutput\u0026quot;: \u0026quot;always\u0026quot;,\r\u0026quot;echoCommand\u0026quot;: true\r}\r] }\rWith most of the steps automated, writing and publishing new articles don\u0026rsquo;t take that long compared to off the shelf solutions like Wordpress or Medium. It also comes with the advantage that you have full control over the website\u0026rsquo;s source code.\n","date":1514700691,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514700691,"objectID":"19fa3fa22d83f5ffc4b26664f3a378bd","permalink":"https://www.ashwinnarayan.com/post/hugo-windows-workflow/","publishdate":"2017-12-31T11:41:31+05:30","relpermalink":"/post/hugo-windows-workflow/","section":"post","summary":"As I mentioned in my first article on this blog, I\u0026rsquo;m now using Hugo, the static site generator to build my personal website. Due to the needs of my work environment (mostly because I need to use MS Word and certain MATLAB features on a regular basis), I\u0026rsquo;ve been primarily using Windows as my operating system for the past year or so.","tags":["programming","windows","batch"],"title":"Hugo Web Development Workflow on Windows","type":"post"},{"authors":null,"categories":null,"content":"\rThis article contains spoilers for all the episodes of Star Trek: Discovery.\rAs a lover of good science fiction I was really happy to hear the announcement of Star Trek: Discovery. I have not watched all of old Star Trek. But from the few that I have watched (Mostly Star Trek: Then Next Generation), I have come to love the Trek universe and the way it handles science fiction. I feel that of late, science fiction is leaning too much towards dystopian themes. I like the occasional story about a world in nuclear winter but I like optimistic or neutral science fiction far more. It appeals to the part of me that gets excited about science and my penchant for the cool technologies and knowledge that it generates. So stories like Contact and Rendezvous with Rama is much more up my alley. I consider even movies like Interstellar as optimistic science fiction since even though the premise is that the earth is becoming uninhabitable, the story is that we work together to build the technology to colonize the stars. I consider Her science fiction although the focus of the movie was the relationship between Theodore and Samantha. The movie portrayed beautiful cityscapes and a future which looked distinctly post-scarcity as the characters seemed to not have to worry about basic needs and could live comfortably while doing basically whatever they wanted. In the case of Star Trek (at least for Star Trek: TnG) the episodes that I\u0026rsquo;ve watched so far fall under very optimistic science fiction.\nOne of my biggest fears about Star Trek: Discovery was that it would devolve into an action flick - especially because of the way the trailer was cut. It seemed to focus more on the action and less on the discovery/science/exploration part while also making the whole thing look like yet another dystopian sci-fi series. I felt that first two episodes seemed to run with this theme so much that they turned me away from the series initially and I took a break from it for nearly a month. But I came back to it one weekend when I was bored - and I\u0026rsquo;m glad I did. The episodes got better and so did the themes in them. While there was still an appreciable amount of action, they did not ignore the exploration and discovery part of things and. I also like that they specifically included characters whose biggest motivation was scientific curiosity. Here are some parts of the show that I particularly enjoyed:\n1. The Warp Capable Tardigrade Basing the strange creature on the real world tardigrade was a really cool idea. Apart from the fact that the creature looked really cool, I like that they treated it with kindness (at least in the case of Burnham) and let it go at the end.\n2. The Mycelial Network and The Spore Drive I was nerding out when the show started talking about a giant fungus spanning the entire universe because it\u0026rsquo;s actually based on an amazing real world fungus called the Armillaria ostoyae which is often reported as one of the largest living organisms in the world. There\u0026rsquo;s a single fungal colony of this type in the Malheur National Forest in the Blue Mountains of eastern Oregon, U.S, spanning 8.9 square kilometers. It\u0026rsquo;s estimated to be 2400 years old. The spore drive animations are amazing and it\u0026rsquo;s a creative plot device too.\n3. The Imperfect Captain In the older Star Treks, I felt that the captains tended to be very \u0026ldquo;perfect\u0026rdquo; characters (Kirk, Picard). They tended to be the kind of characters that are obviously good. However, the captain of the U.S.S Discovery is quite a bit less than perfect. In fact, he does quite a lot of things that are decidedly in the gray zone. In fact, the way he was introduced in the series is very similar to how villians are sometimes introduced in films. This gave me an initial sense of apprehension about the character - I got a fleeting sense that this dude is a bit evil and might not up to any good. In fact, I spent most of the episodes expecting something sinister to happen and for Lorca to pull an Admiral Marcus (Into Darkness) and reveal that he is in fact on the dark side of the force. But that never happened. Now I feel like he is a good captain who just has some unusual interest in war and does the odd unethical thing to get what he wants. Whatever the case, he added a lot of interest and depth to the new Star Trek and I like that he was not the same type of Captain as Kirk or Picard. In fact, I thought that Gabriel Lorca was a more interesting character than Michael Burnham (who I feel the showrunners are trying to make the main character.).\nSumming Up I feel that Star Trek: Discovery was well executed. While it is not exactly the same as the original Star Treks, I feel that the parts that were changed added more to the story than it took away. I like the mid season \u0026ldquo;finale\u0026rdquo; in which the crew of the Discovery were stranded in what seemed to be an alternate dimension. It is reminiscent of the TNG episode \u0026ldquo;Where No One Has Gone Before\u0026rdquo; in which the crew does some crazy new warp technique to go to the edge of the known universe. I look forward to seeing release of rest of the season next year. I\u0026rsquo;m curious to find out how they will handle the parallel universes thing.\n","date":1512919608,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512919608,"objectID":"774567422dd09e5e8bcc61e3f0e3ffb4","permalink":"https://www.ashwinnarayan.com/post/star-trek-discovery/","publishdate":"2017-12-10T23:26:48+08:00","relpermalink":"/post/star-trek-discovery/","section":"post","summary":"This article contains spoilers for all the episodes of Star Trek: Discovery.\rAs a lover of good science fiction I was really happy to hear the announcement of Star Trek: Discovery.","tags":["movie review","miscellaneous"],"title":"My Review of Star Trek: Discovery","type":"post"},{"authors":[],"categories":[],"content":"I\u0026rsquo;ve been working with inertial measurement units lately, and I\u0026rsquo;ve come to realize that there\u0026rsquo;s a surprising amount of mathematics involved in processing the raw data from the sensors. The story begins with me trying to integrate a three-dimensional angular velocity vector to get the orientation of an object. It turns out that while angular velocity is a vector, common representations of orientation, like Euler Angles, are not. So calculating the orientation is not as simple as integrating the angular velocity vector over time ($\\int_0^t \\vec{\\omega} \\mathscr{d}t$).\nRotations in two dimensions are simple because there is only one plane in which you can rotate. The only variable that can be freely set is the center of rotation. So you can represent the orientation of an object in 2D by a single angle $\\phi$. The angular velocity of an object in two dimensions can also be represented by a single number $\\omega$, the time derivative of the angle. This produces the familiar formula I learned in high school physics.\n$$\\omega = \\frac{d\\phi}{dt} = \\frac{v_{\\bot}}{r}$$ Rotations in 3D are much more complicated. In 3 dimensions, the plane of rotation can be any among an infinite number of possibilities. The origin or \u0026ldquo;center\u0026rdquo; of rotation now becomes an axis of rotation which is represented by a vector. The plane of rotation is perpendicular to the axis of rotation. This is a result of the Euler Rotation Theorem\nBefore I can start integrating angular velocity I need to choose a representation for the orientation. There are several different conventions when it comes to representing the orientation of an object in 3D. The most popular approach is to use a set of three angles called Euler Angles. This approach was developed by the mathematician Leonhard Euler (pronounced oy-ler not you-ler). These set of three angles specify three successive rotations around three different axes in a very specific order. The order is important because rotations in 3D have an important property: they do not commute. This means that if I do rotation 1 before 2 I end up with a different orientation than if I do 2 before 1. Euler angles usually specify rotations in the ZXZ order. This means that the first axis of rotation is the current Z-axis. The second axis of rotation is the new X-axis after the first rotation. The final axis of rotation is the new Z-axis after the first and second rotations. A closely related approach is to use what\u0026rsquo;s called Tait-Bryan angles. Tait-Bryan angles are called yaw, pitch and roll and are commonly used when talking about the orientation of aircraft. The angles represent successive rotations around the body fixed X, Y and Z axes. Both Euler angles and Tait-Bryan angles however, suffer from something called Gimbal Lock. This is when for a certain value of one of the rotation angles, a degree of freedom is lost and two rotations \u0026ldquo;collapse\u0026rdquo; into a single rotation. The Wikipedia page linked has some nice visualizations and a short mathematical explanation (using rotation matrices) for why this happens.\nUsing Quaternions to represent rotations is a way to avoid the Gimbal Lock problem. Quaternions are so useful for representing orientations that most Kalman Filters that need to track 3D orientations use them instead of Euler Angles. So I settled on using quaternions. When I first started working with quaternions I found them a little difficult to understand. So I thought of writing an article about the path I took to understand and use quaternions for \u0026ldquo;integrating\u0026rdquo; angular velocity.\nFrom all my time working with mathematics, I\u0026rsquo;ve come to realize that mathematical ideas exist on a spectrum. At one end is math that is focused on the practical application. Math that is very close to the real world (as experienced by humans) and can be understood easily by making analogies to things that humans encounter in everyday life. This is the type of math that is often applied to solve everyday problems like settling bills or building bridges. At the other end of the spectrum is the type of math that is pure abstraction. This type of abstract math is often used to generalize specific results in practical math to other problems or to come up with new insights that can pave the way for new solutions to a problem. Quaternions are a little more towards the abstract end of the spectrum and can be difficult to get an intuition for. Sometimes though there are ideas that you can\u0026rsquo;t get an intuition for. Working with such math is mostly a matter of getting used to it. With abstract math, the best way I\u0026rsquo;ve found to get used to it is to learn the basic definition and keep applying it to problems until you get the hang of it. The understanding forms in the brain automatically as you get the hang of it.\nQuaternion Math So without further ado, I\u0026rsquo;ll talk about what quaternions are and how they behave.\nRepresentation A quaternion $q$ can be represented as a tuple of 4 numbers: $$q = \\begin{bmatrix} w \u0026amp; \\ x \u0026amp;\\ y \u0026amp; \\ z \\end{bmatrix} = \\begin{bmatrix} w \u0026amp; \\ \\vec{v}\\end{bmatrix} = w + x\\mathrm{i} + y\\mathrm{j} + z\\mathrm{k} $$\nwhere the $w$ is the scalar part and the $\\vec{v}$ is the vector part.\nTwo binary operations are defined for quaternions: addition $+$ and quaternion multiplication $\\otimes$.\nAddition Addition is defined as the component-wise sum just like for a 4D vector. The sum is commutative (order is not important) and associative (grouping is not important).\n$$ q_1 + q_2 = \\begin{bmatrix} w_1 + w_2 \u0026amp; \\ x_1 + x_2 \u0026amp; \\ y_1 + y_2 \u0026amp; \\ z_1 + z_2 \\end{bmatrix} = q_2 + q_1$$\nMultiplication Quaternion multiplication is defined in multiple ways but the formula that I find the easiest to remember is: $$ q_1 \\otimes q_2 = \\begin{bmatrix} w_1 w_2 - \\vec{v}_1\\cdot\\vec{v}_2 \u0026amp; \\ w_1\\vec{v}_2 + w_2\\vec{v}_1 + \\vec{v}_1\\times\\vec{v}_2 \\end{bmatrix} $$\nThe multiplication is non-commutative ($q_1 \\otimes q_2 \\neq q_2 \\otimes q_1$ ) and distributive over the sum $(q_1 \\otimes (q_2 + q_3) = q_1 \\otimes q_2 + q_1 \\otimes q_3 )$.\nNorm, Conjugate and Inverse It\u0026rsquo;s also useful to define the norm of a quaternion as: $$ ||q|| = \\sqrt{w^2 + x^2 + y^2 + z^2} $$\na conjugate quaternion $ q^* $ that satisfies the property $ q \\otimes q^* = ||q||^2 $ as $$ q^* = \\begin{bmatrix} w \u0026amp; \\ -x \u0026amp; \\ -y \u0026amp; \\ -z \\end{bmatrix} $$\nand a quaternion inverse $q^{-1}$ with the property $q \\otimes q^{-1} = \\begin{bmatrix} 1 \\ 0 \\ 0 \\ 0 \\end{bmatrix}$ as $$ q^{-1} = \\frac{q^*}{||q||^2} $$\nUsing Quaternions for Rotation Now that the behaviour of quaternions are established, there is the question of how to use them to represent 3D rotation. From Euler\u0026rsquo;s Rotation Theorem it is clear that rotations have 3 degrees of freedom. But quaternions as 4 tuples have 4 degrees of freedom. So an additional constraint needs to be imposed to use them to represent rotations. This is done by requiring that the quaternions are unit quaternions: $||q|| = 1$. Unit quaternions are also called versors. There are many diagrams and visualizations that attempt to make understanding the unit quaternion more intuitive but I found that for me, most were misleading. I found it the most useful to think of quaternions as just an abstract object with the properties that I\u0026rsquo;ve mentioned and not trying to have any picture in mind. The moment I left behind the crutch of visualization and forced myself to accept and think about quaternions as they are, everything fell into place.\nTo rotate a 3D vector $\\vec{r}$ by a versor $q$ an operation called conjugation is used. $$ \\vec{r}\u0026rsquo; = q \\otimes \\begin{bmatrix} 0 \u0026amp; \\ \\vec{r} \\end{bmatrix} \\otimes q^{*} $$\nIf I find the formula quite mysterious (as I did when I first saw it), it\u0026rsquo;s helpful to use one of the other methods (euler angles, axis angle) to rotate a vector and verify that the result is the same.\nIt\u0026rsquo;s possible to compose two rotations represented by two quaternions $q_1$ and $q_2$ by multiplying the two quaternions together $q_2 \\otimes q_1$. This product represents the rotation $q_1$ applied before $q_2$.\nQuaternions, Rotation Matrices and the Rotation Group $SO(3)$ Earlier, I mentioned that rotations in 3D have certain properties (like non-commutativity) that implies that they don\u0026rsquo;t belong to a vector space (and therefore can\u0026rsquo;t be represented by one). If I want to be exact when talking about rotations, I have to consider them as a group. A group is yet another mathematical abstraction. Abstractly, think of them as a set of objects that follow certain rules. Remember that groups are another concept that leans towards the abstract end of the mathematical spectrum. They can be applied to rotations but they were invented by mathematicians to study more general ideas. So what rules does a group follow?\nA group is a set $G$ along with some binary operation $\\cdot$ (takes two elements of the set and gives a third). The elements of the set follow these rules:\nClosure: If $a,b \\in G$ then $a\\cdot b \\in G$. Associativity: If $a,b,c \\in G$ then $a\\cdot ( b \\cdot c) = (a \\cdot b) \\cdot c $. Identity: There\u0026rsquo;s some element of the set $e$ which has the property $a \\cdot e = e\\cdot a = a$. Inverse: If $a \\in G$ there\u0026rsquo;s some element $a^* $ such that $a \\cdot a^* = a^* \\cdot a = e$. If you compare this to 3D rotations, you can see that the set of 3D rotations are an example of a group under the binary operation of composition (doing one rotation after another)!\nClosure: If I compose two rotations it forms another rotation. It doesn\u0026rsquo;t suddenly become a translation or scaling or shear. There\u0026rsquo;s no way to combine rotations to do any of these other operations. Associativity: If I do three rotations, it doesn\u0026rsquo;t matter which two I compose first. Identity: There\u0026rsquo;s an identity rotation ($0^\\circ$ of rotation around any axis). And there\u0026rsquo;s an inverse rotation (rotating by negative of the angle around the same axis.) Quaternions under multiplications also satisfy all these properties.\nIf I convert Euler angle rotations to rotation matrices and compare them with quaternions, the parallels between them are very clear.\nGroup Property Rotation Matrix $R_i \\in G$ Quaternion $q_i \\in \\mathbb{H}_R$ Closure $R_1 \\cdot R_2 \\in G$ $q_1 \\otimes q_2 \\in \\mathbb{H}_R$ Associativity $R_1 \\cdot (R_2 \\cdot R_3) = (R_1 \\cdot R_2) \\cdot R_3$ $q_1 \\otimes (q_2 \\otimes q_3) = (q_1 \\otimes q_2) \\otimes q_3$ Identity $I$ $1$ Inverse $R_i^{-1} = R_i^{T} $ $q_i^{-1}$ The closure and associativity properties rotation matrices can be easily seen as a consequence of the fact that rotation matrices are orthogonal matrices.\nWith this knowledge of the rules that rotations follow, it\u0026rsquo;s clear why it\u0026rsquo;s silly to think of the Euler angles as a vector. They\u0026rsquo;re a set of related numbers but vectors they are not! It\u0026rsquo;s also clear why integrating the angular velocity vector over time does not directly give the orientation in an easily usable form.\nRepresenting quaternion rotation as a matrix Linearity of operations are an important property that both engineers and mathematicians like to take advantage of. It can result in useful simplifications of results. So it\u0026rsquo;s useful (later in this article) to ask the question: Is quaternion multiplication a linear operation? The simplest way to find out is to write out the result of a general quaternion multiplication operation and check if it\u0026rsquo;s possible to represent it as a matrix multiplication.\nThe symbolic result of multiplying two quaternions $q_1$ and $q_2$ is: $$ q_1 \\otimes q_2 = \\left[\\begin{matrix}w_1 w_2 - x_1 x_2 - y_1 y_2 - z_1 z_2\\\\ w_1 x_2 + w_2 x_1 + y_1 z_2 - y_2 z_1\\\\ w_1 y_2 + w_2 y_1 - x_1 z_2 + x_2 z_1\\\\ w_1 z_2 + w_2 z_1 + x_1 y_2 - x_2 y_1\\end{matrix}\\right] $$\nFrom inspection, this can be written as a matrix product: $$ q_1 \\otimes q_2 = \\left[\\begin{matrix}w_2 \u0026amp; -x_2 \u0026amp; -y_2 \u0026amp; -z_2\\\\ x_2 \u0026amp; w_2 \u0026amp; z_2 \u0026amp; - y_2\\\\ y_2 \u0026amp; - z_2 \u0026amp; w_2 \u0026amp; x_2\\\\ z_2 \u0026amp; y_2 \u0026amp; - x_2 \u0026amp; w_2\\end{matrix}\\right] \\begin{bmatrix} w_1 \\\\ x_1 \\\\ y_1 \\\\ z_1 \\end{bmatrix} $$\nAnd if I change the order of multiplication: $$ q_2 \\otimes q_1 = \\left[\\begin{matrix}w_2 \u0026amp; - x_2 \u0026amp; - y_2 \u0026amp; - z_2 \\\\ x_2 \u0026amp; w_2 \u0026amp; - z_2 \u0026amp; y_2 \\\\ y_2 \u0026amp; z_2 \u0026amp; w_2 \u0026amp; - x_2 \\\\ z_2 \u0026amp; - y_2 \u0026amp; x_2 \u0026amp; w_2\\end{matrix}\\right] \\begin{bmatrix} w_1 \\\\ x_1 \\\\ y_1 \\\\ z_1 \\end{bmatrix} $$\nIntegrating Angular Velocity To properly integrate angular velocity to get a quaternion, I need to find a relationship between quaternions and angular velocity - or more precisely - a differential equation that relates the time derivative of the quaternion $\\dot{q}$ and the angular velocity vector $\\vec{\\omega}$.\nA natural place to start is the original definition of the angular velocity from physical law. If I imagine a vector of constant $\\vec{s}(t)$ length stretching out from the origin undergoing rotation with the instantaneous angular velocity $\\vec{\\omega}(t)$ I can find the velocity at the tip of this vector by taking it\u0026rsquo;s derivative. $$ \\frac{\\mathrm{d}\\vec{s}}{\\mathrm{d}t} = \\vec{\\omega} \\times \\vec{s} $$\nSince the angular velocity is perpendicular to the vector $\\vec{s}$ (driving their dot product $\\vec{\\omega} \\cdot \\vec{s}$ to zero) the equation can also be written in quaternion form as: $$ \\frac{\\mathrm{d}\\vec{s}}{\\mathrm{d}t} = \\vec{\\omega} \\otimes \\vec{s} $$\nNow I imagine that this instantaneous vector is represented by a quaternion $q$ rotation from a constant vector $\\vec{s}_0$. $$\\begin{align} \\vec{s} \u0026amp;= q \\otimes \\vec{s}_0 \\otimes q^* \\\\ \\frac{\\mathrm{d}\\vec{s}}{\\mathrm{d}t} \u0026amp;= \\frac{\\mathrm{d}}{\\mathrm{d}t} \\left[ q \\otimes \\vec{s}_0 \\otimes q^* \\right] \\end{align}$$\nSo how do I take that nasty looking derivative on the side? Well it turns out that the product rule of derivatives that is valid in basic calculus is also perfectly valid for quaternion multiplication! I converted the quaternion product into a matrix multiplication and spent some time converting the derivatives of the product to the result from applying the product rule. The only thing to watch out for is the non commutativity of the multiplication. The order of the quaternion product shouldn\u0026rsquo;t be changed when applying the product rule.\n$$ \\frac{\\mathrm{d}}{\\mathrm{d}t} \\left[ q \\otimes \\vec{s}_0 \\otimes q^* \\right] = \\dot{q} \\otimes \\vec{s}_0 \\otimes q^* + q \\otimes \\vec{s}_0 \\otimes \\dot{q^*} $$\nThere\u0026rsquo;s a term in this equation - the derivative of the conjugate - that\u0026rsquo;ll cause some trouble. It is possible to eliminate this using other methods but the simplest way is to directly find a relationship between $\\dot{q}$ and $\\dot{q^*}$. The easy way to do this is to take the derivative of the product of a quaternion and it\u0026rsquo;s conjugate which we know to be 1:\n$$\\begin{align} \\frac{\\mathrm{d}}{\\mathrm{d}t} (q \\otimes q^* ) \u0026amp;= \\frac{\\mathrm{d}}{\\mathrm{d}t} 1 \\\\ \\dot{q} \\otimes q^* + q \\otimes \\dot{q^*} \u0026amp;= 0 \\end{align} $$\nThat gives the relationship\n$$ \\dot{q^* } = -q^* \\otimes \\dot{q} \\otimes q^* $$\nExpressing $s_0$ in terms of $s$, substituting $\\dot{q^* } $ and doing a little algebra: $$ \\frac{\\mathrm{d}}{\\mathrm{d}t} \\left[ q \\otimes \\vec{s}_0 \\otimes q^* \\right] = \\dot{q} \\otimes q^* \\otimes \\vec{s} - \\vec{s} \\otimes \\dot{q} \\otimes q^* = \\vec{\\omega} \\otimes \\vec{s} $$\nThe Quaternion Commutator The expression $\\dot{q} \\otimes q^* \\otimes \\vec{s} - \\vec{s} \\otimes \\dot{q} \\otimes q^*$ is in the form $p \\otimes q - q \\otimes p$ which is defined as a commutator operation written as $[p, q]$. Going through the algebra of this operation and simplifying:\n$$ [q_1, q_2] = \\begin{bmatrix} 0 \\ 2(\\vec{v}_1 \\times \\vec{v}_2) \\end{bmatrix} $$\nInterestingly, if both $q_1$ and $q_2$ are pure quaternions (They do not have a scalar part) then the quaternion commutator and the product are related:\n$$[\\vec{q}_1, \\vec{q}_2] = 2(q_1 \\times q_2) = 2(q_1 \\otimes q_2) $$\nThe Product $\\dot{q} q^* $ is a Pure Quaternion $$\\begin{align} \\dot{q} \\otimes q^* + q \\otimes \\dot{q^* } \u0026amp;= 0 \\\\ \\dot{q} \\otimes q^* \u0026amp;= -(\\dot{q} \\otimes q^* )^* \\end{align} $$\nSaying that a $q = -q^* $ is the same as saying that $w = -w$ which means that the scalar part of the quaternion is zero.\nThe Differential Equation So finally, I can extract the quaternion differential equation:\n$$ \\begin{align} \\dot{q} \\otimes q^* \\otimes \\vec{s} - \\vec{s} \\otimes \\dot{q} \\otimes q^* \u0026amp;= \\vec{\\omega} \\otimes \\vec{s} \\\\ \\left[\\dot{q} \\otimes q^* , \\vec{s}\\right] \u0026amp;= \\vec{\\omega} \\otimes \\vec{s} \\\\ 2\\dot{q} \\otimes q^* \\otimes \\vec{s} \u0026amp;= \\vec{\\omega} \\otimes \\vec{s} \\\\ \\dot{q} \u0026amp;= \\frac{1}{2} \\vec{\\omega} \\otimes q \\end{align} $$\nIn this equation the $\\vec{\\omega}$ is the angular velocity in the global fixed frame. In many situations it\u0026rsquo;s more useful to have an equation in terms of the angular velocity as measured by a reference frame fixed to the moving body - like when it is measured using a gyroscope. The angular velocity in this frame is the global angular velocity rotated into the body frame $\\vec{\\omega}\u0026rsquo; = q^* \\otimes\\vec{\\omega}\\otimes q $. Replacing $\\vec{\\omega}$ gives the more useful differential equation:\n$$ \\dot{q} = \\frac{1}{2} q \\otimes \\vec{\\omega} $$\nIntegration To solve this differential equation is to be able to integrate it. Normal differential equations are difficult enough. How does one solve a differential equation with a quaternion multiplication in it? This is where the linearity of the quaternion multiplication becomes very useful. I am also going to make a (reasonable) assumption - that the angular velocity is constant over a time $\\Delta t$. Then I can rewrite the differential equation in a well known form:\n$$ \\begin{bmatrix} \\dot{w} \\\\ \\dot{x} \\\\ \\dot{y} \\\\ \\dot{z} \\end{bmatrix} = \\frac{1}{2} \\cdot \\left[\\begin{matrix}0 \u0026amp; - \\omega_x \u0026amp; - \\omega_y \u0026amp; - \\omega_z \\\\ \\omega_x \u0026amp; 0 \u0026amp; \\omega_z \u0026amp; - \\omega_y \\\\ \\omega_y \u0026amp; - \\omega_z \u0026amp; 0 \u0026amp; \\omega_x \\\\ \\omega_z \u0026amp; \\omega_y \u0026amp; - \\omega_x \u0026amp; 0 \\end{matrix}\\right] \\cdot \\begin{bmatrix} w \\\\ x \\\\ y \\\\ z \\end{bmatrix} $$\nThis is an ODE in the form $\\dot{q} = Aq$ where A is the big matrix. The solution to this differential equation then is:\n$$ q(t) = e^{A(t - t_0 )} q_0 $$\nQuaternion Exponential Interestingly, if I define the quaternion exponential in the same way as the matrix exponential (using its Taylor Series representation), I get a quaternion equivalent formula 5.\n$$ \\begin{align} \\exp{(q)} \u0026amp;= e^{w}e^{\\vec{v}} \\\\ \u0026amp;= e^{w}\\left(\\sum_0^\\infty \\frac{\\vec{v}^k}{k!}\\right) \\\\ \u0026amp;= e^{w}\\left(\\cos{|\\vec{v}|} + \\frac{\\vec{v}}{|\\vec{v}|} \\sin{|\\vec{v}|}\\right) \\end{align} $$\nUsing the quaternion exponential, the solution to the differential equation can be expressed in quaternion form as:\n$$ q(t) = \\exp{\\left(\\frac{1}{2}\\vec{\\omega}\\Delta t\\right)} \\otimes q_0 $$\nSumming Up I started out with the simple sounding task of integrating angular velocity and in trying to solve it, traversed through a several different areas of mathematics and learned a lot along the way before coming to the final solution. However, my description here is far from complete. The equation above only holds if the angular velocity is constant over a time period. This means its a \u0026ldquo;first order\u0026rdquo; model. Dropping this assumption gives $n^{th}$ order models for integration. There are also intricate details that I\u0026rsquo;m only beginning to understand. For instance, I\u0026rsquo;m reading about how rotations are a special type of group called Lie Groups where the group is also a differentiable manifold (yet another interesting abstract mathematical object). The space of angular velocity forms what is called a Lie Algebra on the group. And the quaternion exponential function which most texts I refer to seem to pull out of thin air is actually related to a more general idea called an exponential map which maps general Lie Algebras to Lie Groups.\nDespite it\u0026rsquo;s incompleteness however, it is the minimum that I needed to understand to be able to actually implement in code the integration of a quaternion - i.e use quaternions practically for integrating data coming in from an inertial measurement unit. I hope that others trying to understand quaternions and their role in representing 3D rotations will find this article useful. Some of the references below go deeper into the nature of quaternions and how to use them for useful things like tracking orientations.\nReferences Boyle, Michael. \u0026ldquo;The integration of angular velocity.\u0026rdquo; Advances in Applied Clifford Algebras (2016): 1-30. https://en.wikipedia.org/wiki/Rotation_group_SO(3) https://en.wikipedia.org/wiki/Quaternion Sola, Joan. \u0026ldquo;Quaternion kinematics for the error-state KF.\u0026rdquo; (2015). https://math.stackexchange.com/questions/1030737/exponential-function-of-quaternion-derivation ","date":1505037488,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505037488,"objectID":"eea2238e7c7929b4f053ade593ae49cf","permalink":"https://www.ashwinnarayan.com/post/how-to-integrate-quaternions/","publishdate":"2017-09-10T17:58:08+08:00","relpermalink":"/post/how-to-integrate-quaternions/","section":"post","summary":"I\u0026rsquo;ve been working with inertial measurement units lately, and I\u0026rsquo;ve come to realize that there\u0026rsquo;s a surprising amount of mathematics involved in processing the raw data from the sensors. The story begins with me trying to integrate a three-dimensional angular velocity vector to get the orientation of an object.","tags":["mathematics","quaternions","robotics"],"title":"How to Integrate Quaternions","type":"post"},{"authors":null,"categories":null,"content":"When prototyping programs that deal with lots of data on an Arduino and other embedded systems or even on full blown computers, it\u0026rsquo;s really useful to have a quick tool for plotting the output of the program. Initially, I used python for doing this. Python is a beautifully simple language and between Numpy, Scipy and Matplotlib, you can do pretty much anything you want with data; from doing simple plotting to running machine learning algorithms on the data. However, when all you want is to quickly plot a text file containing some data, breaking out a text editor to write a python script can get annoying especially if you do it many times a day.\nThat was when I came across this interesting video from the computerphile YouTube channel.\nIt\u0026rsquo;s a fantastic interview with Brian Kernighan where he talks about his work on Unix and in particular then awk command line tool. I\u0026rsquo;ve been using linux as my primary operating system for quite some time now and I do a lot of programming in it. So I am fairly comfortable with using the terminal for compiling and debugging code. But there was never a situation where I had to sit down and learn about all the terminal based utilities that were available. As I was watching Brian Kernighan describe awk and how it works, I started to realize that I could really use this tool to my advantage when playing around with data. That was when I decided take a closer look at all the tools that were available on the linux terminal to see what I was missing out on.\nOver time I\u0026rsquo;ve developed a few \u0026ldquo;recipes\u0026rdquo; that are really useful to me and I thought I\u0026rsquo;d share some that I\u0026rsquo;ve found particularly useful.\n1. Log and monitor a serial port Logging and monitoring serial ports is a really common thing to have to do - especially if you\u0026rsquo;re working with embedded systems like the Arduino. It\u0026rsquo;s a standard way of getting data off the microcontroller. Checking what\u0026rsquo;s being logged to the serial port is as simple as running:\ncat /dev/ttyUSB0 Sometimes the command exits immediately or shows garbled output (due to the wrong baud rate). You can use stty to change the serial port settings.\nstty -F /dev/ttyUSB0 115200 min 1 I can also log the data from the serial port conveniently to a text file,\ncat /dev/ttyUSB0 \u0026gt; logfilename.txt 2. Log and monitor network ports One of the ways to get data off an Arduino is using an XBee device to wirelessly transmit it. I\u0026rsquo;m a big fan of using the XBee WiFi module to log data to a UDP port on my laptop. To view incoming data from the UDP port, I use a really useful tool called netcat. Say the device is logging data to port 9750. I can listen in on the data by running,\nnetcat -ul 9751 and log the data if I like.\nnetcat -ul 9751 \u0026gt; log.txt 3. Plot data in a log file from the terminal feedgnuplot is a really useful Perl script that can read data from stdin and pass it to gnuplot for plotting. The only requirement is that the data arrive in a specific format: One sample per line, spaces between each data stream. This means your data in the file should look like this:\n1.0 1.5 2.3 1.1 1.3 2.7 2.6 5.9 3.3 To plot the data:\ncat log.txt | feedgnuplot --lines --autolegend The --autolegend option automatically numbers each line in the graph. The --legend option can be used to add custom legends. I highly recommend going through the feedgnuplot manpage to find out about all the functionality that the script offers.\n4. Plot only specific data The awk command is useful for filtering data that comes into the program line by line. A simple way it can be applied is to plot only specific columns in the text data.\ncat log.txt | awk '{ print $1, $2 }' | feedgnuplot --lines --autolegend The awk command as shown here will filter out only columns 1 and 2 from the log file and pass it on to feedgnuplot.\nawk can also be used to do more complicated things like select lines with only numbers or only text. This can be useful if the log file contains other debug output lines as well and you want to filter out and plot just the lines that contain numeric data. Wikipedia has a pretty good introduction to awk. I also found that a lot of the time, I could find what I needed for specific problems by searching stackoverflow.\n5. Process data before plotting What if I have some raw data in a log file that you want to run through some processing (more complicated than an awk one liner)? I write a simple python script that reads lines from stdin and writes the processed sample to stdout. If I do this, I can plot the result by doing\ncat log.txt | ./process_script.py | feedgnuplot --lines --autolegend or log it to another file.\ncat log.txt | ./process_script.py \u0026gt; processed_data.txt 6. Interpret packed binary data If the data in the log file, or data that\u0026rsquo;s coming in from a serial port or network interface is in some packed binary format, there\u0026rsquo;s a handy tool called od that can interpret it on the fly. The command below will interpret data coming in as packets of 8 bytes as 2 byte integers.\nnetcat -ul 9751 | od -An -td2 -w8 od is a versatile tool and as is usual for linux programs, I recommend reading the manpage to know more about what it can do.\n7. Process/Plot live data streams If I have data coming in from from a serial port or from a network interface and I want to create a real-time plot, feedgnuplot has an option for that.\ncat /dev/ttyUSB0 | feedgnuplot --lines --autolegend --xlen 100 --stream 0.1 The --xlen option plots a window of the last 100 samples and the --stream option updates the plot as new data comes in. The parameter 0.1 is the refresh rate.\nI can even run the live data stream through my processing algorithm before plotting.\nnetcat -ul 9750 | ./process_data.py | feedgnuplot --lines --autolegend --xlen 100 --stream 0.1 8. Redirecting to multiple programs. Sometimes I\u0026rsquo;ve been in a situation where I want to monitor data coming in from a serial port and log it to a file at the same time. One way of doing this is to write a python script that reads data from stdin, logs it to a file and also writes the same data to stdout.\ncat /dev/ttyUSB0 | ./log_and_print.py | feedgnuplot --lines --xlen 100 --stream 0.1 This is good if you only want to do one extra thing with the output. There is a better solution however that uses the tee command.\ncat /dev/ttyUSB0 | tee \u0026gt;(command1) \u0026gt;(command2) \u0026gt;(logfile.txt) | feedgnuplot --lines --autolegend --xlen 100 --stream 0.1 This technique is quite versatile and can be used in many ways. For example, I can use tee to get the raw data from the serial port, plot it, pass it through a data processing script and plot the output of that result as well for a comparison.\nSumming up I\u0026rsquo;m sure that there are many more clever ways to combine and compose these commands to make prototyping easier as well as commands that I don\u0026rsquo;t know about yet. If there is one thing that I\u0026rsquo;ve learned after using linux for a few years it\u0026rsquo;s that it often has modest looking command line tools that can do much more than a lot of GUI based applications if you spend just a little time to go through the manpage. I hope that this post inspires others to take a second look at the free tools that come with most linux distros. Some of them could really simplify your workflow!\n","date":1502623814,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502623814,"objectID":"f68bd26732c0fb8ac63aae0aab63bf4f","permalink":"https://www.ashwinnarayan.com/post/bash-recipes-for-science/","publishdate":"2017-08-13T19:30:14+08:00","relpermalink":"/post/bash-recipes-for-science/","section":"post","summary":"When prototyping programs that deal with lots of data on an Arduino and other embedded systems or even on full blown computers, it\u0026rsquo;s really useful to have a quick tool for plotting the output of the program.","tags":["programming","linux","science"],"title":"Bash Recipes for Doing Science!","type":"post"},{"authors":null,"categories":null,"content":"Over the past few months I\u0026rsquo;ve been spending a lot of time on implementing various signal processing algorithms in C/C++. Things like Kalman Filters, various types of FIR filters and finite state machines. The number of steps needed to implement each these algorithms were fairly small and in the beginning I tried to put all the functionality of these implementations into simple to use C++ classes. This made things look neater and also fit in quite well with the Arduino programming framework (I was implementing a lot of these algorithms on Arduino compatible microcontrollers like the Teensy). However, once I started combining different algorithms together to make something bigger, the code started becoming very messy. Making changes and debugging was starting to take longer and longer. In many instances, I had to go back and change the deisgn and interface of my C++ classes when I realized that the way I initially implemented it made it impossible or very difficult to do some step in the algorithm. I decided to take some time to figure out how I can do better. I wanted to find out a systematic method - a \u0026ldquo;meta-programming\u0026rdquo; algorithm if you will - that would tell me the way I should implement the algorithm so that the code is easy to write and more importantly, easy to read and debug.\nRepresenting the Algorithm Before I could start solving the problem I needed to decide how to represent a general data processing algorithm. What is a representation that can capture most if not all of the types of algorithms that I wanted to implement? I remembered that in a lot of papers that I\u0026rsquo;ve read, the authors used Simulink to implement their algorithm. So I decided to start out by assuming that I can represent what I want to do in the form of a block diagram - much like the block diagrams that you can draw in Simulink. It turns out that as long as they don\u0026rsquo;t have any cycles or loops, block diagrams with arrows representing the flow of data between the blocks can be represented by a mathematical structure called a Directed Acyclic Graph.\nDirected Acyclic Graphs Graphs as a mathematical structure (different from the graphs that you use to plot data) are useful for representing relationships between things. Intuitively I think of them as circles connected by lines. The circles represent things and the lines represent some type of relationship between the things. If this seems very abstract, that\u0026rsquo;s because graphs can be applied to a lot of different things and when an concept is that general, it tends to be very abstract. As an example, a graph can be used to represent an electrical circuit. Each discrete component like a resistor or an LED can be considered a node or vertex in the graph (circles). The wires that connect these components together can be considered the edges of the graph.\nA graph representing the collatz sequence and some unrelated drawings.\rA directed graph is a graph in which the edges connecting the nodes have a direction. The graph in the image from xkcd is a directed graph since it has arrows connecting the nodes of the graph.\nA directed acyclic graph (DAG) is a directed graph that does not have cycles in it. This means that there is no way to start at a node in the graph and follow the arrows from node to node and reach the node you started at. A directed acyclic graph is useful for modeling dependencies. If you\u0026rsquo;re planning to understand some big concept in science - General Relativitiy for example - there are prerequisite ideas that you need to understand first. A subject and it\u0026rsquo;s prerequisites can be arranged in the form of a directed acyclic graph.\nA directed acyclic graph showing the dependencies for learning about Markov Chains.\rTopological Sorting Given a DAG showing the dependencies for learning about Markov chains like in the image above, one might ask the question: Is there a way to list the nodes of the graph in correct learning order i.e the order in which any dependencies for a node appear before the node itself is listed. It turns out that you can! Every DAG has at least one way in which we can make this sorted list and there are a few algorithms for doing so.\nSo if you want to learn something new, topologically sorting a dependency graph of the topic is a nice approach! In fact, this is exactly what the website Metacademy does! It gives you the order in which to learn things using topological sorting.\nDataflows So how does this relate to programming algorithms represented by block diagrams in C? I thought of the block diagram as a directed acyclic graph. The blocks which represent steps in the data processing algorithm are represented by nodes in the graph and the arrows that connect the blocks represent the flow of data. In programming, the nodes in the block diagram can be naturally represented by functions whose arguments are the incoming edges and the return values are the outgoing edges. This also means that the edges themselves can be naturally represented by variables in the C program. Once I\u0026rsquo;ve defined all the edge variables and block functions, I need to figure out what is the correct order in which to call each of these block functions. The \u0026ldquo;correct\u0026rdquo; order can be defined as the order in which each function is only called once all the variables that represent the input edges to the block have been updated (if necessary) in the current iteration of the main loop of the program. It turns out that this correct order is the same as the topologically sorted order of the function blocks.\nSo to summarize the systematic meta algorithm to implement a data processing algorithm in C:\nStart out with a fresh .h file which will contain your implementation\nConstruct a block diagram of the algorithm showing the data flow. Make sure that the block diagram is a directed acyclic graph. Give names to each node and edge. For each edge in the graph, declare a C variable in the global scope. I use the static keyword if I want to make sure that the variable is only visible inside the header file. The data type of the C variable depends on the node that the edge originates from. For each node in the graph, declare a function that takes as arguments pointers to both the input and and output edge variables from the node. It is useful to declare the input pointers as const to ensure that the function does not modify the data in the edge variables. The function uses the input to carry out the processing step and modifies the output edge variables. I use static variables inside the function if I need to keep track of any state (like for finite state machines). Any parameters needed by the processing step inside the function can either be declared globally or as a const argument of the function. Personally, I like to have the simple parameters as #defines at the top of the header file so I can tweak/change them easily. If there are parameters that need to be modified/tuned during execution, they can be declared as variables global to the file. This is useful if you\u0026rsquo;re running a code that implements something like a PID controller and you want to tune the gains of the controller online. I use an Arduino library that listens to incoming commands on one of the Serial ports. Define an initialization function that initializes all the edge variables to an initial state (if necessary). Define a main function graph execution function that calls the block functions in the topologically sorted order. Here\u0026rsquo;s a rough outline of what the .h file will look like.\n#ifndef DATA_PROC_H #define DATA_PROC_H //#defines and parameters #define PARAM1 0 //Define the edge variables with the appropriate type float e1, e2, e3, e4 int e5; //Define the node function prototypes void F1(const float in1, const float in2, float *out); void F2(const float in1, const float in2, float *out); void F3(const float in1, int *out); //Define the initialization function void data_proc_init() { e1 = 0; e2 = 0; e3 = 0; e4 = 0; } //Define the main execution pipeline function void data_proc_exec() { //Node functions called in the topologically sorted order F1(e1, e2, \u0026amp;e3); F2(e2, e3, \u0026amp;e4); F3(e4, \u0026amp;e5); } //Function implementations //Implement the node functions here #endif And in the main C file:\n#include \u0026quot;data_proc.h\u0026quot; int main(int argc, char** argv) { //Run the initialization function data_proc_init(); while(loop_condition) { //Execute pipeline function in loop data_proc_exec(); } } I\u0026rsquo;ve noticed that if I stick to these rules consistently, my code is generally much easier to read. As long as I give descriptive names to the block functions, I only need to look at the main execution function to figure out the flow of the program. Debugging becomes easier too! It becomes a matter of adding one function from the topologically sorted list at a time and checking the output for correctess.\nWhile the meta algorithm that I wrote down is specifically for C, this method can easily be extended to other programming languages. Python would make doing this even easier as it is much more flexible with functions returning data. Instead of taking in pointers to the output variables as arguments, the function can actually return tuples of data that can be assigned to the output edge variables.\nI\u0026rsquo;m sure that this method will have some limitations. One I can see right away is that it uses a lot of variables. One for each edge and even more for the static variables inside the function. On memory constrained systems like small microcontrollers, the RAM can run out pretty fast (Declaring non-tweakable parameters as being stored in the code ROM should help with this a bit). Another problem is the question of what to do with algorithms that can\u0026rsquo;t be represented as a DAG. I don\u0026rsquo;t know if it\u0026rsquo;s possible to represent all possible algorithms using DAGs (A quick google search did not turn up any conclusive answers). I am also unsure how this model can be used for programming things like GUIs which sit around and wait for events to happen most of the time. However, when implementing control and signal processing algorithms, I find this method is singularly better than the others I\u0026rsquo;ve tried.\n","date":1501517714,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1501517714,"objectID":"2174a5a7eae47c81eef886c06def86d9","permalink":"https://www.ashwinnarayan.com/post/dataflow-programming-in-c/","publishdate":"2017-08-01T00:15:14+08:00","relpermalink":"/post/dataflow-programming-in-c/","section":"post","summary":"Over the past few months I\u0026rsquo;ve been spending a lot of time on implementing various signal processing algorithms in C/C++. Things like Kalman Filters, various types of FIR filters and finite state machines.","tags":["programming","C"],"title":"Programming Complex Dataflows in C","type":"post"},{"authors":null,"categories":null,"content":"The IEEE International Conference on Robotics and Automation (ICRA) that happened in Singapore over the last week is often referred to as the robotics conference. If you\u0026rsquo;re an academic working in the field of robotics, Singapore was the place to be in the last week. So I spent most of my time hanging around the Marina Bay Sands Hotel Convention center as a student volunteer for the conference, helping out and - in my free time - attending some of the hundreds of presentations that that took place.\nOne thing that completely blew me away was the scale of the event. It made me realize how vast human knowledge is and how my life\u0026rsquo;s entire work would just be a miniscule part of the sum total. Robotics itself is just a small portion of all there is to know. And even in a conference dedicated to this field, I had to sift through dozens to subfields to attend the talks that were relevant to my narrow area of research.\nDay 1 The first day of the conference did not have any paper presentations. I guess they wanted to give the delegates from other countries time to get used to the place before they had to present their work. There were however, workshops on several different subjects that were going on. It was also one of the busiest days as a volunteer for me since I was helping out with the registrations of those coming in for the conference. I spent the day helping people get their conference ID tags (which were used for access control) and package. Instead of the usual thick booklet of the conference schedule, ICRA 2017 gave out to all the delegates an android tablet pre-loaded with an app that had the full conference schedule.\nRegistration work ended at 4.30 and I had some time to catch the end of a very interesting workshop on rehabiliation robotics.\nDays 2 - 4 Days 2 - 4 were when the bulk of the conference happened. The papers were classified into sub topics and the presentations for each sub topic happened in different rooms. I feel like the organizers did a good job of separating the papers out in a way that prevented situations where you had two relevant sessions that you had to be in at the same time. After listening to many people presenting their work, I feel a little less nervous about the time I\u0026rsquo;ll have to present my own work in a conference. For the most part, people were friendly, interested and loved to discuss with you about your work after the presentation. In fact, I\u0026rsquo;ll say that I\u0026rsquo;m almost looking forward to my next conference so that I can discuss with interested people about my work.\nConferences are also very intellectually stimulating! As I listened to the presentations I also found myself getting new ideas for how I could solve problems that I\u0026rsquo;m facing in my own work. And surprisingly, I had some of my more interesting ideas in sessions that were not directly related to my work. In my next conference I think I will also spend some time attending sessions that are not directly related to my area of research.\nWhile the technical sessions were fantastic, I enjoyed even more the brilliant talks that were arranged for the Keynote and Plenary sessions. These are talks arranged in the afternoons and in the mornings. I think that the organizers selected the works of some particularly brilliant people for these sessions. There were three talks that really stood out.\nMy favorite talk was one by Professor Lourdes Agapito from University College London. She gave a talk on her work on extracting 3D information from static 2D photos and videos. This is something that\u0026rsquo;s very difficult to do. The best camera sensor that does this is the Kinect and it has to use multiple cameras and an infra red pattern projected onto the scene to get depth information. This limits the range of the camera to a few feet. To get really good long range 3D reconstruction, you need to use a LIDAR - the sensors that self-driving cars use to sense the environment around them. That\u0026rsquo;s why I was so impressed by the quality of the 3D reconstruction that she was able to extract from images taken by just a single camera.\nI also really enjoyed the talk by Chris Gerdes from Stanford. Strapping a bunch of electronics on a DeLorean (among other cars) and making automatic control systems that can keep up with human racecar drivers (and even perform drifting maneuvers) is just pure awesomeness.\nThe last Keynote on June 1 by Professor Katja Mombaur was in a category of its own. She talked about her work on developing very accurate dynamic models of human walking. As someone who spent a lot of time trying to understand the very hairy mathematics behind the dynamics of human walking, I could really appreciate the amount of effort that went into her research. It\u0026rsquo;s probably work that I will be referring to and using quite frequently during my PhD.\nThere were also some robot competitions and an exhibition happening at the conference. I was expecting a lot from these but I didn\u0026rsquo;t find them as exciting as I thought I would. Maybe working in lab with lots of cool robots every day has rasied my standards of the kind of robotics demos that I find exciting. The robotics competitions were pretty interesting to watch though. Especially the block stacking challenge from DJI.\nDay 5 The last day of the conference was a little quiet. A lot of the people had already left or were busy exploring Singapore. The few who stuck around were those interested in attending the workshops on the last day of the conference. I attended one focusing on Assistive robotics.\nWorth it? Doing volunteer work in a conference is no easy task. I was on my feet through most of the 5 days and my feet were killing me at the end of the day. I don\u0026rsquo;t think I\u0026rsquo;ve ever walked more in my life than during the first four days of the conference. Your voice can also take quite a hit, especially if you\u0026rsquo;re working at the registration desk.\nOn the whole though, I think it was definitely worth it. I\u0026rsquo;d have gladly done all that work for the amazing talks and technical presentations alone, but that was not all that made the conference worth attending. It felt amazing to be surrounded by so much technology and by people who love robotics as much as I do. Being a bit of an introvert, I\u0026rsquo;ve always found it difficult to do small talk with people. The conversation just doesn\u0026rsquo;t feel natural or interesting to me. In the conference however, I felt like I could walk up to almost anyone and start a conversation about something without feeling like I\u0026rsquo;m boring my conversation partner. A welcome change for someone used to people zoning out when I talk about things that interest me.\nApart from the technical presentations, I also got to experience a really nice 9 course dinner, and free entry into the Night Safari and the flower dome in the Gardens By the Bay. So if you ever get an opportunity to become a student volunteer in a big conference like this in your field, go for it!\n","date":1496674252,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1496674252,"objectID":"b709a734684894012f1da4756659e20d","permalink":"https://www.ashwinnarayan.com/post/icra-2017/","publishdate":"2017-06-05T22:50:52+08:00","relpermalink":"/post/icra-2017/","section":"post","summary":"The IEEE International Conference on Robotics and Automation (ICRA) that happened in Singapore over the last week is often referred to as the robotics conference. If you\u0026rsquo;re an academic working in the field of robotics, Singapore was the place to be in the last week.","tags":["academia","conference","ICRA"],"title":"ICRA 2017","type":"post"},{"authors":[],"categories":[],"content":"Xenomai gets tasks to run in real-time by having a co-kernel running alongside the regular linux kernel handling all the time critical tasks. The Xenomai co-kernel is able to do this because of the i-pipe patch that the custom kernel is compiled with. This patch adds an interrupt pipeline that sits between the hardware of the computer and any kernels running on the hardware. The interrupt pipeline has domains which can be assigned a priority. When any interrupt, system call or processor fault comes in, the domain with the higher priority is allowed to process them first. The Xenomai co-kernel has the higher priority in an ipipe patched kernel. The Xenomai website has a more detailed explanation of how it works.\nBefore I start with the explanation, here\u0026rsquo;s the full code and Makefile for those who just want to compile some code and get started. The documentation for all the functions used in the code and more can be found here.\nThe code:\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;sys/mman.h\u0026gt; #include \u0026lt;alchemy/task.h\u0026gt; #include \u0026lt;alchemy/timer.h\u0026gt; #include \u0026lt;math.h\u0026gt; #define CLOCK_RES 1e-9 //Clock resolution is 1 ns by default #define LOOP_PERIOD 1e7 //Expressed in ticks //RTIME period = 1000000000; RT_TASK loop_task; void loop_task_proc(void *arg) { RT_TASK *curtask; RT_TASK_INFO curtaskinfo; int iret = 0; RTIME tstart, now; curtask = rt_task_self(); rt_task_inquire(curtask, \u0026amp;curtaskinfo); int ctr = 0; //Print the info printf(\u0026quot;Starting task %s with period of 10 ms ....\\n\u0026quot;, curtaskinfo.name); //Make the task periodic with a specified loop period rt_task_set_periodic(NULL, TM_NOW, LOOP_PERIOD); tstart = rt_timer_read(); //Start the task loop while(1){ printf(\u0026quot;Loop count: %d, Loop time: %.5f ms\\n\u0026quot;, ctr, (rt_timer_read() - tstart)/1000000.0); ctr++; rt_task_wait_period(NULL); } } int main(int argc, char **argv) { char str[20]; //Lock the memory to avoid memory swapping for this program mlockall(MCL_CURRENT | MCL_FUTURE); printf(\u0026quot;Starting cyclic task...\\n\u0026quot;); //Create the real time task sprintf(str, \u0026quot;cyclic_task\u0026quot;); rt_task_create(\u0026amp;loop_task, str, 0, 50, 0); //Since task starts in suspended mode, start task rt_task_start(\u0026amp;loop_task, \u0026amp;loop_task_proc, 0); //Wait for Ctrl-C pause(); return 0; } The Makefile\nSKIN=alchemy MAIN_SRC=cyclic_test TARGET=cyclic_test LM=-lm CFLAGS := $(shell xeno-config --skin=alchemy --cflags) LDFLAGS := $(LM) $(shell xeno-config --skin=alchemy --ldflags) CC := $(shell xeno-config --cc) $(TARGET): $(MAIN_SRC).c $(CC) -o $@ $\u0026lt; $(CFLAGS) $(LDFLAGS) First, the headers, defines and global variables:\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;sys/mman.h\u0026gt; #include \u0026lt;alchemy/task.h\u0026gt; #include \u0026lt;alchemy/timer.h\u0026gt; #include \u0026lt;math.h\u0026gt; #define CLOCK_RES 1e-9 //Clock resolution is 1 ns by default #define LOOP_PERIOD 1e7 //Expressed in ticks //RTIME period = 1000000000; RT_TASK loop_task; The includes are fairly standard. The Xenomai libraries are included by the alchemy/task.h and the alchemy/timer.h statements. I\u0026rsquo;ve deifined CLOCK_RES (The resolution of the clock) and LOOP_PERIOD (The period with which I want the periodic task to run) for convenience. The variable RT_TASK loop_task will hold an address to a task descriptor for a Real-Time task/thread that Xenomai will create.\nJumping ahead to main(), the first line that you come across that might be unfamiliar is:\n//Lock the memory to avoid memory swapping for this program mlockall(MCL_CURRENT | MCL_FUTURE); The mlockall() function is actually a function provided by linux rather than Xenomai and is provided by the \u0026lt;sys/mman.h\u0026gt; include. In Part one, I talked about how a real-time task can miss its deadlines if the task is swapped out of memory by the operating system. This line of code makes sure that the memory that is currently mapped to the address space of the process as well as any memory that gets mapped into the address space of the process in the future is \u0026ldquo;locked\u0026rdquo; into RAM and cannot get swapped out.\nIn the next few lines of code, a new real-time task is created.\n//Create the real time task sprintf(str, \u0026quot;cyclic_task\u0026quot;); rt_task_create(\u0026amp;loop_task, str, 0, 50, 0); The rt_task_create() function creates a new real-time task using Xenomai\u0026rsquo;s Alchemy API. The first argument is the RT_TASK variable that holds the address of the task descriptor. The second is a string that holds a name for the task. You can give it a descriptive name. The third argument is the size of the stack for the new task. Passing a zero makes the function use a system dependent default. The next argument is the priority of the task. This tells the real-time scheduler how important the task is. Higher priority tasks can interrupt lower priority tasks. The last argument is the task creation mode into which you can pass bitwise OR\u0026rsquo;ed flags. For example, passing the T_JOINABLE flag allows you to call the rt_task_join() function to wait on the task to finish. In this code sample, I\u0026rsquo;m just passing in zero, which is the default mode. The function returns a 0 if the task is successfully created. Ideally, you should check for this and print an error if the return value is not zero. However, for this simple example, I\u0026rsquo;m omitting this.\nA real-time task created using rt_task_create() starts off dormant. To begin the execution of the task, you need to call the rt_task_start() function.\n//Since task starts in suspended mode, start task rt_task_start(\u0026amp;loop_task, \u0026amp;loop_task_proc, 0); The first two arguments are the task descriptor and a pointer to the function that implements the real-time task. The last argument is a pointer to a user defined struct that will be passed on as arguments to the real-time task function.\nFinally we call the pause() function and wait for a Ctrl-C signal from the terminal.\nOnce rt_task_start() is called, the real-time task starts executing. To make a Xenomai task periodic, you need to call the rt_task_set_periodic() function.\n//Make the task periodic with a specified loop period rt_task_set_periodic(NULL, TM_NOW, LOOP_PERIOD); If you\u0026rsquo;re calling this function from outside a real-time task, you need to pass in an RT_TASK as the first argument. However, you can also call this function from inside a real-time task with a NULL first argument. TM_NOW tells Xenomai to start timing the task right away and LOOP period is the period of the task in ticks of the clock. Since the default resolution of the clock is 1 nanosecond, this argument is the same as the period you want for the task expressed in nanoseconds.\nNow we can start the infinite loop of the task.\n//Start the task loop while(1){ printf(\u0026quot;Loop count: %d, Loop time: %.5f ms\\n\u0026quot;, ctr, (rt_timer_read() - tstart)/1000000.0); ctr++; rt_task_wait_period(NULL); } In the loop I increment a simple counter and also use the rt_timer_read() function to get the current system time so I can print to the terminal and check if the task is running in real-time. The rt_task_wait_period() blocks the loop till the start of the next period.\nWhen I started out trying to compile and run Xenomai with no prior experience, it seemed like quite a daunting task. The Xenomai documentation although excellent is written for programmers and as a result, it can be difficult to write your very first program. However, once you do write your very first program and you get a good idea for how it works, things go very smoothly. This post, like the one before is a bit long but hopefully, someone trying to get started with Xenomai for the first time will find it useful!\n","date":1495293016,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1495293016,"objectID":"997bd596a75a293516994ef15bcdfdc6","permalink":"https://www.ashwinnarayan.com/post/xenomai-realtime-programming-part-2/","publishdate":"2017-05-20T23:10:16+08:00","relpermalink":"/post/xenomai-realtime-programming-part-2/","section":"post","summary":"I walk you through writing a simple cyclic task in Xenomai.","tags":["programming"],"title":"Real-Time Programming with Xenomai 3 - Part 2: Writing a simple periodic task.","type":"post"},{"authors":null,"categories":null,"content":"In my lab, we recently started moving away from Simulink\u0026rsquo;s Real-Time packages and towards Real-Time Linux for implementing the low level control of our robots. I thought I would document what I went through to get Xenomai (A Real-Time framework for linux) working stably as a resource for others trying to get started on the same thing.\nWhat is Real-Time? The word \u0026ldquo;real-time\u0026rdquo; is used in a lot of different fields to mean different things. Some people also mistake real-time systems for high performance systems. I use the word real-time to refer to systems that guarantee consistent responses to events within time constraints (also called deadlines) with low variability regardless of system load. This is something that\u0026rsquo;s not easy to do. A normal linux operating system is not real-time.\nSay you want to implement a program in C on a regular linux computer that toggles a pin on the parallel port every millisecond. A naive implementation would be as a simple loop that toggles the pin and waits for 1 millisecond. This may work OK most of the time but the moment the system is loaded by something else, the program may start running its loops slower because the process may be preempted by the kernel or be swapped out of memory in favor of another memory intensive program.\nA real-time operating system will be designed so that regardless of the system load, the program that toggles the pin can do the operation every millisecond give or take a few microseconds. This is the reason that a high performance computer with the latest Core i7 processor running a non-realtime OS can be less \u0026ldquo;real-time\u0026rdquo; than a low end microcontroller running a single optimized control task. Real-time systems are used in mission critical control systems such as those on fly-by-wire aircraft, satellites, exoplanetary rovers, cardiac pacemakers or car engine control units.\nA real-time operating system (RTOS) usually has an API for creating and running real-time tasks and uses a scheduling algorithm that\u0026rsquo;s different from what\u0026rsquo;s used by general purpose operating systems like Windows and Linux. There are many RTOSs in the wild. Wikipedia has a great list of them. Some RTOS\u0026rsquo;s like FreeRTOS are meant to be used in embedded microcontrollers. Some - like RTLinux are used when the real-time application needs to be run on a full blown operating system. Using real-time with full operating systems also allow you to take advantage of a lot of existing software and functionality that the operating system will have like networking and math libraries like GSL.\nReal-Time Operating Systems for Control When implementing a control system such as a PID controller digitally, real-time response times become very important. One of the assumptions made when developing digital control systems is that of constant sampling time. When you implement a control loop in code, if the constant sampling rate assumption is not met or if the controller responds too late to changes in the system state, it could lead to the system becoming unstable.\nThe choice of using Xenomai to implement our real time controllers was mostly due to the fact that it has very good documentation apart from being free and open source.\nInstalling Xenomai To get Xenomai running on a linux system, you need to compile a modified kernel. I used Lubuntu 12.04 (which ships with kernel 3.2). The version of the kernel that I compiled is 3.18.20. Choose a version of the kernel that is close in version number to the one that the distribution ships with to minimize issues.\nBefore starting, create a fresh folder to act as your workspace. Also make sure you have plenty of disk space available. The 3.18.20 kernel requires just over 11 GB of free disk space to compile successfully. Newer versions of the kernel need more. 20 GB should be safe.\nThese are the steps that I\u0026rsquo;ve been following to get a freshly installed Lubuntu system working with xenomai. Keep in mind that if this is the first time you\u0026rsquo;re compiling a kernel, things are bound to go wrong. Be willing to debug your compilation patiently. I had to go through the compilation process dozens of times, making tweaks at each step to get my first successful kernel image.\nGo to the downloads section of the xenomai website and look for an ipipe patch (it\u0026rsquo;s a file with a .patch extension) that is for a kernel version that\u0026rsquo;s close to the version your distribution ships with. This is the kernel version that you\u0026rsquo;ll be compiling. Go to kernel.org and download the version of the linux kernel that exactly matches the kernel version on the ipipe patch file name. Download the xenomai source from the xenomai website. Unzip the files into separate folders. Apply the xenomai patch to the kernel: xenomai-3.0.4/scripts/prepare-kernel.sh --linux=linux-\u0026lt;version\u0026gt; --ipipe=patch-\u0026lt;patch-version\u0026gt;.patch --arch=x86_64 cd into the kernel source directory and run make menuconfig and make the following changes: Power Management and ACPI Options -\u0026gt; CPU Frequency Scaling - DISABLE Power Management and ACPI Options -\u0026gt; ACPI Support -\u0026gt; Processor - DISABLE Power Management and ACPI Options -\u0026gt; CPU Idle -\u0026gt; CPU Idle PM Support - DISABLE Device Drivers -\u0026gt; Input Device Support -\u0026gt; Generic Input Layer -\u0026gt; Miscellaneous Devices -\u0026gt; PC Speaker Support - DISABLE Processor type and features -\u0026gt; Processor family: Select the exact processor on the motherboard. This is important for things to work properly. Xenomai/cobalt -\u0026gt; Core Features -\u0026gt; Shared Interrupts - ENABLE (If you want shared interrupts to work) In the Xenomai/Cobalt drivers section enable all the drivers for the devices that you’ll be using. Consider compiling the drivers as modules (using the m key) so that it is easier to load and unload and debug using modprobe/insmod/rmmod Before compiling the kernel ensure that you have all the packages needed to compile the kernel. Use apt-get or any package manager. gcc make Autoconf libtool kernel-package build-essential fakeroot dh-autoconf cd into the kernel source folder again and compile the kernel using the command: sudo CONCURRENCY_LEVEL=8 CLEAN_SOURCE=no fakeroot make-kpkg --initrd --append-to-version -xenomai-realtime --revision 1.0 kernel_image kernel_headers Once the compile is complete, in the directory above the kernel source, there should be two .deb files: One starting with linux-headers and one starting with linux-image. These are the kernel image and header debian packages that you can use to install the kernel. Use sudo dpkg -i \u0026lt;package-name\u0026gt; to install each of the packages Update the initramfs using the command sudo update-initramfs -c -k \u0026lt;kernel-version\u0026gt;-xenomai-realtime \u0026amp;\u0026amp; sudo update-grub cd into the unzipped xenomai source folder and run sudo ./configure followed by sudo make \u0026amp;\u0026amp; make install Reboot and select the new kernel in the grub menu (Hold down shift at boot time to bring up the menu). If everything went well, xenomai should be installed on your system now. You might be tempted to start running some tests immediately but I think it\u0026rsquo;s worth taking some more time to set up your build environment properly to make development easier.\nSome important xenomai related executables (including xeno-config) are in the /usr/xenomai/bin folder. You need to append this to the PATH environment variable. The library files that the code is linked against are installed in the /usr/xenomai/lib folder. You need to append this to the LD_LIBRARY_PATH environment variable. My preferred way of doing this is to edit the ~/.bashrc file with export statements. Open up your .bashrc file (it\u0026rsquo;s in your home folder, hidden) by running leafpad ~/.bashrc and add the following two lines to it at the end.\nexport LD_LIBRARY_PATH=”/usr/xenomai/lib:$LD_LIBRARY_PATH”``` When you try to run a compiled xenomai application afterwards, you will need to run it as superuser (using the sudo command). It might complain that it cannot find the library files. This is because environment variables are cleared when running a program as root. To fix this permanently: 1. Open up a terminal and go to the `/etc/ld.so.conf.d` folder. 2. Create a new file called xenomai.conf (as superuser) 3. Add the line `/usr/xenomai/lib` to the file. 4. Run `sudo ldconfig` _Now_ you can finally try to run some tests. If everything went well, running `sudo /usr/xenomai/bin/latency` should run the latency test program that outputs some numbers on to the terminal that shows you the latency figures of your system. It should be in the tens of microseconds range (If not something's wrong). The process of getting real-time linux with Xenomai or any other framework running for the first time can be a little painful but once your installation is stable, it'll serve you well for a very long time. Once you have a working compiled kernel package, installation on future hardware will also go much faster. In Part 2 of this series of blog posts, I will go through the process of writing a simple periodic real-time task using Xenomai's real-time API. ","date":1494950856,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1494950856,"objectID":"518b90624e1fed5568732a8c3d044e50","permalink":"https://www.ashwinnarayan.com/post/xenomai-realtime-programming/","publishdate":"2017-05-17T00:07:36+08:00","relpermalink":"/post/xenomai-realtime-programming/","section":"post","summary":"In my lab, we recently started moving away from Simulink\u0026rsquo;s Real-Time packages and towards Real-Time Linux for implementing the low level control of our robots. I thought I would document what I went through to get Xenomai (A Real-Time framework for linux) working stably as a resource for others trying to get started on the same thing.","tags":["xenomai","real-time","programming"],"title":"Real-Time Programming with Xenomai 3 - Part 1: Installation and Basic Setup","type":"post"},{"authors":null,"categories":null,"content":"My old website was formatted a lot like an online resume - something I feel doesn\u0026rsquo;t quite fit me any more after I decided to join a PhD program. So I decided to refresh my website deisgn into something that fit my current research interests. I also wanted a platform where I could blog about my work and personal projects. I\u0026rsquo;ve read blogs by many active researchers and I feel that the informal tone and nature of a blog allows more accessible explanations of research than formal journal/conference papers - where the language can often be very terse and full of jargon. A few excellent research blogs that I was inspired by:\nStudywolf - About robotics and control. Math ∩ Programming Math and programming colah\u0026rsquo;s blog - A blog by a researcher at Google about machine learning Like for my old website, I decided to go with a static website which allows me to host the site for free using Github pages. I used a static site generator called Jekyll. However, I found it a bit time consuming to use. I wanted to spend more time focusing on the content of the website and less on the setup. So I did a little research on other static site generators that I can use and came across Hugo. It seemed to have all the nice features that a static site generator should have. It works across all operatings systems, had a lot of free themes, was open source and most importantly was easy to set up. I was able to get a basic website generated in under two minutes by following their getting started tutorial. If you\u0026rsquo;re looking for a good static site generator, I highly recommend Hugo.\n","date":1494693531,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1494693531,"objectID":"c37907f82482fd5612d3e60689e56628","permalink":"https://www.ashwinnarayan.com/post/welcome/","publishdate":"2017-05-14T00:38:51+08:00","relpermalink":"/post/welcome/","section":"post","summary":"My old website was formatted a lot like an online resume - something I feel doesn\u0026rsquo;t quite fit me any more after I decided to join a PhD program. So I decided to refresh my website deisgn into something that fit my current research interests.","tags":["miscellaneous"],"title":"Brand New Website!","type":"post"}]